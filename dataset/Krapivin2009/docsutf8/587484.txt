--T
Uniform Convergence and Mesh Independence of Newton''s Method for Discretized Variational Problems.
--A
In an abstract framework, we study local convergence properties of Newton's method for a sequence of generalized equations which models a discretized variational inequality. We identify conditions under which the method is locally quadratically convergent, uniformly in the discretization. Moreover, we show that  the distance between the Newton sequence for the continuous problem and  the Newton sequence for the discretized problem is bounded by the norm of a residual. As an application, we present mesh-independence results for an optimal control problem with control constraints.
--B
Introduction
In this paper we study local convergence properties of Newton-type methods applied to
discretized variational problems. Our target problem is the variational inequality representing
the rst-order optimality conditions in constrained optimal control. In an abstract frame-
work, the optimality conditions are modeled by a \generalized equation", a term coined by S.
Robinson [12], where the normal cone mapping is replaced by an arbitrary map with closed
graph. In this setting, Newton's method solves at each step a linearized generalized equation.
When the generalized equation describes rst-order optimality conditions, Newton's method
becomes the well-known sequential quadratic programming (SQP) method.
We identify conditions under which Newton's method is not only locally quadratically
convergent, but the convergence is uniform with respect to the discretization. Moreover, we
derive an estimate for the number of steps required to achieve a given accuracy. Under some
additional assumptions, which are natural in the context of the target problem, we prove
that the distance between the Newton sequences for the continuous problem and the Newton
sequence for the discretized problem, measured in the discrete metric, can be estimated by
the norm of a residual. Normally, the residual tends to zero when the approximation becomes
ner, and the two Newton sequences approach each other. In the context of the target optimal
control problem, the residual is proportional to the mesh spacing h, uniformly along the
Newton sequence. In particular, this implies that the least number of steps needed to reach
a point at distance " from the solution of the discrete problem does not depend on the mesh
spacing; that is, the method is mesh-independent.
The convergence of the SQP method applied to nonlinear optimal control problems has
been studied in several papers recently. In [5, 6] we proved local convergence of the method
for a class of constrained optimal control problems. In parallel, Alt and Malanowski obtained
related results for state constrained problems [3]. In the same line Troltzsch [13] studied the
SQP method for a problem involving a parabolic partial dierential equation.
Kelley and Sachs [10] were the rst to obtain a mesh independence result in constrained
optimal control; they studied the gradient projection method. More recently, uniform convergence
and mesh-independence results for an augmented Lagrangian version of the SQP method,
applied to a discretization of an abstract optimization problem with equality constraints, were
presented by Kunisch and Volkwein [11]. Alt [2] studied the mesh-independence of Newton's
method for generalized equations, in the framework of the analysis of operator equations in
Allgower et al. [1]. An abstract theory of mesh independence for innite-dimensional optimization
problems with equality constraints, together with applications to optimal control of
partial dierential equations and an extended survey of the eld can be found in the thesis of
Volkwein [14].
The local convergence analysis of numerical procedures is closely tied to problem's sta-
bility. The analysis is complicated for optimization problems with inequality constraints, or
for related variational inequalities. In this context, the problem solution typically depends on
perturbation parameters in a nonsmooth way. In Section 2 we present an implicit function
theorem which provides a basis for our further analysis. In Section 3 we obtain a result on
uniform convergence of Newton's method applied to a sequence of generalized equations, while
Section 4 presents our mesh-independence results. Although in part parallel, our approach is
dierent from the one used by Alt in [2] who adopted the framework of [1]. First, we study
the uniform local convergence of Newton's method which is not considered in [2]. In the mesh-
independence analysis, we avoid consistency conditions for the solutions of the continuous and
the discretized problems; instead, we consider the residual obtained when the Newton sequence
of the continuous problem is substituted into the discrete necessary conditions. This allows
us to obtain mesh independence under conditions weaker than those in [2] and, in the same
time, to signicantly simplify the analysis.
In Section 5 we apply the abstract results to the constrained optimal control problem
studied in our previous paper [5]. We show that under the smoothness and coercivity conditions
given in [5], and assuming that the optimal control of the continuous problem is a
Lipschitz continuous function of time, the SQP method applied to the discretized problem is
Q-quadratically convergent, and the region of attraction and the constant of the convergence
are independent of discretization, for a suciently small mesh size. Moreover, the l 1 distance
between the Newton sequence for the continuous problem at the mesh points and the Newton
sequence for the discretized problem is of order O(h). In particular, this estimate implies the
mesh-independence result in Alt [2].
2. Lipschitzian localization
Let X and Y be metric spaces. We denote both metrics by (; ); it will be clear from the
context which metric we are using. B r (x) denotes the closed ball with center x and radius r.
In writing \f maps X into Y " we adopt the convention that the domain of f is a (possibly
proper) subset of X. Accordingly, a set-valued map F from X to the subsets of Y may have
empty values.
Denition 2.1. Let map Y to the subsets of X and let x  2 (y  ). We say that
has a Lipschitzian localization with constants a, b and M around (y  ; x  ), if the map y 7!
(y)\B a single-valued (a function) and Lipschitz continuous in B b (y  ) with a Lipschitz
constant M .
Theorem 2.1. Let G map X into the subsets of Y and let y  2 G(x  ). Let G 1 have a
Lipschitzian localization with constants a; b, and M around (y  ; x  ). In addition, suppose that
the intersection of the graph of G with B a closed and B a (x  ) is complete. Let
the real numbers ,
M ,  a, m and  satisfy the relations
Suppose that the function continuous with a constant  in the ball
B a (x  ), that
sup
and that the set
is nonempty.
Then the set fx 2 B a consists of exactly one point,
x, and for each
Proof. Let us choose positive ;
a and  such that the relations in (1) hold. We
rst show that the set T := nonempty. Let x 0 2  and put
Take an arbitrary " > 0 such that
Choose an y
and
from the Lipschitzian localization property, there exists x 1 such that
We dene inductively a sequence x k in the following way. Let x be already dened
for some k  1 in such a way that
and
Clearly, x 0 and x 1 satisfy these relations. Using the second inequality in (5), we estimate
a
Thus both x k 1 and x k are in B a (x  ) from which we obtain by (2),
k. Due to the assumed Lipschitzian localization property of G, there
exists x k+1 such that (7), with k replaced by k + 1, is satised and
By (6) we obtain
and hence (6) with k replaced by k + 1, is satised. The denition of the sequence x k is
complete.
>From (6) and the condition M < 1, fx k g is a Cauchy sequence. Since all x
sequence fx k g has a limit x Passing to the limit in (7), we obtain g(x 00
Hence x 00 2 T and the set T is nonempty. Note that x 00 may depend on the choice of ". If we
prove that the set T is a singleton, say ^
x, the point x would not depend on ".
Suppose that there exist x 00 2 T and
It follows that (g(x); y  )
x 00 . >From the denition of the Lipschitzian localization, we obtain
which is a contradiction. Thus T consists of exactly one point, ^ x, which does not depend on
". To prove (4) observe that for any choice of k > 1,
Passing to the limit in the latter inequality and using (5), we obtain
But since x
x does not depend on the choice of ", one can take in (8) and the proof
is complete.
3. Newton's Method
Theorem 2.1 provides a basis for the analysis of the error of approximation and the convergence
of numerical procedures for solving variational problems. In this and the following
section we consider a sequence of so-called \generalized equations". Specically, for each
be a closed and convex subset of a Banach space, let Y N be a linear
normed space, let fN : X N 7! Y N be a function, and let FN : X N 7! 2 Y N be a set-valued
map with closed graph. We denote by k  kN the norms of both X N and Y N . We study the
following sequence of problems:
Find
We assume that there exist constants , ,
, and L, as well as points x
that satisfy the following conditions for each N :
(A2) The function fN is Frechet dierentiable in B  (x
N ) and the derivative rfN is Lipschitz
continuous in B  (x
N ) with a Lipschitz constant L.
(A3) The map
y 7!
has a Lipschitzian localization with constants ;  and
around the point (z
We study the Newton method for solving (9) for a xed N which has the following form:
If x k is the current iterate, the next iterate x k+1 satises
where x 0 is a given starting point. If the range of the map F is just the origin, then (9) is an
equation and (10) becomes the standard Newton method. If F is the normal cone mapping in
a variational inequality describing rst-order optimality conditions, then (10) represents the
rst-order optimality condition for the auxiliary quadratic program associated with the SQP
method.
In the following theorem, by applying Theorem 2.1, we obtain the existence of a locally
unique solution of the problem (9) which is at distance from the reference point proportional
to the norm of the residual z
N . We also show that the method (10) converges Q-quadratically
and this convergence is uniform in N and in the choice of the initial point from a ball around
the reference point x
N with radius independent of N . Note that, for obtaining this result we
do not pass to a limit and consequently, we do not need to consider sequences of generalized
equations.
Theorem 3.1. For every
there exist positive constants  and  such that if
kz
then the generalized equation (9) has a unique solution xN in B  (x
xN satises
Furthermore, for every initial point x
N ) there is a unique Newton sequence fx k g, with
Newton sequence is Q-quadratically convergent to xN , that
is,
where  is independent of k; N and x
Proof. Dene
min
s
We will prove the existence and uniqueness of xN by using Theorem 2.1 with
and
Observe that a  ; b  , and
b  a. By (A3) the map G has a Lipschitzian localization
around
. One can check that the relations (1) are satised.
Further, for
N ); we have
Obviously, x
dened in (3). The assumptions of Theorem
2.1 are satised, hence there exists a unique xN in B  (x
Hence
xN is a unique solution of
holds. This completes the rst part of the
proof.
Given x
N ), a point x is a Newton step from x k if and only if x satises the
inclusion
where G is the same as above, but now
The proof will be completed if we show that (14) has a unique solution x
this solution satises (12). To this end we apply again Theorem 2.1 with a; b; M;
M , and
the same as in the rst part of the proof, and with
With these identications, it can be checked that the assumptions (1) and (2) hold, and that g
is Lipschitz continuous in B  (x
N ) with a Lipschitz constant . Further, by using the solution
xN obtained in the rst part of the proof, we have
L
The last expression has the estimate
Thus xN 2  6= ; and the assumptions of Theorem 2.1 are satised. Hence, there exists a
unique Newton step x k+1 in B  (x
N ) and by Theorem 2.1 and (15) it satises
4. Mesh independence
Consider the generalized equation (9) under the assumption (A1)-(A3). We present rst a
lemma in which, for simplicity, we suppress the dependence of N .
Lemma 4.1. For every
, every  > 0 and for every suciently small  > 0, there
exists a positive  such that the map
is a Lipschitz continuous function from B  (z
for y and  for w.
Proof. Let
and  > 0. We choose the positive constants  and  as a solution of
the following system of inequalities:
This system of inequalities is satised by rst taking  suciently small, and then taking
suciently small. In particular, we have    and   .
We apply Theorem 2.1 with
,
and
We have
for all x Hence the function g is Lipschitz continuous with a Lipschitz constant
. For
+2
Note that a point x is in the set P (y only if g(x) 2 G(x). Since
the set  dened in (3) is not empty. Hence, from Theorem 2.1 the set P (y
consists of exactly one point. Let us call it x 00 . Applying the same argument to an arbitrary
point (y that there is exactly one point x
Hence x 0 2  and we obtain
It remains to prove that P maps B  (z  From the last inequality
with
Thus x
In the remaining part of this section, we x
and 0 <  < 1, and we choose the
constants  and  according to Theorem 3.1. For a positive  with   , let  be the constant
whose existence is claimed in Lemma 4.1. Note that  can be chosen arbitrarily small; we take
Also, we assume that kz
and consider Newton sequences with initial points
In such a way, the assumptions of Theorem 3.1 hold and we have a unique
Newton sequence which is convergent quadratically to a solution.
Suppose that Newton's method (10) is supplied with the following stopping test: Given
" > 0, at the k-th step the point x k is accepted as an approximate solution if
Denote by k " the rst step at which the stopping test (18) is satised.
Theorem 4.1. For any positive " < , if x k" is the approximate solution obtained using
the stopping test (18) at the step
and
Proof. Choose an " such that 0 < " < . If the stopping test (18) is satised at x k" , then
there exists v k
" with k v k
" such that
Let P N be dened as in (16) on the basis of fN and FN . Since
Lemma 4.1 implies that
The latter inequality yields (19). For all k < k " , we obtain
Since x k is a Newton iterate, we have
Hence
By the denition of the map P N , the Newton step x 1 from x 0 satises
while the Newton step x 2 from x 1 is
Since P N is Lipschitz continuous with a constant , we have
By induction, the 1)-st Newton step x k+1 satises
Combining (21) and (22) and we obtain the estimate
which yields (20).
Our next result provides a basis for establishing the mesh-independence of Newton's
method (10). Namely, we compare the Newton sequence x k
N for the \discrete" problem
and the Newton sequence for a \continuous" problem which is again described by (9) but with
us assume that the conditions (A1){(A3) hold for the generalized equation
According to Theorem 3.1, for each starting point x 0
0 close to a solution x
there is a unique Newton sequence x k
which converges to x 0 Q-quadratically. To relate the
continuous problem to the discrete one, we introduce a mapping N from X 0 to X N . Having in
mind the application to optimal control presented in the following section, X 0 can be thought
as a space of continuous functions x() in [0; 1] and, for a given natural number N , t
will be the space of sequences fx Ng. In this case the operator N
is the interpolation map N
Theorem 4.2. Suppose that for every k and N there exists r k
and
In addition, let
for all k and N . Then for all
Proof. By denition, we have
Using Lemma 4.1 we have
By induction we obtain (24).
The above result means that, under our assumptions, the distance between the Newton
sequence for the continuous problem and the Newton sequence for the discretized problem,
measured in the discrete metric, can be estimated by the sup-norm !N of the residual obtained
when the Newton sequence for the continuous problem is inserted into the discretized
generalized equations. If the sup-norm of the residual tends to zero when the approximation
becomes ner, that is, when N !1, then the two Newton sequences approach each other. In
the next section, we will present an application of the abstract analysis to an optimal control
problem for which the residual is proportional to the mesh spacing h, uniformly along the
Newton sequence. For this particular problem Theorem 4.2 implies that the distance between
the Newton sequences for the continuous problem and the Newton sequence for the discretized
problem is O(h).
For simplicity, let us assume that if the continuous Newton process starts from the point
N , then the discrete Newton process starts from N (x 0
Also, suppose that for any xed
kN (w) N (v)k N ! kw vk 0 as N !1: (25)
In addition, let
where !N is dened in (23). Letting k tend to innity and assuming that N is a continuous
mapping for each N , Theorem 4.2 gives us the following estimate for the distance between the
solution xN of the discrete problem and the discrete representation N of the solution x
of the continuous problem:
Choose a real number " satisfying
where  is as in Theorem 3.1. Theorem 4.2 yields the following result:
Theorem 4.3. Let (25) and (26) hold and let " satisfy (28). Then for all N suciently
large,
Proof. Let m be such that
Choose N so large that1
!N < "=2
and
Using Theorem 3.1, Theorem 4.2, (27), and (31), we obtain
This means that if the continuous Newton sequence achieves accuracy " (measured by the
distance to the exact solution) at the m-the step, then the discrete Newton sequences should
achieve the same accuracy " at the (m 1)-st step or earlier. Now we show that the latter
cannot happen earlier than at the (m 1)-st step. Choose N so large that
and suppose that
>From Theorem 3.1, (24), (27), (30) and (31), we get
which contradicts the choice of " in (28).
5. Application to optimal control
We consider the following optimal control problem:
subject to _
U is a nonempty, closed and convex set
in IR m , and y 0 is a xed vector in IR n . L the space of essentially bounded and
measurable functions with values in IR m and W 1;1 (IR n ) is the space of Lipschitz continuous
functions with values in IR n .
We are concerned with local analysis of the problem (32) around a xed local minimizer
which we assume certain regularity. Our rst standing assumption is the following:
Smoothness. The optimal control u  is Lipschitz continuous in [0; 1]. There exists a positive
number  such that the rst three derivatives of ' and g exist and are continuous in the set
Dening the Hamiltonian H by
it is well known that the rst-order necessary optimality conditions at the solution (y
can be expressed in the following way: There exists  2 W 1;1
solution of the variational inequality
_
_
where NU (u) is the normal cone to the set U at the point u; that is, NU (u) is empty if u 62 U ,
while for u 2 U ,
Although the problem (32) is posed in L 1 and the optimality system (33){(35) is satised
almost everywhere in [0; 1], the regularity we assume for the particular optimal solution implies
that at (y  ; u  ;  ) the relations (33){(35) hold everywhere in [0; 1].
Dening the matrices
yy H(x  (t));
where z we employ the following coercivity condition:
Coercivity. There exists  > 0 such that
Let N be a natural number, let 1=N be the mesh spacing, let t
the forward dierence operator dened by
We consider the following Euler discretization of the optimality system (33){(35):
The system (37){(39) is a discrete-time variational inequality depending on the step size h. It
represents the rst-order necessary optimality condition for the following discretization of the
original problem (32):
subject to y 0
In this section we examine the following version of the Newton method for solving the variational
system (37)-(39), which corresponds to the SQP method for solving the optimization
problem (40). Let x denote the k-th iterate. Let the superscript k and the
attached to the derivatives of H and G denote their values at x k
. Then the new
iterate x solution of the following linear variational inequality for
the variable
In [5],

Appendix

2, it was proved that the coercivity condition (36) is stable under the Euler
discretization, then the variational system (41){(43) is equivalent, for x k near x
to the following linear-quadratic discrete-time optimal control problem which is expressed in
terms of the variables y, u, and z = (y; u):
minimize
(y N y k
r z ' k
subject to y 0
A natural stopping criterion for the problem at hand is the following: Given " > 0, a
control ~
obtained at the k-th iteration is considered an "-optimal solution if
dist(r u H(~y k
where ~
i and ~
i are the solutions of the state and the adjoint equations (37) and (38) corresponding
to
We now apply the general approach developed in the previous section to the discrete-time
variational inequality (37){(38). The discrete L 1
N norm is dened by
The variable x is the triple (y; u; ) while X N is the space of all nite sequences x
with y 0 given, equipped with the L 1
norm. The space Y N is the Cartesian product L 1
N corresponding to the four components of the function fN dened by
r
With the choice (x
the general condition (A1) is satised by taking
(z
The rst component of z
N is estimated in the following way:
sup
sup
ih
Since g is smooth and both y  and u  are Lipschitz continuous, the above expression is bounded
by O(h). The same bound applies for the second component of z
N , while the third and fourth
components are zero. Thus the norm of z
N can be made arbitrarily small for all suciently
large N . Condition (A2) follows from the smoothness assumption. A proof of condition (A3)
is contained in the proof of Theorem 6 in [5]. Applying Theorems 3.1 and 4.1 and using the
result from [5], Appendix 2, that the discretized coercivity condition is a second-order sucient
condition for the discrete problem, we obtain the following theorem:
Theorem 5.1. If Smoothness and Coercivity hold, then there exist positive constants K,
" and
N with the property that for every N >
N there is a unique solution (y
of the variational system (37){(39) and (y h ; u h ) is a local minimizer for the discrete problem
(40). For every starting point (y
there is a unique SQP sequence (y k ; u Q-quadratically convergent, with a constant
K, to the solution (y In particular, for the sequence of controls we have
Moreover, if the stopping test (44) is applied with an " 2 [0;
"], then the resulting "-optimal
control u k" satises
Note that the termination step k " corresponding to the assumed accuracy of the stopping
test can be estimated by Theorem 4.1. Combining the error in the discrete control with
the discrete state equation (37) and the discrete adjoint equation (38), yield corresponding
estimates for discrete state and adjoint variables.
Remark. Following the approach developed in [5] one can obtain an analog of Theorem
5.1 by assuming that the optimal control u  is merely bounded and Riemann integrable in
[0; 1] and employing the so-called averaged modulus of smoothness to obtain error estimates.
The stronger Lipschitz continuity condition for the optimal control is however needed in our
analysis of the mesh independence.
The SQP method applied to the continuous-time optimal control problem (32) has the
following starting point, the iterate x
_
_
for a.e. t 2 [0; 1], where the superscript k attached to the derivatives of H and G denotes
their values at x k . In particular, (45){(48) is a variational inequality to which we can apply
the general theory from the previous sections. We attach the index to the continuous
problem and for
fy
is clearly satised with Condition (A2) follows from
the Smoothness assumption. The condition (A3) follows from the Coercivity assumption as
proved in [9], Lemma 3 (see also [4], Section 2.3.4 for an earlier version of this result in the
convex case). Hence, we can apply Theorem 3.1 obtaining that for any suciently small ball
around x  (in the norm of X 0 ), if the starting point x 0 is chosen from B, then the SQP
method produces a unique sequence x k 2 B which is Q-quadratically convergent to x  (in the
norm of X 0 ). Moreover, from Theorem 4.1 we obtain an estimate for the number of steps
needed to achieve a given accuracy.
In order to derive a mesh-independence result from the general theory, we rst study the
regularity of the SQP sequence for the continuous problem.
Lemma 5.1. There exist positive constants p and q such that for every x
continuous in [0; 1], for every
Proof. In [5], Section 6, extending a previous result in [7], see also [6], Lemma 2, we showed
that the coercivity condition implies pointwise coercivity almost everywhere. In the present
circumstances, the latter condition is satised everywhere in [0; 1]; that is, there exists a
constant  > 0 such that for every v 2 U U and for all t 2 [0; 1]
For a positive parameter p consider the SQP sequence x k starting from x
the initial control u 0 is a Lipschitz continuous function in [0; 1]. Throughout the proof we will
choose suciently small and check the dependence of the constants of p. By (48) the iterate
(r
uy H(x k (t))(y k+1 (t) y k (t))
for every t 2 [0; 1] and for every u 2 U . Let t are contained in B p (x  )
for all k and therefore both y 0k and 0k are bounded by a constant independent of k; hence,
y k and k are Lipschitz continuous function in time with Lipschitz constants independent of
k. We have from (50)
(r
uy
and the analogous inequality with t 1 and t 2 interchanged. Adding these two inequalities
and adding and subtracting the expressions r 2
uy
where the function  k is dened as
By (49), for a suciently small p the right-hand side of the inequality (51) satises
Combining (51) and (52) we obtain
uy
uy
uy
Let u k be Lipschitz continuous in time with a constant L k . Then the function  k is almost
everywhere dierentiable and its derivative is given by
_
>From this expression we obtain that there exists a constants c 1 , independent of k and t and
bounded from above when p ! 0, such that
Estimating the expressions in the right-hand side of (54) we obtain that there exists a constant
independent of k and t and bounded from above when p ! 0, such that
Hence, u k+1 is Lipschitz continuous and, for some constants c of the same kind as c 1 ; c 2 , its
Lipschitz constant L k+1 satises
Since p can be chosen arbitrarily small, the sequence L i.e. by a
constant q. The proof is complete.
To apply the general mesh-independence result presented in Theorem 4.2 we need to estimate
the residual r k
obtained when the SQP sequence of the continuous problem is substituted
into the relations determining the SQP sequence of the discretized problem. Specically, the
residual is the remainder term associated with the Euler scheme applied to (45){(48); that is,
where the subscript i denotes the value at t i . From the regularity of the Newton sequence
established in Lemma 5.1, the uniform norm of the residual is bounded by ch, where c is
independent of k. Note that the map N (x) dened in Section 4, acting on a function x
gives the sequence x(t i Condition (25) is satised because the space X 0 is a
subset of the space of continuous functions. Summarizing, we obtain the following result:
Theorem 5.2. Suppose that Smoothness and Coercivity conditions hold. Then there exists
a neighborhood W, in the norm of X 0 , of the solution x such that for all
suciently small step-sizes h, the following mesh-independence property holds:
sup
where u k () is the control in the SQP sequence (y k (); u k (); k ()) for the continuous problem
starting from a point x continuous in [0; 1], and u k
h is
the control in the SQP sequence (y k
h ) for the discretized problem starting from the point
Applying Theorem 4.3 to the optimal control problem considered we obtain the mesh-
independence property (29) which relates the number of steps for the continuous and the
discretized problem needed to achieve certain accuracy. The latter property can be also easily
deduced from the estimate (55) in Theorem 5.2, in a way analogous to the proof of Theorem
4.3. Therefore the estimate (55) is a stronger mesh-independence property than (29).

Table

1: L 1 error in the control for various choices of the mesh.
Iteration

Table

2: Error in current iterate divided by error in prior iterate squared.
Iteration
5. Numerical examples
The convergence estimate of Theorem 5.2 is illustrated using the following example:
minimize
dt
subject to _
This problem is a variation of Problem I in [8] that has been converted from a linear-quadratic
problem to a fully nonlinear problem by making the substitution and by adding
additional terms to the cost function that degrade the speed of the SQP iteration so that the
convergence is readily visible (without these additional terms, the SQP iteration converges to
computing precision within 2 iterations). Figures 1{3 show the control iterates for successively
ner meshes. The control corresponding to barely visible beneath the
Observe that the SQP iterations are relatively insensitive to the choice of the mesh. Specically,
suciently large to obtain mesh independence. In Table 1 we give the L 1
error in the successive iterates. In Table 2 we observe that the ratio of the error in the current
iterate to the error in the prior iterate squared is slightly larger than 1.
Figure

1. SQP iterates for the control with

Figure

3. SQP iterates for the control with

Figure

2. SQP iterates for the control with



--R


Discretization and mesh-independence of Newton's method for generalized equa- tions
The Lagrange-Newton method for state constrained optimal control problems

Lipschitzian stability in nonlinear control and optimiza- tion

Variants of the Kuhn-Tucker sucient conditions in cones of non-negative functions
Dual approximations in optimal control
Multiplier methods for nonlinear optimal control
Mesh independence of the gradient projection method for optimal control problems
Augmented Lagrangian-SQP techniques and their approxima- tions
Mathematical programming: the state of the art (Bonn


--TR

--CTR
Steven J. Benson , Lois Curfman McInnes , Jorge J. Mor, A case study in the performance and scalability of optimization algorithms, ACM Transactions on Mathematical Software (TOMS), v.27 n.3, p.361-376, September 2001
