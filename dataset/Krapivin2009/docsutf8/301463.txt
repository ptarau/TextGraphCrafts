--T
On learning algorithms and balancing loads in Time Warp.
--A
We present, in this paper, an algorithm which integrates flow control and dynamic load balancing in order to improve the performance and stability of Time Warp. The algorithm is intended for use in a distributed memory environment such as a cluster of workstations connected by a high speed switch. Our flow control algorithm makes use of stochastic learning automata and operates in the fashion of the leaky-bucket flow control algorithm used in computer networks. It regulates the flow of messages between processors continuously throughout the course of the simulation, while the dynamic load balancing algorithm is invoked only when a load imbalance is detected. Both algorithms make use of a space-time product metric and collect the requisite information via a snapshot-based GVT algorithm.We compare the performance of the flow control algorithm, the dynamic load balancing algorithm and the integrated algorithm with that of a simulation without any of these controls. We simulated large shuffle ring networks with and without hot spots and a PCS network on an SGI Origin 2000 system.Our results indicate that the flow control scheme alone succeeds in greatly reducing the number and length of rollbacks as well as the number of anti-messages, thereby increasing the number of non-rolled back messages processed per second. It results in a large reduction in the amount of memory used and outperforms the dynamic load balancing algorithm for these measures. The integrated scheme produces even better results for all of these measures and results in reduced execution times as well.
--B
Introduction
The synchronization algorithm for Time Warp [9] involves
rolling the simulation back to a previous state if
an event arrives at a simulation object (an LP, or logical
process) with a timestamp which is smaller than that
of a previously processed event. In order to accomplish
this, Time Warp periodically records checkpoints of the
state of the simulation and sends out anti-messages,
whose function it is to cancel events which resulted from
the arrival of a straggler (out-of-order) message.
It is well known that optimistic simulations can consume
a large amount of memory and be subject to
an explosive growth in the number of rollbacks during
the course of a simulation. The large demands on
memory stem from checkpointing the state, sending an
anti-message for each output message, and storing input
messages which might later have to be canceled.
Both of these problems have been the subject of much
attention in the research literature.
One approach to these problems has been trying to
restrain the optimism of the simulation [18] via a global
synchronization barrier. In this approach [16], a window
of virtual time is defined within which it is permissible
to simulate events at LPs provided that they do
not violate causality constraints.
In probabilistic algorithms each LP determines a
blocking period. The amount of time which an LP
spends in a blocked state can be determined by estimates
of the time at which the next event will arrive
or by comparing the costs of rolling back with blocking
[8], or by comparing the frequency and cost of rollbacks
[2].
A different approach has been via memory manage-
ment. The objective of memory management is the
reclamation of space from existing objects when fossil
collection does not reclaim sufficient space so that the
simulation may be allowed to continue. These techniques
include cancelback [10], artificial rollback [11],
and adaptive memory management [6].
In an attempt to prevent a simulation from running
out of memory and increase processor utilization,
dynamic load balancing algorithms transfer LPs from
heavily loaded processors to lightly loaded ones [3, 1, 4].
A number of metrics have been used to evaluate load,
including virtual time progress, the number of non-
rolled back events per second [1] and queue length. [7]
contains a comparison of the efficacy of three of these
metrics.
In [14], the authors use a moving window in the same
fashion as computer networks. A queuing model is used
to determine an initial window size, which is adjusted
during the course of the simulation depending on its
performance. In a shared memory environment, an integration
of this approach with the adaptive memory
management scheme is also described.
The algorithm described in this paper combines a
flow control algorithm with a dynamic load balancing
algorithm. The flow control algorithm is executed on a
continuous basis, regulating the message traffic between
pairs of communicating processors. The algorithm assigns
a pool of tokens to each (one way) message flow.
In order to send a message, a processor must first acquire
a token. When the token pool is depleted, the
processor is blocked. The number of tokens in the pool
is dynamically updated throughout the course of the
simulation by means of a stochastic learning algorithm.
The metric which we use is the space-time product at
a processor (defined in the next section). Our dynamic
load balancing algorithm is employed when, in spite of
the use of flow control, a load imbalance is discovered.
A condition for load imbalance is checked at each GVT
cycle.
Our algorithm is targeted towards the use of distributed
memory architectures, such as the use of clusters
of workstations connected by high-speed switches.
By contrast, [14] combines memory management and
flow control in a shared memory environment.
Section 2 of this paper contains a description of the
algorithm(s) as well as some background information
on stochastic learning automata, section 3 describes our
experiments, and the final section contains our conclusions

2 The Algorithm
We make use of the space-time product as our metric
for our flow control and dynamic load balancing
algorithms. We define the space-time product of
each processor at real time t as follows: ST i
NEvents is the number of events,
NStates is the number of states, sizeof(event) and
are the respective size of an event and a
state, and LGV T i is the minimum LVT at processor P i .
The objective of our algorithm is to control the differences
between the space-time products of the processors
involved in the simulation. More precisely, we
require that
where ffic is the maximum allowable difference between
two processors and P is a set of processors. In
using the space-time product, we are attempting to balance
both the memory used by the processors and to
keep the processors close to one another in virtual time
in order to reduce the possibility of rollbacks.
2.1 Flow control
Our flow control scheme is similar to the "leaky bucket"
scheme [17] used in computer networks where a counter
is associated with each channel. Whenever a packet is
sent, the counter is increased. If the counter increases
above a fixed threshold, arriving packets are discarded.
In our algorithm, each processor is first assigned a
number of tokens (or permits). In order to send a message
to another processor, a processor makes use of a
token, i.e. each time it sends a message, the processor
decreases its alloted token pool by one. A separate
pool of tokens is assigned to a processor corresponding
to each of the other processors. The number of tokens
in each of these pools is varied dynamically throughout
the course of the simulation.
We determine the number of tokens assigned to a
processor by means of stochastic learning automata
[13]. An SLA consists of stochastic automaton
and its surrounding environment, as shown in figure 1.
Environment
Response
Input
Input
x
Action
a
F
{ ,p,G}
A
Stochastic Automaton

Figure

1: Stochastic Learning Automaton
In order to make use of SLA in a flow control al-
gorithm, we must answer the following questions. (1)
What is the nature of the control model, i.e. how do
the automata interact with one another? (2) Which
reinforcement scheme should be used? (3) How often
should the reinforcement scheme be invoked?
We provide answers to each of these questions in
turn.
Control model
Our control model consists of a collection of automata
such that each automaton resides within a processor,
and cooperates with the remaining automata to control
the flow of messages. Figure 2 contains a portrayal
of our model, where A i (t) is defined as the number
of events which arrive during the interval [t; t+1)
and D i (t-1) the number of departing events during
the interval [t-1; t). By defining a "regulation factor"
is the maximum number of messages
which processor P i may transmit to other processors,
is the number of tokens assigned to
processor P i at the next interval [t; t+1):
l
l (t)
Environment
A (t)
A (t)

Figure

2: Feedback response between processor P i and
its environment
Reinforcement scheme
We adopted an S-model with an linear reward-inaction
scheme (SL RI ) as a reinforcement scheme, based on
[12]. The S-model takes continuous values over an interval
[0,1]. The probability that processor P i sends a
message to processor P k at time t is denoted by p i;k (t)
where
,N-1. The essence
of our flow control scheme is the computation of the
token generation probability p i;j (t); i 6= j for each destination

Our equation for updating p i;d (t), where d is the destination
processor, is as follows:
F j;d (t)p j;d (t)]g;
(2)
where G(t) is defined as the "gain" for an automaton
and
automata are
involved in the simulation. Each automaton has N-1
actions and receives responses from the rest of proces-
sors. We define the regulation factor as the ratio of
We define F i;d (t) as the normalized environment response
from the destination processor P d at processor
F i;d
where the space-time product ST i;i of processor P i
at real time t is expressed as ST i;i
NEvents
NEvents is the number of events, NStates the number
of states in processor P i , and LGV T i is the minimum
LVT in processor P i . The space-time product at
each processor is piggybacked onto each message sent
to another processor.
ST i;d (t) is the most recent value of processor P d 's
space-time product ST d;d (t) (piggybacked on messages
sent to P i ), and STmax
is the maximum space-time product of the
simulation system monitored at processor P i at time
t. F i;d was defined in this manner to reflect the space-time
difference between processors P i and P d . Its value
is constrained to lie between 0 and 1 because environ-
ment's response in an SLA must be between 0 and 1.
In effect, equation (2) assigns a new value to p i;d
in proportion to the difference between F i;d and the
average of the other F j;d 's, j 6= i.
If ST i;i (t) - ST i;d (t), then F i;d (t) is equal to one. If
progressing faster
than P d or P i consumes more space than P d . We would
like processor P i to acquire more tokens in this case. If
we interpret this to mean that P d is
progressing faster than P i or it requires more memory
than P i . Then we would like to assign fewer tokens to
the sending processor P i in order to reduce the number
of outgoing messages. Thus the value of F i;d is less
than 1. It is important to recall that the assignment of
tokens to processor P i will not just depend on F i;d , but
will also depend upon the mean of the F j;d 's, j 6= d.
The gain G(t) for an automaton is computed in the
following manner. In our SL RI model, G(t) at each
processor is adjusted depending upon its space-time
product's closeness to the average value ST . When
the automaton which is residing on a processor has a
space-time product close to the average ST , G(t) at the
processor will be assigned a value which is close to 1.
When the automaton has its st farther away from ST ,
the value of G(t) will be assigned a lower value because
control by the automaton is considered to be ineffective.
We derived G(t) by modifying Chebyshev's theorem as
follows:
oe and jst \Gamma
In expression (5), when st is within oe of ST , then
G(t) is equal to 1. When st is farther away from the
average value of ST , G(t) at processor P i will be diminished
in proportional to the difference jst
Updating interval
Action probabilities are periodically updated to reflect
responses from the environment. The elapsed time or
a number of received responses may be used as a basis
for defining the interval. Updating the probabilities
too frequently may cause computational overloads
for the learning automata, in spite of reflecting recent
responses from the environment. On the other hand,
infrequent updating may provide obsolete information,
inadequate to choose an optimal action from the action
set.
In our model, action probabilities are updated when
the assigned token number is decreased to 0 or when
some fixed number (here, 500) of events is received at
the processor.
2.2 Dynamic load balancing
A number of dynamic load balancing algorithms have
appeared in the literature [3, 15, 1, 4]. They differ from
one another in several important ways among which
are: the metric which they employ to balance the load,
the way in which information pertaining to the value
of the metric is collected, the number LPs chosen to
migrate and the manner in which they are chosen.
A number of metrics have been employed in distributed
load balancing algorithms. Examples of these
metrics include the number of events in an input queue,
the rate of processed events at each processor, virtual
time progress, and effective utilization. We make use of
the space-time product (as previously defined) as our
metric.
Our algorithm migrates load from the heavily loaded
processor(s) to the most lightly loaded processor. We
rely on our GVT algorithm [5] to provide information
about the space-time product to all of the processors
involved in the simulation. In particular, it provides the
minimum space-time product st min with its processor
id. pid min , an average space-time product value ST ,
and its standard deviation oe. Each processor actually
makes use of an exponentially smoothed version of its
space-time product, st n (t+1) as ffst n (t)+(1 \Gamma ff)
st n (t)
(here, in order to minimize the fluctuation of
its space-time product.
It is not clear that the mean value ST and its standard
deviation oe given by the GVT computation will
follow a normal distribution because the number of processors
employed in a simulation is too small (e.g., 6).
Hence, we use Chebyshev's theorem in which the proportion
of observations falling within z standard deviation
units with mean ST is at least
where
oe . If each processor has its st within ST \Sigma zoe
2oe, then the probability
of st existing between ST \Sigma 2oe is 0.75 1 . Therefore,
we invoke dynamic load balancing when the condition
are
The choice of which LPs to migrate depends upon
the granularity of the LPs, the amount of traffic between
neighboring LPs, and the connectivity of the LPs.
We chose to migrate a group of 10 LPs at each transfer,
based upon experimental results. In our research, LPs
which have close topological relations with LPs residing
on the destination processor (pid min ) are the only ones
chosen for migration.
2.3 Integrated scheme - Flow control
and Dynamic load balancing
The flow control and dynamic load balancing algorithms
both have the same intention, that of keeping
the space-time product of the processors close to one
another throughout the course of the simulation, i.e.
our definition of balancing the workload. In attempting
to improve the performance and the stability of our
system, we integrate both of these schemes in a complementary
fashion. In our integrated scheme both of the
algorithms are executed independently of one another.
The flow control algorithm exerts control continuously
on the outgoing messages from a processor as determined
by the action probabilities. The action probabilities
are regularly updated as described above. On the
other hand, the dynamic load balancing algorithm can
be executed at each GVT cycle depending on whether a
sufficiently large load imbalance is detected. Hence the
intention of the integrated scheme is to allow the flow
control to balance the load to the extent that it can.
In the event that a sufficiently large load imbalance is
still detected during the course of a GVT computation,
the load balancing algorithm is invoked to rectify the
imbalance.
2.4 GVT computation
Our GVT algorithm plays an important part in the
gathering and dissemination of information for our load
balancing algorithms. It is an extension of Mattern's algorithm
[5] which relies upon techniques used to build a
global snapshot (consistent cuts) to compute the GVT.
An approximate proportion within - \Sigma 2oe in a normal distribution
is .955.
In [5], we show that it has a superior performance to
that of Mattern's algorithm as well as to Bellenot's and
algorithms.
3 Simulation results
3.1 Applications
In this section we compare the performance of the flow
control, the distributed load balancing algorithm and
the integrated algorithm with one another to a simulation
without any form of control. We make use of
the Snapshot(1) GVT algorithm described in [5] in all
of our simulations. The simulations were executed on
an SGI Origin 2000, which consists of 8 64-bit R10000
processors and 256 MB of memory per processor.
We simulated shuffle ring networks and a PCS net-work
[5]. The shuffle ring network shown in figure 3 is
obtained by modifying a shuffle exchange network. We
modified a shuffle exchange network by interconnecting
nodes in the first and last column and substituting one
of the input buffers with a local source and one of the
output buffers with a local sink. The topology gets its
name from this modification.
0,3

Figure

3: 4x4 Shuffle Ring Network
The PCS is a wireless communication network which
provides communications for mobile users. The service
area is divided into cells, each of which has a transmitter
with a fixed number of channels. A regular hexagon
is used to represent a cell. When a user makes a call,
a channel is assigned to the user. If all channels are
allocated, the call is blocked. If a user moves from one
cell to another during a call, a new channel is allocated
to provide for a continuation of the call.
In our simulation, LPs correspond to cells, and each
cell has 500 channels. Calls can be static or mobile. The
velocity of a mobile call is assumed to be constant, and
its direction can be chosen from one of six direction -
east, southeast, southwest, west, northwest, northeast.
The velocity and direction of a call are chosen from
a uniform distribution and the call completion time is
determined by an exponential distribution with a mean
of 300. The cell diameter is fixed at 1 km.
We used an hexagonal mesh topology which wraps
the hexagonal mesh (H-mesh) into a homogeneous
graph with an in- and out-degree of six as shown in
figure
Figure

4: Wrapped hexagonal mesh with n=3
3.2 Comparisons
In order to compare each algorithm, we made use of the
following performance measures: (1) simulation time,
(2) memory used, (3) number and length of rollbacks,
(4) number of anti-messages.
We simulated the following size networks - a 125x125
SRN (57,862 LPs), a 200x200 SRN (146,672 LPs), and
a PCS H(80) (56,884 LPs). In the PCS H(80) network,
the number of cells on each peripheral edge of the mesh
is equal to 80.
Both uniform and non-uniform load distributions
were used in the simulation. In order to create a non-uniform
load distribution, we made use of "hot spots",
or LPs with mean service times equal to one third of
the mean service times at the other LPs. Exponential
service times were used. The hot spots are randomly
distributed throughout the network.
3.3 Experimental results
Rollbacks
We present results for the number of rollbacks, the
length of a rollback and the number of anti-messages
produced during the course of a simulation. Table 1
contains the number of rollbacks for each scheme as
well as the percentage difference between each scheme
and a simulation without any form of control. Results
are presented for the 125x125 SRN with and without
hot spots, the 200x200 SRN with hot spots and the
PCS.
2 The links of edge cells are not depicted in this figure.

Table

1: Rollback number at SRN networks and a PCS network
Network type % % %

Table

2: Anti-messages at SRN networks and a PCS network
Network type % % %
We see that flow control results in fewer rollbacks
than does dynamic load balancing in all of the networks
simulated except for the 125x125 SRN without
hot spots. The integrated scheme exhibits the best per-
formance, with a reduction in the number of rollbacks
ranging from 19-52%.
In tables 2 and 3, the number of anti-messages and
the rollback lengths are recorded. Both tables reveal
similar results. Flow control results in fewer anti-messages
than does dynamic load balancing. The roll-back
length is also shorter than that which results
from dynamic load balancing except in the case of the
125x125 SRN. The integrated scheme results in the
best performance reducing the rollback length by 8-
59%, while the number of anti-messages are reduced
by between 15-91%.
The reason that the flow control scheme has a greater
success than the dynamic load balancing scheme lies in
the fact that when clusters of LPs are moved between
processors, it is necessary to temporarily halt the sending
of messages to the LPs in the cluster. This results
in longer message delays, increases the probability of a
rollback occurring and increasing the length of a roll-back
when it occurs. In addition, some LPs which formerly
communicated with one another in a processor
must now make use of inter-processor links, again resulting
in larger message delays. The flow control algo-
rithm, on the other hand, reacts in a more incremental
fashion than does the dynamic load balancing algorithm
and does not cause an interruption in processing while
it shifts LPs.
The exception to this observation is the 125x125
SRN without hot spots, in that it does not reduce the
number of rollbacks as much as dynamic load balancing
does. The reduction in the rollback length is close
to that obtained by dynamic load balancing, although
both are relatively small reductions. The reason for this
different behavior is to be found in the nature of the
simulations. The 125x125 SRN simulation exhibits a
more balanced behavior than do the other simulations.
The other two simulations have hot spots and the PCS
simulation, by its nature, experiences a shifting of load
between groups of LPs.
The reason for the success of the integrated scheme is
its judicious combination of flow control and dynamic
load balancing. The flow control scheme reduces the
frequency with which the dynamic load balancing algorithm
needs to be called as well as the number of
LPs which need to be transferred to balance the load.
Since it is based on a learning algorithm, it is sensitive
to changes in the load distribution between the processors

Goodput
We define the goodput to be the rate of the number
of processed non rolled-back events in the simulation.
Analogous to the throughput of a computer network, it
is intended to be a measure of the progress a simulation
is making in simulated time, and hence a measure of the
stability of the simulation.

Table

4 contains a comparison of the goodputs for
our three algorithms as well as the uncontrolled simu-
lation. The table contains results for simulations of the
125x125 and 200x200 SRN's with hot spots and the
PCS.
The patterns established when we examined roll-backs
and anti-messages again assert themselves. Flow
control establishes itself as being superior to dynamic
load balancing. The integrated algorithm produces better
results than do dynamic load balancing or flow control
for the SRN simulations. However, it produces
results which are intermediate between the other two

Table

3: Rollback distances at SRN networks and a PCS network
Network type % % %

Table

4: Average goodput at SRN networks and a PCS network
Network type evts./sec evts./sec % evts./sec % evts./sec %
SRN 200x200 (25%) 24,272.9 24,578.2 1.3 28,815.9 18.7 28,915.4 19.1
methods for the PCS simulation. This is because the
processing load shifts during the course of the PCS simulation
and the dynamic load balancing portion of the
integrated algorithm suspends the sending of messages
during the transfer of LPs between processors. In the
end, the integrated scheme produces goodputs which
are 10-21% better than the uncontrolled version of Time
Warp.
The improvements in goodput generated by the flow
control and the integrated algorithms is a result of the
reduction in the number and length of the rollbacks and
the consequent decrease in the number of anti-messages.
Memory

Table

5 contains results for the average amount of memory
used for the three schemes as well as for the simulation
operating without control.
As has been the case so far, we see that flow control
performs better than dynamic load balancing, and the
integrated scheme gives the best performance. The integrated
scheme saves 13-20% of the memory used by
the uncontrolled scheme.
We note that the simulation for the 200x200 SRN
uses less memory than the 125x125 SRN simulation.
The reason for this is that a smaller GVT was used for
the termination condition for the 200x200 SRN simulation

Execution times
The simulation times of the three schemes and the uncontrolled
scheme are contained in table 6. Once again,
the percentage differences from the uncontrolled scheme
are included in the table.
In all cases the integrated scheme provides the best
performance with a 13-23% range of improvements
when compared to the uncontrolled scheme. On examining
this table, we note that flow control does not
produce the same level of improvements which we have
previously observed. This is because the flow control
also regulates the sending of messages, necessarily increasing
the delays associated with them. Hence the
savings in execution time which results from a decrease
in the number and length of rollbacks is somewhat mit-
igated. In the integrated algorithm the dynamic load
balancing algorithm reduces the reliance upon the flow
control algorithm, producing the best results.
Our results indicate that the flow control scheme succeeded
in reducing the number and length of rollbacks
as well as the number of anti-messages, thereby increasing
the goodput of the simulation. In short, the
flow control algorithm serves to increase the stability
of Time Warp. The combination of flow control and
dynamic load balancing had a more pronounced effect
than flow control or dynamic load balancing alone. This
suggests that the algorithm did indeed act in a complementary
fashion. The dynamic load balancing algorithm
transferred load when the flow control algorithm
could not manage to keep the space-time products sufficiently
close to one another. By reducing the need
to invoke dynamic load balancing, the flow control algorithm
decreased the number of times LPs had to be
transferred between processors. When LPs are trans-
ferred, it is necessary to suspend the sending of messages
by LPs involved in the transfer, resulting in an
increase in the number and length of rollbacks as well
as the number of anti-messages which are sent.
In order to validate the usefulness of these algo-
rithms, it will be necessary to test them in the context
of simulations of real system. We hope to have this
opportunity in the near future.

Table

5: Used memory at SRN networks and a PCS network
Network type bytes bytes % bytes % bytes %

Table

Simulation progress at SRN networks and a PCS network
Network type sec. sec. % sec. % sec. %



--R

"The Dynamic Load Balancing of Clustered Time Warp for Logic Simulation"
"The Adaptive Time-Warp Concurrency Control Algorithm"
"Load Balancing Strategies for Time Warp on Multi-User Workstations"
"Background Execution of Time Warp Programs"
"An Efficient GVT Computation using Snapshots"
"An Adaptive Memory Management Protocol for Time Warp Parallel Simulation"
"Dynamic Load Balancing for Clustered Time Warp"
"Estimating Rollback Overhead for Optimism Control in Time Warp"
"Virtual Time"
"Virtual Time II: The Cancelback Protocol for Storage Management in Time Warp"
"Reducing the State Saving Overhead for Time Warp Parallel Simulation"
"Learning Automata Models for Adaptive Flow control in Packet-Switching Networks"
"Learning Automata - A Survey"
"Adaptive Flow Control in Time Warp"
"Dynamic Load Balancing of a Multi-Cluster Simulator on a Network of Workstations"
"SPEEDES: Synchronous Parallel Environment for Emulation and Discrete Event Simulation"
"New Directions in Communications (or Which Way to the Information Age?)"
"Performance Evaluation of the Bounded Time Warp Algorithm"
"On the behaviour of stochastic automata with a variable structure"
--TR
Virtual time
Virtual time II: storage management in conservative and optimistic systems
An adaptive memory management protocol for Time Warp parallel simulation
Dynamic load balancing of a multi-cluster simulator on a network of workstations
Background execution of time warp programs
The dynamic load balancing of clustered time warp for logic simulation
Adaptive flow control in time warp
Estimating rollback overhead for optimism control in Time Warp

--CTR
Tapas K. Som , Robert G. Sargent, Model structure and load balancing in optimistic parallel discrete event simulation, Proceedings of the fourteenth workshop on Parallel and distributed simulation, p.147-154, May 28-31, 2000, Bologna, Italy
Johannes Lthi , Steffen Gromann, The resource sharing system: dynamic federate mapping for HLA-based distributed simulation, Proceedings of the fifteenth workshop on Parallel and distributed simulation, p.91-98, May 15-18, 2001, Lake Arrowhead, California, United States
Herv Avril , Carl Tropper, On Rolling Back and Checkpointing in Time Warp, IEEE Transactions on Parallel and Distributed Systems, v.12 n.11, p.1105-1121, November 2001
Ewa Deelman , Boleslaw K. Szymanski, Simulating spatially explicit problems on high performance architectures, Journal of Parallel and Distributed Computing, v.62 n.3, p.446-467, March 2002
Boon Ping Gan , Yoke Hean Low , Sanjay Jain , Stephen J. Turner , Wentong Cai , Wen Jing Hsu , Shell Ying Huang, Load balancing for conservative simulation on shared memory multiprocessor systems, Proceedings of the fourteenth workshop on Parallel and distributed simulation, p.139-146, May 28-31, 2000, Bologna, Italy
