--T
The Value Function of the Singular Quadratic Regulator Problem with Distributed Control Action.
--A
We  study  the regularity properties of the value function  of  a quadratic  regulator problem for a linear  distributed  parameter system   with   distributed  control  action.   No   definiteness assumption on the cost functional is assumed. We  study  the regularity  in  time  of the value function and  also  the  space regularity in the case of a holomorphic semigroup system.
--B
Introduction
. In this paper we are concerned with a general class of finite
horizon linear quadratic optimal control problems for evolution equations with distributed
control and non-definite cost. More precisely, we consider the following
abstract differential equation over a finite interval [-; T
where A is the infinitesimal generator of a strongly continuous semigroup e At on a
Hilbert space X , B is a linear bounded operator from the control space U to X . With
the dynamics (1.1), we associate the cost functional
F
is the mild solution to equation (1.1) and F is the quadratic
(we denoted by h\Delta; \Deltai inner products in both the spaces X and U ). All the operators
Q, S, R and P 0 contained in the functional (1.2) are linear bounded operators in the
proper spaces, with
. We define as usual the value function
of the problem:
The goal of the present work is
ffl to characterize the property
This research was supported by the Italian Ministero dell'Universit'a e della Ricerca Scientifica e
Tecnologica within the program of GNAFA-CNR.
y Dipartimento di Matematica Applicata, Universit'a di Firenze, Via S. Marta 3, 50139 Firenze,
Italy (fbucci@dma.unifi.it).
z Dipartimento di Matematica, Politecnico di Torino, Corso Duca degli Abruzzi 24, 10129 Torino,
Italy (lucipan@polito.it), partially supported also by HCM network CEC n. ERB-CHRX-CT93-
ffl to study the regularity properties of the map
on the interval [0; T ], when x 0 is fixed.
We shall consider also the map x in a special case, see x6. It is well
known that if the regulator problem is standard, i.e.
then the solution to the operator Riccati equation corresponding to problem (1.1)-
(1.2) provides the synthesis of the unique optimal control. This problem is well
understood, both in finite and infinite dimensions, over a finite or infinite time horizon
(compare [10], [2, 3]).
The purpose of this paper is to examine the case when (1.5) fails, with special interest
in non-coercive R. We shall see that in this case the function
mild regularity properties, see x4. More regularity is obtained in the coercive case,
see x5.
The study of LQR problems with non-definite cost is related to a large variety
of problems. Among them, we recall the study of dissipative systems (see [20]), the
analysis of the stability of feedback systems ([14]), the analysis of second variations
of non-linear optimization problems (see [5], [15]). When game theory is studied
for linear systems then the quadratic form (1.3) is non-positive. In particular, the
suboptimal H 1 -problem can be recast in this setting ([1]). Finally, very recently
singular control theory has been used to obtain new results on regular control problems
for some class of boundary control systems: systems with input delays first [16], and
later systems described by wave- or plate-like equations with high internal damping
[9].
We recall that the existing results for finite dimensional systems over an infinite
time interval ([19, 21], see also [4]) were extended to distributed systems in [22, 23,
12, 13, 8]. If T ! +1 the only work we know in an infinite dimensional context,
in which a nonpositive cost functional is studied, is [6]. This paper considers even
time-varying systems, but under the restriction
2. A simple example. The interest of the results presented in this paper is
justified by the possible applications that we already quoted, for instance to H 1 -
control theory over a finite time interval, or to the analysis of the second variation
of general cost functionals. However the following example may help the reader to
understand our problem. The example is a bit artificial, since we want to present
a very simple one. Nevertheless it is suggested by non trivial problems in network
theory.
A delay line in its simpler form is described by an input-output relation
and the integral is a Stieltjes integral.
For simplicity we assume that the input u(\Delta) is continuous, a condition that can be
very much relaxed.
The simplest case described by (2.1) is
and corresponds to a jump function j, with jump at \Gamma1. If the system is started at
then the input (2.1) is read only for t ? 0, so that the output v(\Delta) from (2.1) is
given by
The function OE describes the "initial state" of the system (quite often it will be
In the case of equation (2.2) we have in particular
Notice that if OE(\Delta) and u(\Delta) are regular then v(t; solves the first order
hyperbolic equation
The function v can be interpreted as a delayed potential at the output of the network
produced by the potential u(\Delta) at the input. If the delay line is connected to a resistive
load, it produces a current
and the energy disspated by the load in
time T is given by
Z
Since
then
The energy that the load can dissipate is at most
u(\Delta)
We see from this that the load dissipates a finite amount of energy V (OE) if T ! 1,
described by the quadratic functional
Z
Otherwise, the load can dissipate as much energy as we want.
Hence it makes sense to study the energy function E(T )
In this example the function E(T ) is finite only if T ! 1, and in this case E(T ) is the
quadratic functional (2.3).
In this paper we consider an analogous problem in more generality: we study the
dependence on the interval [-; T ] of the "energy" dissipated by a certain linear time
invariant system.
4 F. BUCCI AND L. PANDOLFI
3. Preliminary results. We recall that the solution to (1.1) is
with
e A(t\Gammas) Bu(s) ds;
continuous
Note that t ! (L - u)(t) is a X-valued continuous function.
The adjoint L
- of
is given by
(L
e A   (s\Gammat) f(s) ds;
continuous
Introduce also the bounded operator from U to X
e A(T \Gammas) Bu(s) ds
(which describes the map (3.1) from the input u to the solution of (1.1) at time
with initial time - and x 0). The adjoint of L -;T is the map given by
(L
Using (3.1), one can easily show the following
Lemma 3.1. The cost functional (1.2) can be rewritten as
with
selfadjoint, defined as follows
(R
We first state a Lemma, which will be useful later.
Lemma 3.2. If there exists - 0 and a constant fl such that
then R - fl I for any - 0 .
Proof. It is sufficient to notice that if - 0 we can write
where v(\Delta) is given by . Hence, from (3.7)
it follows that R - fl I for any - 2 [-
We shall use the following general result pertaining continuous quadratic forms
in Hilbert spaces whose proof is given for the sake of completeness.
Lemma 3.3. Let X and U be two Hilbert spaces, and consider
with
1. If there exists x 2 X such that
u2U
2. The infimum of f(x; \Delta) is attained if and only if the equation
is solvable and in this case any solution u of (3.8) gives a minimum.
3. If for each x 2 X there exists a unique u x such that
f(x;
then R is invertible (the inverse R \Gamma1 may not be bounded) and u
so that the transformation x ! u x is linear and continuous from X to U .
4. Let us assume that V (x) ? \Gamma1 for each x 2 X. Then there exists a linear
bounded operator P 2 L(X) such that
Proof. If there exists v such that hRv; vi ! 0 then f(x;
This proves the first item of the Lemma. The second item is well known ([23, Lemma
2.3]). To prove the third item we use item 2: the minimum u x is characterized by (3.8).
This equation is uniquely solvable for every x by assumption. Hence, ker
and im N ' im R. Consequently, acts from the closure
of the image of R. Hence, R \Gamma1 N is bounded since R \Gamma1 is closed and N is bounded.
The proof of the fourth item follows an approach in [7]. If R is coercive, then
it is boundedly invertible, so that f(x; \Delta) admits a unique minimum, namely
\GammaR
Hence, (3.9) holds true and we have obtained an explicit expression for P , i.e.
If we simply have R - 0, we consider the function
6 F. BUCCI AND L. PANDOLFI
Now
n I is coercive, hence
Vn
with Pn 2 L(X). By construction
is a decreasing numerical sequence for any x 2 X , and
hence there exists P 2 L(X) such that
To conclude, it remains to show that V (x) coincides with hx; Pxi for any x 2 X .
Assume by contradiction that V (x) ! hx; Pxi for a given x 2 X , and let ff ? 0 such
that
there exists u 2 U such that
Correspondingly, there exists an integer n 0 2 IN such that
From (3.11) and (3.12) it follows
which is a contradiction, compare (3.10).
The above lemma and (3.3) imply a first necessary condition for finiteness of the
value function.
Lemma 3.4. If there exists x 0 such that V (-; x
This observation is now used to obtain a necessary condition of more practical interest,
which is well known in the finite dimensional case. The symbol I denotes the identity
operator acting on a space which will be clear from the contest.
Proposition 3.5. If there exists - 0 2 [0; T ) and a constant fl - 0 such that
Consequently,
if there exists x 0 and - 0 such that V (-
(3.
Proof. We first consider the case hence by assumption R -0 - 0. By
contradiction, suppose that there exists a control u 0 2 U and a constant ff ? 0 such
that \Gammaff. Given a small ffl ? 0, choose a control u as follows:
ae
and compute
e A(t\Gammas) Bu 0 ds;
e A(t\Gammas) Bu 0 dsi dt
e A(T \Gammas) Bu 0 ds;
e A(T \Gammas) Bu 0 dsi dt
tends to 0:
Since ffl can be taken arbitrarily small, (3.15) yields hR -0 u; ui ! 0, and this contradicts
the assumption.
Assume instead R -0 - fl I ? 0. By choosing
direct computation yields
which implies hRu
Finally, if V (- , then from Lemma 3.4
it follows that R - is a non-negative operator for - 0 . Therefore from the previous
part of the proof, R - 0.
We now show that the value function satisfies the Bellmann's optimality principle
which is known, in the context of linear-quadratic problems, as "Linear Operator
Inequality" (LOI) or "Dissipation Inequality" (DI).
We begin with the following
Lemma 3.6. If for some number - and some x
then we have also V (t; denotes the value
at time t of the function given by (3.1), for any fixed control u(\Delta) on [-; t].
Proof. Let
ds
ds
F
now a control v j 0 on [-; t):
then
ds
8 F. BUCCI AND L. PANDOLFI
and
ds
Conclusion immediately follows since in fact
Theorem 3.7. Let - 2 [0; T ] and x 0 2 X be given. Let V be the value function
of problem (1.1), (1.2) and assume that V (-; x
ds
for any u(\Delta) 2 L 2 (-; T ; U) and any t 2 (-; T ), with Moreover, the
equality holds true if and only if the control u in(3.17) is optimal.
Proof. We return to the conclusion of the preceding Lemma, and observe again
that
while
hence plugging (3.18) into (3.16) and taking into account (3.19), we get
F
which is nothing but (3.17). Thus, if for a given initial datum x 0 there exists an
optimal control u then we can rewrite (3.16) and (3.19)
with is in fact an equality. Therefore (3.20) becomes an
equality as well. For these arguments compare also [11].
Viceversa, assume that (3.17) is satisfied for any control u 2 L 2 (-; T ; U) and it is an
equality for a given u   . Then, passing to the limit, as
and assuming for the moment that
lim
we readily get
ds
that is
hence by definition u   is optimal.
To conclude, it remains to show that if (x   ; u   ) satisfies
ds
then (3.21) holds true. From (3.22) it follows that there exists
lim
and by the very definition of the value function it follows
lim
To see this rewrite the above limit as
lim
By contradiction, assume now that
lim
where fl is a suitable positive constant. Then, there exists
for any t 2 Recall now that
hence we can rewrite
ds
ds
A3
Take a possibly smaller ffi, in order to get
so that (3.23) yields
Finally, let ffi such that
hQe A(s\Gammat) x   (t); e A(s\Gammat) x   (t)ids
Fix now t 2 (T \Gamma ffi; T ), so that (3.24) and (3.26) hold true. From (3.25) it follows
that there exists a control such that
that is, by means of (3.3),
with M t , N t , R t defined in (3.4), (3.5) and (3.6), respectively. We know that
R T
ds. Thus we cancel the
term A 1 , we take into account (3.26) and we obtain
In particular this implies that v t 6= 0. Notice now that
const \Deltajv t (\Delta)j 2
and therefore
lim inf
Hence there exists a sequence t n such
so that we see from (3.27) for n largejv t n
In other words J t n
this is a contradiction since by assumption J - (0; u)
is non-negative for any u 2
The next Proposition is an immediate consequence of Lemma 3.1 and of Lemma
3.3. We omit the proof.
Proposition 3.8. Let - 2 [0; T ]. If
there exists a selfadjoint operator W (\Delta) 2 L(X) such that W (T
4. Time regularity of the value function: the non-coercive case. In this
section we investigate the regularity properties of V (-; x 0 ) with respect to the initial
time - .
We note that several regularity results are known for the value function even
of non-linear systems, and with more general cost but under special boundedness
properties, which are not satisfied in the present case, compare [11, Ch. 6].
Our first result is:
Lemma 4.1. Let - be such that V (-
upper semicontinuous at - 0 .
Proof. Fix In order to show that
lim sup
we shall show that for any real number ff ? V (-
is taken small enough. We first consider the case when - 0 . Let u be an admissible
control such that
and define
e A(t\Gammas) Bu(s) ds:
It is readily verified that
1: lim
2: lim
ds
so that if
Finally, if - 0 , choose once more in such a way that (4.1) holds
true. It is now sufficient to repeat tha same arguments used before, after replacing u
with -
u defined as follows:
The proof is complete.
As to lower semicontinuity, the following result holds true.
Lemma 4.2. Let x 0 be such that is finite on [0; T ]. Then
ffl the map lower semicontinuous at - 0 provided that for each
element - n of a sequence f- n g which tends monotonically to - 0 there exists a
control such that
ii) there exists
Proof. Let be given, and consider a sequence f- n gn2I N such that - n # - 0 .
Introduce the inputs
and define
Notice that x -n
x -n (t) ! 0, as n !1, for any t, and that its norm is uniformly
bounded in L 2 (-
lim
Therefore
lim inf
where the last equality is due to i). On the other hand ii) implies the existence of an
admissible such that
as n !1. Now the map
is convex continuous, hence weakly lower semi-continuous, so that
To conclude the proof, we need to consider a sequence fr n gn2I N such that r n " - 0 . In
this case, we introduce
~
ae
Again from ii) it follows that there exists an input v 2 L 2 (- such that ~
in similar argument gives
which finally yields
Consequently, we can conclude
Theorem 4.3. Under the same assumptions as Lemma 4.2, the map - !
continuous for any - 2 [ 0; T ].
In the case that an optimal control exists for each - near - 0 , Lemma 4.2 takes
a simpler form. We state this form, under the assumption that an optimal control
exists for each - .
Corollary 4.4. Let x 0 2 X be fixed. Assume that
there exists an optimal control u
ii) there exists a constant fl ? 0, independent of - , such that
(4.
Under these conditions, the map
We note explicitly that if there exists an optimal control u   for J -
each there exists an optimal control for J - 0 (x(-
It has some interest to see that if the operator A generates a strongly continuous
group then we can prove more:
Theorem 4.5. Let us assume that for each - 2 [0; T ) and each x 0 2 X there
exists a unique optimal control u At is a
strongly continuous group then the value function is continuous from the right.
Proof. We prove continuity from the right at a fixed - We know from
Lemma 3.3 item 2 that x
linear and continuous from X to L 2 (-;
for each - 2 [0; T ).
Now we consider points - 0 . We show that for each fixed - 0 there exists
It is sufficient to see for this that there exists a solution x 1 of
e A(- \Gammas) Bu
If this is true, unicity of the optimal control shows that (4.5) holds.
We noted above that ku so that the norm of the
operator
e A(- \Gammas) Bu ds
can be estimated as follows: kT x 1
We write Eq. (4.6) in the form
sufficiently small, is less then 1 hence Eq. (4.7) can be
continuously solved for x 1 and gives a linear continuous transformation x
which, of course, depends upon - . The vector x 1 ,
is continuous with respect to x 0 and also with respect to - if - is close to - 0 . In
bounded in a neighborhood of - 0 . Therefore,
Right continuity follows from Lemma 4.2.
The previous theorem presents a case in which the quite involved condition of
Lemma 4.2 is satisfied. The next example shows that the condition in that lemma
cannot be avoided if we are to obtain continuity of the value function.
We note first that the value function is not continuous in general, even for finite
dimensional systems: if the cost is jx(T )j 2 and the system is controllable then the
14 F. BUCCI AND L. PANDOLFI
value function has a jump at T . The following example shows that the value function
may be discontinuous even at points - ! T .
Example 4.6. Consider the delay system given by
with initial datum OE 0 =col[x 0). The quadratic functional is
Consequently
In particular J 1
On the other hand, if and it can be
arbitrarily fixed, by means of suitable choices of the control u, within the class of
W 1;2 functions which are zero at 1. This set is dense in L
suitable functions y can be found in order to drive x(t) to zero in time ffl ? 0, namely
remaining uniformly bounded. Therefore we have that
In conclusion, if and the value function is not continuous
at
Remark 4.7. The previous example shows that in the statement of Lemma 4.2-
which concerns lower semicontinuity of V (-; x 0 )-assumption ii) cannot be dispensed
with. In fact that assumption holds in the previous example for but not for
5. Time regularity of the value function: the coercive case. Let - 2 [0; T
be given, and consider the operator R -
- as defined in (3.6). Throughout this section
we shall assume that R - is coercive, i.e.
Our present goal is to show that under assumption (5.1) the value function V (-; x 0 )
displays better regularity properties with respect to - . We start by showing that the
is continuous for any - 2
We recall that from (5.1), by virtue of Lemma 3.2, it follows that R - fl for any
by continuity also on an interval (- Hence there exists a
constant fl 0 such that
Moreover (5.1) implies that for any initial time there exists a unique
optimal control u
- (\Delta) for short ), explicitly given in terms of the
initial state by
(compare item 3 of Lemma 3.3); and from (5.2) it follows
independent of - :
The following Theorem provides a simple explicit expression of the value function in
terms of the optimal pair which will be useful in the next section.
Theorem 5.1. Let R - be coercive, and let
pair for problem (1.1)-(1.2). Then
e A   (t\Gamma- )
dt:
Proof. Since the infimum of the cost is attained at
- for short),
plugging (5.3) into (3.3) we easily obtain
The adjoint operator N
)-function v in
e A   (t\Gamma- ) ((Q
hence (5.5) follows from (5.6) by a direct computation.
As a consequence of Corollary 4.4, we first have
Theorem 5.2. Let x 2 X be given. Assume that(5.1) is satisfied. Then - !
is continuous on [- ; T ].
Actually we are able to show that the value function satisfies a further regularity
property. Before we state a preliminary result.
Lemma 5.3. Assume that R - is coercive. If w(\Delta) is a continuous function, then
the function
(R
is continuous for any -
- .
In particular, if R - is coercive then the optimal control is continuous.
Proof. Since R -
- is coercive, R is coercive, so that we can assume that R = I .
Moreover, for any - , R - is coercive, hence invertible.
Let OE(t) := (R \Gamma1
- w)(t), with w(\Delta) continuous: we know that OE(\Delta) is at least an U -
valued
e A   (s\Gammat) Q
e A(s\Gammar) BOE(r) dr ds
e A(t\Gammas)
e A   (s\Gammat) SOE(s) ds
e A(T \Gammas) BOE(s) ds;
and the second hand side is apparently an U -valued continuos function.
The second statement follows from (5.3) since (N - x 0 )(\Delta) is a continuous function,
compare (3.5).
Theorem 5.4. Let x 2 D(A) be given. Assume that (5.1) is satisfied. Then the
differentiable in [- ; T ].
Proof. Let x
optimal control of
problem (1.1)-(1.2), -
- . As in (5.6)
with M - and N - given by (3.4), (3.5), respectively.
From the very definition of M - it readily follows that the derivative @
@-
exists for any x 0 2 D(A). In order to show that the the second summand in (5.8),
namely
is differentiable with respect to - , we first observe that the factor (N - x 0 )(\Delta) is differ-
entiable, with
@
Moreover, again from (3.5) it follows that (5.10) is a continuos function.
We next want to show that for each t ? - the U -valued function
first derivative with respect to - and that this is continuous. Fix - 0 and consider first
the case - 0 . Introduce the operator -
defined as follows:
By construction
and for instance
Moreover, we take into account (5.10) and we see that
lim
In fact it is sufficient to observe that
Now we compute, via

The first summand in (5.12) tends to
@
'-
, due to (5.11).
As to the second summand, it can be rewritten in the following way:
e A   (s\Gammat) Q 1
e
a(-;s)
ds
We rewrite, in turn,
e
(r)dr
c(-;s)
Observe now that as a consequence of Lemma 5.3 we have
lim
while lim - +c(-;
Finally, since (-; s) ! a(-; s) is bounded, we can conclude that 1 converges to
\GammaR
e A   (s\Gammat) Qe A(s\Gamma-
as - tends to -
. The convergence of the terms 2 and 3 can be proved even more
easily.
If - 0 we define instead
and rewrite the term R \Gamma1
(R
-0 (R -0
The rest of the proof is completely similar.
Therefore we have proved that for each - there exists @
- (t) and that
@
e A   (s\Gammat) Qe A(s\Gamma-
ds
\GammaR
In conclusion we saw that the function (N - x 0 )(t)
- (t) is differentiable with respect
to - , and moreover its derivative is a continuous function in [-
Therefore (5.9) is differentiable, and
@
@-
We are now able to deduce a differential form of the Dissipation Inequality.
Proposition 5.5. Assume that (5.1) holds true. Then there exists a selfadjoint
operator W (\Delta) 2 L(X) such that
d
d-
for any (a; v) 2 D(A) \Theta U , for any - 2 [- ; T ].
Proof. We fix a 2 D(A), v 2 U , and take a control u(\Delta) 2 C 1 ([-; T ]; U) such that
u). It is well known (see for instance [2]) that in
this case x is a strict solution to (1.1), that is x
it satisfies (1.1) on [-; T ].
We write the dissipation inequality (3.17) for namely
F
If we divide in (5.15) by
d
ds
To conclude, substitute
We proved that if we replace an optimal pair in the left hand side of the dissipation
inequality in integral form, then we get an equality. Hence we get an equality also
in the differential form (5.14). In particular, we fix a 2domA and we see that
a) is a minimum of the left hand side of inequality (5.14). Hence we find
that
Since R is coercive then R is coercive too and we see that the optimal control has the
well known feedback form
(if a 2 D(A) and, by continuity, for each a 2 X , see item 3 of Lemma 3.3). Moreover,
as a)), the previous equality gives the feedback form of
the optimal control on the interval [0; T ]. We replace this expression for the unique
optimal control in the left hand side of (5.14) and we find a quadratic differential
equation for W (-) which is the usual Riccati equation.
Of course, the Riccati equation can be written provided that R \Gamma1 is a bounded
operator. But, an example in [6] shows that if R is not coercive then the minimum of
the cost may exist and be unique, in spite of the fact that the corresponding Riccati
equation is not solvable on [-; T ].
6. Space regularity of the value function. This section is devoted to the
study of some space regularity properties of the value function in the case that the
optimal control problem is driven by an abstract equation of parabolic type. See [17]
for analogous arguments. More precisely, we shall make the following assumption:
H1: A is the generator of an analytic semigroup e tA on X .
It is well known (see for instance [18]) that in this case there exists a ! 2 IR such
that the fractional powers are well defined for any ff 2 (0; 1), and moreover
there exist constants M ff , fi such that the following estimates hold true
(6.
20 F. BUCCI AND L. PANDOLFI
For the sake of simplicity we assume that the semigroup is exponentially stable, i.e.
that we can choose
We associate the following output to system (1.1):
where y belongs to a third Hilbert space Y and C 2 L(X; Y ),
assume that the cost penalizes the output y i.e. that the quadratic functional F in
(1.3) is given by
so that special and important case is
We now use similar arguments as in Lemma 3.3. Introduce a regularized optimal
control problem with cost given by
and observe that since the operator
n I is coercive for each n, then there
exists a unique optimal control u
n and
Vn
Arguing as in the proof of statement 4 in Lemma 3.3 we know that
(\Delta). Then we have the following
Lemma 6.1. Let assume that there
exists a number
Then there exists a constant c such that
Proof. The estimate is easily obtained as follows (note that 0 2 ae(A) since we
assumed
Remark 6.2. We stress that since
the estimate (6.4) is uniform with respect to n and - .
Lemma 6.3. Under the same assumptions of Lemma 6.1 there exists a constant
k such that
Proof. Let We recall that since by construction the operator R -;n relative
to Jn (- 0 ; u) is coercive for each fixed n, then the regularized control problem admits
a unique optimal pair
Theorem 5.1 yields
e A   (t\Gamma- ) C   y
The regularity assumptions on C and P 0 imply that Wn (-
Now, as a consequence of (6.4) there exists k such that
uniformly in n. Conclusion follows immediately by choosing -
Consequently we have the following
Theorem 6.4. Under the same assumptions of Lemma 6.1 the operator
admits a bounded extension to X for any fl !
.



--R


Representation and Control of Infinite Dimensional Systems

The Riccati equation
Singular Optimal Control: the Linear-Quadratic Problem
Linear quadratic optimal control of time-varying systems with indefinite costs on Hilbert spaces: the finite horizon problem
Spectral thoery of the linear quadratic optimal control problem: discrete-time single-input case
Equivalent conditions for the solvability of the nonstandard LQ-Problem for Pritchard-Salamon systems
A singular control approach to highly damped second-order abstract equations and applications
Differential and Algebraic Riccati Equations with Application to Boundary/Point Control Problems: Continuous Theory and Approximation Theory
Optimal Control Theory for Infinite Dimensional Systems
The frequency theorem for equations of evolutionary type
The Hilbert space regulator problem and operator Riccati equation under stabilizability
Some nonlinear problems in the theory of automatic control
Nonnegativity of a quadratic functional
The standard regulator problem for systems with input delays: an approach through singular control theory

Semigroups of Linear Operators and Applications to Partial Differential Equations
Least squares stationary optimal control and the algebraic Riccati Equation

The frequency theorem in control theory


--TR
