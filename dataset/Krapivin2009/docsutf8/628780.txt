--T
A Cooperative Algorithm for Stereo Matching and Occlusion Detection.
--A
AbstractThis paper presents a stereo algorithm for obtaining disparity maps with occlusion explicitly detected. To produce smooth and detailed disparity maps, two assumptions that were originally proposed by Marr and Poggio are adopted: uniqueness and continuity. That is, the disparity maps have a unique value per pixel and are continuous almost everywhere. These assumptions are enforced within a three-dimensional array of match values in disparity space. Each match value corresponds to a pixel in an image and a disparity relative to another image. An iterative algorithm updates the match values by diffusing support among neighboring values and inhibiting others along similar lines of sight. By applying the uniqueness assumption, occluded regions can be explicitly identified. To demonstrate the effectiveness of the algorithm, we present the processing results from synthetic and real image pairs, including ones with ground-truth values for quantitative comparison with other methods.
--B
Introduction
Stereo vision can produce a dense disparity map. The resultant disparity map
should be smooth and detailed; continuous and even surfaces should produce a region of
smooth disparity values with their boundary precisely delineated, while small surface
elements should be detected as separately distinguishable regions. Though obviously
desirable, it is not easy for a stereo algorithm to satisfy these two requirements at the
same time. Algorithms that can produce a smooth disparity map tend to miss the details
and those that can produce a detailed map tend to be noisy.
For area-based stereo methods [13], [18], [29], [7], [2], [12], which match
neighboring pixel values within a window between images, the selection of an
appropriate window size is critical to achieving a smooth and detailed disparity map.
The optimal choice of window size depends on the local amount of variation in texture
and disparity [20], [2], [6], [21], [12]. In general, a smaller window is desirable to avoid
unwanted smoothing. In areas of low texture, however, a larger window is needed so
that the window contains intensity variation enough to achieve reliable matching. On the
other hand, when the disparity varies within the window (i.e., the corresponding surface
is not fronto-parallel), intensity values within the window may not correspond due to
projective distortion. In addition to unwanted smoothing in the resultant disparity map,
this fact creates the phenomena of so-called fattening and shrinkage of a surface. That
is, a surface with high intensity variation extends into neighboring less-textured surfaces
across occluding boundaries.
Many attempts have been made to remedy these serious problems in window-based
stereo methods. One earlier method is to warp the window according to the
estimated orientation of the surface to reduce the effect of projective distortion [23]. A
more recent and sophisticated method is an adaptive window method [12]. The window
size and shape are iteratively changed based on the local variation of the intensity and
current depth estimates. While these methods showed improved results, the first method
does not deal with the difficulty at the occluding boundary, and the second method is
extremely computationally expensive. A typical method to deal with occlusion is bi-directional
matching. For example, in the paper by Fua [6] two disparity maps are
created relative to each image: one for left to right and another for right to left. Matches
which are consistent between the two disparity maps are kept. Inconsistent matches
create holes, which are filled in by using interpolation.
The fundamental problem of these stereo methods is that they make decisions
very locally; they do not take into account the fact that a match at one point restricts
others due to global constraints resulting from stereo geometry and scene consistency.
One constraint commonly used by feature-based stereo methods is edge consistency [22],
[14]; that is, all matches along a continuous edge must be consistent. While constraining
matches using edge consistency improves upon local feature-based methods [1], [26],
they produce only sparse depth maps.
The work by Marr and Poggio [15], [16] is one of the first to apply global
constraints or assumptions while producing a dense depth map. Two assumptions about
stereo were stated explicitly: uniqueness and continuity of a disparity map. That is, the
disparity maps have unique values and are continuous almost everywhere. They devised
a simple cooperative algorithm for diffusing support among disparity estimates to take
advantage of the two assumptions. They demonstrated the algorithm on synthetic
random-dot images. The application of similar methods to real stereo images has been
left largely unexplored probably due to memory and processing constraints at that time.
Recently, Scharstein and Szelski [27] proposed a Bayesian model of stereo matching. In
creating continuity within the disparity map, support among disparity estimates is non-linearly
diffused. The derived method has results similar to that of adaptive window
methods [12]. Several other methods [3], [8], [11] have attempted to find occlusions and
disparity values simultaneously using the ordering constraint along with dynamic
programming techniques.
In this paper we present a cooperative stereo algorithm using global constraints to
find a dense depth map. The uniqueness and continuity assumptions by Marr and Poggio
are adopted. A three-dimensional array of match values is constructed in disparity space;
each element of the array corresponds to a pixel in the reference image and a disparity,
relative to another image. An update function of match values is constructed for use with
real images. The update function generates continuous and unique values by diffusing
support among neighboring match values and by inhibiting values along similar lines of
sight. Initial match values, possibly obtained by pixel-wise correlation, are used to retain
details during each iteration. After the match values have converged, occluded areas are
explicitly identified.
To demonstrate the effectiveness of the algorithm we provide experimental data
from several synthetic and real scenes. The resulting disparity maps are smooth and
detailed with occlusions detected. Disparity maps using real stereo images with ground-truth
disparities (University of Tsukuba's Multiview Image Database) are used for
quantitative comparison with other methods. A comparison with the multi-baseline
method and the multi-baseline plus adaptive window method is also made.
2. A Cooperative Stereo Algorithm
Marr and Poggio [15], [16] presented two basic assumptions for a stereo vision
algorithm. The first assumption states that at most a single unique match exists for each
pixel; that is, each pixel corresponds to a single surface point. When using intensity
values for matching this uniqueness assumption may be violated if surfaces are not
opaque. A classic example is a pixel receiving contribution from both a fish and a fish
bowl. The second assumption states that disparity values are generally continuous, i.e.
smooth within a local neighborhood. In most scenes the continuity assumption is valid
since surfaces are relatively smooth and discontinuities occur only at object boundaries.
We propose a cooperative approach using disparity space to utilize these two
assumptions. The 3D disparity space has dimensions row r, column c and disparity d.
This parameterization is different from 3D volumetric methods [5], [17], [27], [28] that
use x, y, and z world coordinates as dimensions. Assuming (without loss of generality)
that the images have been rectified, each element (r, c, d) of the disparity space projects
to the pixel (r, c) in the left image and to the pixel (r, c+d) in the right image, as
illustrated in figure 1. Within each element, the estimated value of a match between the
pixels is held.
To obtain a smooth and detailed disparity map an iterative update function is used
to refine the match values. Let L d) denote the match value assigned to element (r,
c, d) at iteration n. The initial values d) may be computed from images using:
c
r
I
c
r
I
d
c
r
where d is an image similarity function such as squared differences or normalized
correlation. The image similarity function should produce high values for correct
matches, however the opposite does not need to be true, i.e. many incorrect matches
might also have high initial match values.
The continuity assumption implies neighboring elements have consistent match
values. We propose iteratively averaging their values to increase consistency. When
averaging neighboring match values we need a concept of local support. The local
support area for an element determines which and to what extent neighboring elements
should contribute to averaging. Ideally, the local support area should include all and only
those neighboring elements that correspond to a correct match if the current element
corresponds to a correct match. Since the correct match is not known beforehand, some
assumption is required on deciding the extent of the local support. Marr and Poggio, for
example, used elements having equal disparity values for averaging - that is, their local
support area spans a 2D area (d=const.) in the r-c-d space. This 2D local support area
corresponds to the fronto-parallel plane assumption. However, sloping and more general
surfaces require using a 3D area in the disparity space for local support. Many 3D local
support assumptions have been proposed [9], [25], [26], [12]; Kanade and Okutomi [12]
present a detailed analysis of the relationship and differences among them. For simplicity
we use a box-shaped 3D local support area with a fixed width, height and depth, but a
different local support area could be used as well.
Current d)
Inhibition Area, y(r, c, d)
d)

Figure

Illustration of the inhibitory and support regions between elements for a 2D slice of the 3D
disparity space with the row number held constant.
Left Camera Right Camera
c)
Let us define S d) to be the amount of local support for (r, c, d), i.e. the sum
of all match values within a 3D local support area F.
d
c
r
d
c
c
r
r
d
c
r
, (2)
The uniqueness assumption implies there can exist only one match within a set of
elements that project to the same pixel in an image. As illustrated in figure 1 by dark
squares, let Y(r, c, d) denote the set of elements which overlap element (r, c, d) when
projected to an image. That is, each element in Y(r, c, d) projects to pixel (r, c) in the left
image or to pixel (r, c+d) in the right image. With the uniqueness assumption, Y(r, c, d)
represents the inhibition area to a match at (r, c, d).
d) denote the amount of inhibition S d) receives from the
elements in Y(r, c, d). Many possible inhibition functions are conceivable; we have
chosen the following for its computational simplicity:
a
d
c
r
d
c
r
c
r
d
c
r
d
c
r
R
The match value is inhibited by the sum of the match values within Y(r, c, d). The
exponent a controls the amount of inhibition per iteration. To guarantee a single element
within Y(r, c, d) will converge to 1, a must be greater than 1. The inhibition constant a,
should be chosen to allow elements within the local support F to affect the match values
for several iterations while also maintaining a reasonable convergence rate.
Summing the match values within a local support in equation (2) can result in
oversmoothing and thus a loss of details. We propose restricting the match values
relative to the image similarity between pixel (r, c) in the left image and pixel d) in
the right image. In this way, we allow only elements that project to pixels with similar
intensities to have high match values (though pixels with similar intensity do not
necessarily end up with high match values.) The initial match values L 0 , which are
computed using a measure of intensity similarity, can be used for restricting the current
match values L n . Let T d) denote the value R d) restricted by L
d
c
r
R
d
c
r
d
c
r
Our update function is constructed by combining equations (2), (3) and (4) in their
respective order.
a

d
c
r
d
c
r
c
r
d
c
r
d
c
r
d
c
r
While our method uses the same assumptions as Marr and Poggio's, this update
function differs substantially. Using the current notation, the update function that Marr
and Poggio proposed is:
d
c
r
d
c
r
c
r
d
c
r
d
c
r
d
c
r
where s is a sigmoid function and e is the inhibition constant.
Marr and Poggio [15], [16] used discrete match values and a 2D local support for
F, possibly due to memory and processing constraints. Their results using synthetic
random-dot images with step function disparities were excellent. Since real stereo image
pairs have multiple intensity levels and sloping disparities, continuous match values and a
3D local support for F are needed. Marr and Poggio did not address the steps needed to
apply equation (6) to real stereo image pairs [24]. Equation (5) possesses two main
advantages over (6), in addition to supporting the use of real images. First, the values in
are restricted by the initial match values to maintain details. In (6) the initial values
are added to the current values to bias the results towards values which were initially
high. Since (6) does not restrict values that were initially low, oversmoothing and a loss
of details may still occur. Second, the inhibition function in (5) is simpler so a costly
sigmoid function does not need to be computed; for their experiments Marr and Poggio
actually used a threshold function instead of a sigmoid function due to processing
constraints.
3. Explicit Detection of Occluded Areas
Occlusion is a critical and difficult phenomena to be dealt with by stereo
algorithms. With any reasonably complex scene there exists occluded pixels that have no
correct match. Unfortunately most stereo algorithms do not consider this important case
explicitly, and therefore they produce gross errors in areas of occlusion or find disparity
values similar to the foreground or background. Several methods have attempted to
explicitly detect occlusions, including methods using intensity edges [10], multiple
cameras with camera masking [19] and bi-directional (left-to-right and right-to-left)
matching [6]. Recently, several stereo algorithms, Belhumeur and Mumford [3], Geiger,
Ladendorf and Yuille [8] and Intille and Bobick [11] have proposed finding occlusions
and matches simultaneously to help in identifying disparity discontinuities. By imposing
an additional assumption called the ordering constraint these methods have been able to
successfully detect occlusions. The ordering constraint states that if an object a is left of
an object b in the left image then object a will also appear to the left of object b in the
right image. While powerful, the ordering constraint assumption is not always true, and
is violated when pole-like objects are in the foreground.
In our algorithm we try to identify occlusions by examining the magnitude of the
converged match values in conjunction with the uniqueness constraint. Since no correct
match exists in areas of occlusion, all match values corresponding to occluded pixels
should be small. Consider a pixel p in the left image, whose correct corresponding point
is not visible in the right image. Referring to figure 2, for an element v of the array along
the line of sight of p, there are two cases that occur for its projection q on the right image.
The first case, depicted in figure 2(a), is when q's correct corresponding point is visible in
the left image. Then there exists an element v' which corresponds to the correct match
between a pixel p' in the left image and q. Since elements v and v' both project to pixel q,
their match values will inhibit each other due to the uniqueness assumption. Generally,
the correct element v' will have a higher match value, causing the value for element v to
decrease. The second case, depicted in figure 2(b), is a more difficult case. This occurs
when q's true corresponding element is occluded in the left image. Since neither p nor q
has a correct match, the value of a match between p and q will receive no inhibition from
elements corresponding to correct matches, and false matches could have high values. In
such cases additional assumptions must be made to correctly find occluded areas. The
ordering constraint could be one such assumption that may label these correctly as
occluded. However, a tradeoff exists; enforcing the ordering constraint could in turn lead
to other pixels being mislabeled as occluded. Due to this tradeoff we have chosen not to
enforce the ordering constraint.
In general, provided mutually occluded areas within the disparity range do not
have similar intensities, all match values corresponding to occluded pixels will be small.
After the match values have converged, we can determine if a pixel is occluded by
finding the element with the greatest match value along its line of sight. If the maximum
match value is below a threshold the pixel is labeled as occluded.
v'
Right
Image
Image
. q
Right
Image
Image
Occluded Surface
False Match
Non-occluded Surface
Correct Match

Figure

2;(a) If q is not occluded there is a correct match with p' which will inhibit the false match with p; (b) If q is occluded it
is possible for a false match to occur with p.
4. Summary of Algorithm
The cooperative algorithm is now summarized as follows:
1. Prepare a 3D array, (r, c, d): (r, c) for each pixel in the reference image
and d for the range of disparity.
2. Set initial match values L 0 using a function of image intensities, such
as normalized correlation or squared differences.
3. Iteratively update match values L n using (5), until the match values
converge.
4. For each pixel (r, c), find the element (r, c, d) with the maximum
match value.
5. If the maximum match value is higher than a threshold, output the
disparity d, otherwise classify it as occluded.
The running time for steps 1 through 5 is on the order of N 2 *D*I, where N 2 is the
size of the image, D is the range of disparities, and I is the number of iterations. The
amount of memory needed is on the order of N 2 *D. In practice the algorithm takes about
8 seconds per iteration with 256x256 images on a SGI Indigo 2ex.
5. Experimental Results
To demonstrate the effectiveness of our algorithm we have applied it to several
real and synthetic images. The input images are rectified. Initial match values are set by
using the squared difference of image intensities for each pixel. The squared difference
values were linearly adjusted so that their values distribute between 0 and 1. The
threshold for detecting occlusions was set constant for all image pairs at 0.005.
5.1 Random Dot Stereogram

Figure

3(a) and (b) present a synthetic random dot image pair with random noise.
A sinusoidal repetitive pattern is also inserted for part of the image to make it more
difficult. The disparity map shown in figure 3(c) has step-function as well as curved
disparities. The algorithm was run with three different sizes of local support (3x3x3,
5x5x3 and 7x7x3.) Table 1 shows the performance summary after 10 iterations.
Approximately 99% of the disparity values were found correctly for each size of local
support area. Pixels labeled occluded in the true disparity map are not used in computing
the disparity errors. A disparity is labeled as correct if it is within one pixel of the correct
disparity. It is worth noting that at the beginning of iteration one, only 35% of the
maximum initial matches L 0 that were computed using a local image intensity similarity
measure were correct. As observed in Figure 3(d), the disparity errors mainly occur
within the repetitive texture and at disparity discontinuities. We found, however, that if
enough iterations are completed, incorrect disparities due to repetitive textures are
completely removed [30]. Of the detected occlusions, 81% to 97% were indeed
occlusions and 58% to 80% of the true occlusions were found depending on local support
area size. Occlusions created by the three vertical bars, which violate the ordering
constraint, were found correctly. The inhibition constant a controls the convergence
properties of the algorithm. Figure 4 illustrates the convergence properties for different
values of a. Higher values for the inhibition constant lead to slightly faster convergence
with a minimal loss of accuracy.
5.2 U. of Tsukuba Data with Ground Truth
The University of Tsukuba's Multiview Image Database provides real stereo
image pairs with ground truth data. The ground-truth data allows us to do a quantitative
comparison between our method and others. Figure 5(a), (b) and (c) shows a stereo
image pair from the University of Tsukuba data with a ground-truth disparity map. In
this stereo pair, 59% of the maximum initial match values L 0 were correct. We tested our
algorithm using three different sizes of local support (3x3x3, 5x5x3, and 7x7x3) with the
inhibition constant set to 2. After 15 iterations, as shown in Table 2, at least 97% of the
disparities were found correctly over the range of local support area sizes. The best result
is a 1.98% disparity error for a 5x5x3 local support area. Most errors occurred around
less-textured object boundaries. Approximately 60% of the occlusions detected were
correct with 50% of the true occlusions found.
We allowed the match values to completely converge using 80 iterations. The
resulting disparity map is shown in Figure 5(d). Table 3 shows a detailed analysis of
correct and erroneous matches in the obtained disparity map. Of the 84,003 pixels
labeled non-occluded in the ground truth data, 82,597 pixels had the correct disparity,
1,121 had incorrect disparities and 285 were labeled as occluded using our algorithm. Of
the 1,902 pixels labeled occluded in the ground truth data, our algorithm labeled 860
correctly as occluded and 1,042 incorrectly as non-occluded. Ignoring the occlusion
labeling, of the 84,003 pixels labeled non-occluded in the ground truth data 1.44% had
incorrect disparity values of greater than one pixel using our algorithm. Table 4 shows a
comparison of various stereo algorithms on the U. of Tsukuba data. The GPM-MRF
algorithm [4] had approximately twice as many errors. The results of more standard
algorithms also provided by [4], had an error rate of 9.0% for LOG filtered L 1 and 10.0%
for normalized correlation. The University of Tsukuba group has obtained the best
results so far using multiple images (more than two) and camera masking [19] with errors
of 0.3% for 25 images and 0.9% for 9 images. The error results for the camera masking
method are evaluated on fewer pixels since the chance of a pixel being occluded
increases with the number of camera angles used.
5.3 CMU Coal Mine Scene

Figure

6 presents the stereo image pair of the "Coal Mine" scene and the
processing results. For comparison, the multi-baseline method [21] using sums of
squared differences and the adaptive window method [12] are applied to the image set.
The multi-baseline result (Figure 6 (f)) that uses three input images is clearly the noisiest
of the three. The result of the adaptive window approach (Figure 6 (g)) also using three
images is smooth in general, but a few errors remain. Especially, the small building
attached to the tower in the center of the image is not well delineated and the slanted roof
in the upper corner of the scene is overly smoothed. For our approach we used
normalized correlation within a 3x3 window to create the initial match values instead of
squared differences, since intensity values varied between the input images. The results

Figure

are smooth while recovering several details at the same time. The slanted
roof of the lower building and the water tower on the rooftop are clearly visible. Depth
discontinuities around the small building attached to the tower are preserved. 15
iterations were used and the inhibition constant was set to 2.
(a) (b)
(c) (d)

Figure

3: Synthetic Scene, 50% density; (a) Reference (left) image; (b) Right image; (c) True Disparity
black areas are occluded; (d) Disparity map found using 3x3x3 local support area, black areas are
detected occlusions.
Random Dot Stereogram
Area RxCxD
Correct
Correct
Found
3x3x3 99.44 97.11 79.61
5x5x3 99.29 95.41 71.05
7x7x3 98.73 81.10 58.42

Table

1: The percentage of disparities found correctly, the percentage of the detected occlusions that are
correct and the percentage of the true occlusions found for three different local support area sizes using the
random dot stereo pair.

Figure

4: Convergence rate for inhibition constant a of 1.5, 2 and 4 over 20 iterations using the random dot
stereogram.
(a) (b)
(c) (d)

Figure

5: Head scene provided by University of Tsukuba: (a) Reference (left) image; (b) Right image; (c)
Ground truth disparity map with black areas occluded, provided courtesy of U. of Tsukuba; (d) Disparity
map found using our algorithm with a 5x5x3 local support area, black areas are detected occlusions. The
match values were allowed to completely converge. Disparity values for narrow objects such as the lamp
stem are found correctly.
94.00%
95.00%
96.00%
97.00%
98.00%
99.00%
100.00%
Iterations
Disparities
Correct 1.54
a
U. of Tsukuba Stereo Image Pair
Area RxCxD
Correct
Correct
Found
5x5x3 98.02 66.58 51.84
7x7x3 97.73 63.23 44.85

Table

2: The percentage of disparities found correctly, the percentage of the detected occlusions that are
correct and the percentage of the true occlusions found for three different local support area sizes using the
U. of Tsukuba stereo pair.
Confusion matrix for the disparity map
obtained from U. of Tsukuba data.
Ground Truth
Occluded
Ground Truth
Non-occluded Total
Occluded 860 285 1,145
Non-Occluded 1,042
Correct
Incorrect
Total 1,902 84,003 85,905

Table

3: The number of occluded and non-occluded pixels found using our algorithm compared to the
ground truth data provided by University of Tsukuba. A 5x5x3 area was used for the local support and the
disparity values were allowed to completely converge.
Zitnick and Kanade
GPM-MRF [4]
LOG-filtered
Normalized correlation [4]
Nakamura et al. [19] (25 images)
Nakamura et al. [19]

Table

4: Comparison of various algorithms using the ground truth data supplied by University of Tsukuba.
rates of greater than one pixel in disparity are for pixels labeled non-occluded in the ground truth
data. GPM-MRF [4] has approximately twice the error rate of our algorithm. LOG-filtered L 1 and
Normalized correlation are supplied for comparison to more conventional algorithms. The University of
Tsukuba group provides their results using a 3x3 and 5x5 camera array. The error results for their method
use fewer pixels since the chance of a pixel being occluded increases with the number of camera angles
used.
(a) (b) (c)
(d) (e)

Figure

Coal mine scene; (a) Reference (left) image; (b) Right image; (c) Disparity map obtained by using
proposed method with a 3x3x3 local support area, black areas are detected occlusions; (d) Real oblique
view of the coal mine model; (e) Isometric plot of the disparity map of Figure 6(c); (f) Isometric plot of the
disparity map using multi-baseline stereo with three images as presented in [21]; (g) Isometric plot of the
disparity map using multi-baseline stereo with adaptive window with three images as presented in [12].
6. Conclusion
One of the important contributions of Marr and Poggio [15], [16], in addition to
the cooperative algorithm itself, is that they insisted the explicitly stated assumptions be
directly reflected in their algorithm. Many other stereo algorithms in contrast do not state
assumptions explicitly or the relationship between the assumptions and the algorithm is
unclear. In following Marr and Poggio's positive example we have attempted to directly
reflect the continuity and uniqueness assumptions in our algorithm. To find a continuous
surface, support is diffused among neighboring match values within a 3D area of the
disparity space. A unique match is found by inhibition between match values along
similar lines of sight. Additionally, after the values have converged, occlusions can be
explicitly identified by examining match value magnitudes.
As demonstrated by using several synthetic and real image examples, the resulting
disparity map is smooth and detailed with occlusions detected. The quantitative results
obtained using the ground truth data supplied by University of Tsukuba demonstrates the
improvement of our algorithm over other current algorithms.
7.

Acknowledgements

We would like to thank Dr. Y. Ohta and Dr. Y. Nakamura for supplying the
ground truth data from the University of Tsukuba.



--R

"Depth from edge and intensity based stereo,"
"Stereo Vision,"
"A bayesian treatment of the stereo correspondence problem using half-occluded regions,"
"Markov Random Fields with Efficient Approximations,"
"A space-sweep approach to true multi-image matching,"
"A parallel stereo algorithm that produces dense depth maps and preserves image features,"
Photogrammetric Standard Methods and Digital Image Matching Techniques for High Precision Surface Measurements.
"Occlusions and Binocular Stereo,"
"Computational experiments with a feature based stereo algorithm,"
"Incorporating intensity edges in the recovery of occlusion regions,"
"Disparity-space images and large occlusion stereo,"
"A stereo matching algorithm with an adaptive window: Theory and experiment,"
"Computer determination of depth maps,"
"A parallel binocular stereo algorithm utilizing dynamic programming and relaxation labelling,"
"Cooperative computation of stereo disparity,"
"A computational theory of human stereo vision,"
"Robot spatial perception by stereoscopic vision and 3D evidence grids,"
"An iterative prediction and correction method for automatic stereo comparison,"
"Occlusion detectable stereo - - Occlusion patterns in camera matrix,"
"Stereo vision for robotics,"
"A multiple-baseline stereo,"
"Stereo by intra- and inter-scanline search using dynamic programming,"
"A flexible approach to digital stereo mapping,"
"The Marr and Poggio algorithm for real scenes was not defined so any implementation will be a change; however the algorithm worked well on random-dot stereograms and there are several papers to support this."
"Pmf: A stereo correspondence algorithm using a disparity gradient limit,"
"Detection of binocular disparities,"
"Stereo matching with nonlinear diffusion,"
"Stereo matching with transparency and matting,"
"Realities of automatic correlation problem,"
"A volumetric iterative approach to stereo matching and occlusion detection,"
--TR

--CTR
Zheng-dong Liu , Ying-nan Zhao , Jing-yu Yang, Fast stereo matching method using edge traction, Intelligent information processing II, Springer-Verlag, London, 2004
S. Someya , K. Okamoto , G. Tanaka, 3D Shape Reconstruction from Synthetic Images Captured by a Rotating Periscope System with a Single Focal Direction, Journal of Visualization, v.6 n.2, p.155-164, April
Ayoub K. Al-Hamadi , Robert Niese , Axel Panning , Bernd Michaelis, Toward robust face analysis method of non-cooperative persons in stereo color image sequences, Machine Graphics & Vision International Journal, v.15 n.3, p.245-254, January 2006
Omni-Directional Stereoscopic Images from One Omni-Directional Camera, Journal of VLSI Signal Processing Systems, v.42 n.1, p.91-101, January   2006
Philip Kelly , Noel E. O'Connor , Alan F. Smeaton, Pedestrian detection in uncontrolled environments using stereo and biometric information, Proceedings of the 4th ACM international workshop on Video surveillance and sensor networks, October 27-27, 2006, Santa Barbara, California, USA
Heiko Hirschmller , Peter R. Innocent , Jon Garibaldi, Real-Time Correlation-Based Stereo Vision with Reduced Border Errors, International Journal of Computer Vision, v.47 n.1-3, p.229-246, April-June 2002
Qiuming Luo , Jingli Zhou , Shengsheng Yu , Degui Xiao, Stereo matching and occlusion detection with integrity and illusion sensitivity, Pattern Recognition Letters, v.24 n.9-10, p.1143-1149, 01 June
Steven M. Seitz , Jiwon Kim, The Space of All Stereo Images, International Journal of Computer Vision, v.48 n.1, p.21-38, June 2002
Minglun Gong , Yee-Hong Yang, Genetic-Based Stereo Algorithm and Disparity Map Evaluation, International Journal of Computer Vision, v.47 n.1-3, p.63-77, April-June 2002
L.-Q. Xu , B. Lei , E. Hendriks, Computer Vision for a 3-D Visualisation and Telepresence Collaborative Working Environment, BT Technology Journal, v.20 n.1, p.64-74, January 2002
Michael Bleyer , Margrit Gelautz, Graph-cut-based stereo matching using image segmentation with symmetrical treatment of occlusions, Image Communication, v.22 n.2, p.127-143, February, 2007
Gustavo Olague , Francisco Fernndez , Cynthia B. Prez , Evelyne Lutton, The Infection Algorithm: An Artificial Epidemic Approach for Dense Stereo Correspondence, Artificial Life, v.12 n.4, p.593-615, October 2006
Olga Veksler, Dense Features for Semi-Dense Stereo Correspondence, International Journal of Computer Vision, v.47 n.1-3, p.247-260, April-June 2002
Tim Burkert , Jan Leupold , Georg Passig, A photorealistic predictive display, Presence: Teleoperators and Virtual Environments, v.13 n.1, p.22-43, February 2004
Gang Li , Steven W. Zucker, Contextual Inference in Contour-Based Stereo Correspondence, International Journal of Computer Vision, v.69 n.1, p.59-75, August    2006
Sang Hwa Lee , Yasuaki Kanatsugu , Jong-Il Park, MAP-Based Stochastic Diffusion for Stereo Matching and Line Fields Estimation, International Journal of Computer Vision, v.47 n.1-3, p.195-218, April-June 2002
C. Lawrence Zitnick , Sing Bing Kang, Stereo for Image-Based Rendering using Image Over-Segmentation, International Journal of Computer Vision, v.75 n.1, p.49-65, October   2007
Changming Sun, Fast Stereo Matching Using Rectangular Subregioning and 3D Maximum-Surface Techniques, International Journal of Computer Vision, v.47 n.1-3, p.99-117, April-June 2002
Sing Bing Kang , Richard Szeliski, Extracting View-Dependent Depth Maps from a Collection of Images, International Journal of Computer Vision, v.58 n.2, p.139-163, July 2004
Myron Z. Brown , Darius Burschka , Gregory D. Hager, Advances in Computational Stereo, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.25 n.8, p.993-1008, August
Daniel Scharstein , Richard Szeliski, A Taxonomy and Evaluation of Dense Two-Frame Stereo Correspondence Algorithms, International Journal of Computer Vision, v.47 n.1-3, p.7-42, April-June 2002
