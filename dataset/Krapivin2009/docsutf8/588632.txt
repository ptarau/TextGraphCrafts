--T
Detection of Edges in Spectral Data II. Nonlinear Enhancement.
--A
We discuss a general framework for recovering edges in piecewise smooth functions with finitely many jump discontinuities, where $[f](x):=f(x+)-f(x-) \neq 0$. Our approach is based on two main aspects--- localization using appropriate concentration kernels and separation of scales by nonlinear enhancement. To detect such edges, one employs concentration kernels, $K_\epsilon(\cdot)$, depending on the small scale $\epsilon$. It is shown that odd kernels, properly scaled, and admissible (in the sense of having small $W^{-1,\infty}$-moments of order ${\cal O}(\epsilon)$) satisfy  recovering both the location and amplitudes of all edges. As an example we consider general concentration kernels of the form $K^\sigma_N(t)=\sum\sigma(k/N)\sin kt$ to detect edges from the first $1/\epsilon=N$ spectral modes of piecewise smooth f's. Here we improve in generality and simplicity over our previous study in [A. Gelb and E. Tadmor, Appl. Comput. Harmon. Anal., 7 (1999), pp. 101--135]. Both periodic and nonperiodic spectral projections are considered. We identify, in particular, a new family of exponential factors, $\sigma^{exp}(\cdot)$, with superior localization properties.  The other aspect of our edge detection involves a nonlinear enhancement procedure which is based on separation of scales between the edges, where $K_\epsilon*f(x)\sim [f](x) \neq 0$, and the smooth regions where  examples demonstrate that by coupling concentration kernels with nonlinear enhancement one arrives at effective edge detectors.
--B
Introduction
We discuss a general framework for recovering edges from the spectral projections of piecewise smooth
functions. Our approach for edge detection is based on two fundamental aspects - localization to
the neighborhood of the edges using appropriate concentration kernels and separation of scales by
nonlinear enhancement. Both the location and amplitudes of all edges are recovered.
Let SN f(x) denote the spectral projection of a piecewise smooth f . Given SN f , one can accurately
reconstruct f away from its discontinuous jumps, e.g., [10],[14, x2.1], as well as up to the
discontinuities, [11]. In either case, an a priori knowledge on the location of the edges and their
amplitudes is required. This issue was treated in recent literature, consult [1], [5], [13], [15]. In [7],
we unified the previous treatments as special cases of appropriate concentration kernels. Here we
improve on these results in both generality and simplicity. To this end, let [f ](x) :=
denote the local jump function and let us consider a concentration kernel K ffl (\Delta), depending on a small
scale ffl. It is shown that odd kernels, properly scaled, and admissible (- in the sense of having small
W \Gamma1;1 -moments of order O(ffl), (2.6)), recover both the locations and the amplitudes of the jumps
so that
Thus, K ffl tends to "concentrate" near the singular support of f .
Differentiation of ffl-supported mollifiers is one example for local concentration kernels outlined in
x2.2.1. In x2 we also address the issue of detecting edges in global Fourier projections. Given the
first modes, we seek concentration kernels of the form
K oe
sin kt:
It is shown that if the concentration factors oe(-) j -) are normalized so that
K oe
N (t) is an admissible concentration kernel, K oe
and the following error estimate
holds
-(
log N
The non-periodic case is studied in x3. The analogous results for the Chebyshev case reads, consult
Corollary 3.2
log N
The special cases of Fourier concentration factors oe ff (- sin ff- and oe p were considered
earlier in [1],[7],[9],[13], and [15]. Our general framework motivates a new set of C 1
-exponential
concentration factors which yield superior localization properties away from the detected edges.
While (1.1) refers to the asymptotic behavior of the concentration kernel as a function of the
small parameter ffl # 0, it is essential to recover the exact locations of the edges of f for the accurate
reconstruction of f . In x4 we discuss another essential aspect of edge detection, namely nonlinear
enhancement. To this end, one introduces a critical threshold, J crit , for the amplitude of admissible
edges, and an enhancement exponent, p, to amplify the separation of scales in (1.1) between the
edges, where K ffl   f(x) - [f ](x) 6= 0, and the smooth regions where K ffl
the enhanced kernel
Enhanced detection of edges in spectral data 3
ae
Clearly, with p large enough, one ends up with a sharp edge detector where K ffl;J [f at
all but O(ffl)-neighborhoods of the jump discontinuities. In this sense, the enhancement procedure
actually "pinpoints" the location jump discontinuities, allowing an accurate reconstruction of f . The
particular case corresponds to the quadratic filter studied in [12],[22], in the special context of
concentration kernels based on localized mollifiers.

Acknowledgment

. Research was supported in part by the Sloan Foundation (AG) and by NSF
Grant No. DMS97-06827 and ONR Grant No. N00014-1-J-1076 (ET).
Edge Detection by Concentration Kernels
2.1 Concentration Kernels
We want to detect the edges in piecewise smooth functions. Assume that f(\Delta) has jump discontinuities
of the first kind with well defined one-sided limits,
f(x\Gamma) denote the local jump function. By piecewise smoothness we mean 1
In practice one encounters functions f(x) with finitely many jump discontinuities, and (2.2)
requires the differential of f(x) on each side of the discontinuity to have bounded variation. For
example, if f 0 (x\Sigma) are well defined (for finitely many jumps), then (2.2) holds.
We will detect the edges in such piecewise smooth f 's using smooth concentration kernels,
depending on a small parameter ffl. Such kernels are characterized by
Thus the support of K ffl   f(x) tends to "concentrate" near the edges of f(x). One recovers both the
location of the jump discontinuities as well as their amplitudes.
To guarantee the concentration property of K ffl , we seek odd kernels,
which are normalized so that Z
and which satisfy the main admissibility requirement
Z
Const
Remarks.
1 Here and below we use BV [a; b] to denote the space of functions with bounded variation, endowed with the usual
semi-norm kOEk BV [a;b] := R b
a jOE 0 jdx
A. Gelb and E. Tadmor
1. For example, if K ffl (t) concentrates near the origin so that its first moment does not exceed
Z
Const \Delta ffl; (2.7)
then it is clearly admissible in the sense that (2.6) holds. We note that our admissibility
condition also allows for more general oscillatory kernels, K ffl (t), where (2.7) might fail, yet
(2.6) is satisfied due to the cancelation effect of the oscillations, consult (2.18 below.
2. Observe that the admissibility requirement (2.6) generalizes both properties P 3 and P 4 in the
definition of admissible kernel [7, definition 2.1].
Our main result states that
Theorem 2.1 Consider an odd kernel K ffl (t), (2.4), normalized so that (2.5) holds, and satisfying
the admissibility requirement (2.6). Then the kernel K ffl (t) satisfies the concentration property (2.3)
for all piecewise smooth f 's, and the following error estimate holds
Const \Delta ffl: (2.8)
Proof. Using the fact that K ffl (t) is odd, we have
Z
Z
Z
Applying (2.5) yields
Z
By our assumption in (2.2), F x (t) is BV and it is therefore bounded. Consequently, in the particular
case that the moment bound (2.7) holds, the first term on the right of (2.9) is of order O(ffl), yielding
Const \Delta
Z
In the general case, F x (t) has bounded variation, and the admissibility requirement (2.6) implies
that the first term on the right of (2.9) is of order O(ffl), and we conclude
2.2 Examples of Concentration Kernels
2.2.1 Compactly supported kernels
Our first example consists of concentration kernels which 'concentrate' near the origin, so that (2.7)
holds. We consider a standard mollifier, OE ffl (t) := 1
), based on an even, compactly supported
bump function, OE 2 C 1
We then set
Enhanced detection of edges in spectral data 5
Clearly, K ffl is an odd kernel satisfying the required normalization (2.5)
Z
Z
In addition, its first moment is of order
Z
Z
and hence (2.7) holds. Theorem 2.1 then implies
Corollary 2.1 Consider the odd kernel K ffl
ffl (t), based on even OE 2 C 1
Then K ffl (t) satisfies the concentration property (2.3), and the following error estimate holds
2.2.2 The conjugate Dirichlet kernel
The conjugate Dirichlet kernel,
log N
~
sin kt;
is an example of an oscillatory concentration kernel. Clearly, KN (t) is an odd kernel. Moreover, the
normalization (2.5) holds with ffl - 1
log N ,
log N
log N
Finally, summing
~
sin
cos
sin t;
we find that the first moment of
DN (t)= log N does not exceed
Const \Delta ffl;
log
so that the requirement (2.7) is fulfilled.
Theorem (2.1) then yields the classical result regarding the concentration of conjugate partial
sums, [2, x42],[23, xII Theorem 8.13],
log N
~
log N
We note in passing that in the case of Dirichlet conjugate kernel, KN (t) does not concentrate near
the origin, but instead (2.7) is fulfilled thanks to its uniformly small amplitude of order O(1= log N ).
The error, however, is only of logarithmic order, consult [7, x2].
6 A. Gelb and E. Tadmor
2.2.3 Oscillatory kernels. general concentration factors
To accelerate the unacceptable logarithmically slow rate of Dirichlet conjugate kernel in (2.12), we
consider general form of odd concentration kernels
K oe
based on concentration factors, oe( k
N ) which are yet to be determined. Clearly K oe
N (t) is odd. Next,
for the normalization (2.5) we note that
K oe
Z 1oe(x)
x
dx:
In fact, the above Riemann's sum amounts to the midpoint quadrature, so that for oe(-)
one has Z -
K oe
Z 1oe(-)
and thus (2.5) holds for normalized concentration factors oe(-),
Z 1oe(-)
Consult [7] for further refinement concerning the assumed regularity of oe(\Delta) (We note that oe(\Delta) is
rescaled here with an additional factor of \Gamma- compared to [7]).
Finally, we address the admissibility requirement (2.6) (and in particular (2.7)). To this end, we
proceed along the lines of [7, Assertion 3.3], utilizing the identity (abbreviating -
This leads to the corresponding decomposition of K oe
K oe
sin t:
Here, R oe
N (t) consists of the first four terms on the right hand side of (2.16),
and it is easily verified that each one of these terms has a small first moment satisfying (2.7) (and
consequently, (2.6) holds), i.e.
jtR oe
Const
log N
Enhanced detection of edges in spectral data 7
For example, using the standard bound j sin(kt)=2 sin(t=2)j - minfk; 1=tg, the contribution corresponding
to the first term, I 1 (t), does not exceed
I 1 (t)
Similar estimates hold for the remaining contributions of I 2 ; I 3 and I 4 . In particular, since oe(- is
Finally, the admissibility of the fifth term on the right of (2.16) is due to standard cancelation
which guarantees that (2.6) holds,
sin tOE(t)dt
Const \Delta oe(1)
It is in this context of spectral concentration kernels that admissibility requires the more intricate
property of cancellation of oscillations. Summarizing (2.14), (2.17) and (2.18), we obtain as
a corollary an improved version of the main result in [7, Theorem 3.1] regarding spectral edge detection
using concentration kernels, K oe
N (t). In particular, since K oe
N (t) are N \Gammadegree trigonometric
polynomials, one detects the edges of the piecewise smooth function f(x) directly from its spectral
projection SN (f) :=
K oe
Corollary 2.2 Consider the odd concentration kernel (2.13)
K oe
sin kt; oe(-)
Assume that oe(\Delta) is normalized so that (2.15) holds
Z 1oe(-)
Then K oe
admits the concentration property (2.3), and the following estimate holds
Const \Delta
log N
Remark. One can relax the regularity on the concentration factor oe(\Delta), [7]. Corollary 2.2 is a
generalization of [7, Theorem 3.1] 2 ; in particular, the error estimate (2.19) is valid throughout the
interval, including at the location of the jump discontinuities.
Let us introduce few prototypical examples of concentration factors oe(\Delta) for the detection of edges
from spectral data. In this context we note that other detection methods of discontinuities in periodic
spectral data can be found in the works of Eckhoff [5], [6] and of Mhaskar & Prestin, e.g., [15] and
the references therein. We note that our results apply to the non-periodic expansions as discussed
in x3.2.2 below.
We note the different rescaling here of oe(\Delta) by an additional factor of \Gamma-, compared with the formulation in [7,
Theorem 3.1]
8 A. Gelb and E. Tadmor
1. Trigonometric factors. We consider concentration factors of the form
with the proper normalization Si(ff) :=
R ff(sin j=j)dj. The edge detector introduced originally
by Banerjee & Geer, [1] corresponds to oe -); the general case is found in [7, x3.2].
2. Polynomial factors. As a first example consider oe(-. In this case, K x
corollary 2.2 recovers Fej'er's result, [23, xIII Theorem 9.3], with the following error estimate
Const \Delta log N
This is the first member of a whole family of polynomial concentration factors, e.g., [7, x3.4],
which correlate to concentration kernels satisfying (2.4), (2.5), and (2.6). For odd p's, K oe p
N (f ); for even p's, K oe p
These edge detectors were introduced in [9] and were recently analyzed by
Kvernadze in [13]. Corollary 2.2 yields
i-
Const \Delta
log N
The last error estimate is (essentially) first order. It is sharp. It was noted in [7, x3.4], however,
that oe p 's with higher p's lead to faster convergence rate at selected interior points, bounded
away from the singularities of f . This leads us to the next example of
3. Exponential factors. Polynomial concentration factors (of odd degree) correspond to differentiation
in physical space; trigonometric factors correspond to divided differences in the physical
space - consult the original derivation in [1]. Our main result stated in Corollary 2.2 provides
us with the framework of general concentration kernels which are not necessarily limited to
a realization in the physical space. In particular, we seek concentration factors, oe(\Delta), which
vanish at to any prescribed order,
The higher p is, the more localized the corresponding concentration kernel, K oe
becomes.
Here is why.
Evaluating K oe
N (t) at the equidistant points t
K oe
sin 2-k'
we observe that K oe
coincide with the '-discrete Fourier coefficient of oe(\Delta); since oe(-) and
its first p-derivatives vanish with at both ends, there is a rapid decay of its (discrete)
Fourier coefficients, j-oe ' j - Const:' \Gammap ,
Enhanced detection of edges in spectral data 9
Thus, for t away from the origin, K oe
N (t) is rapidly decaying for large enough N 's. Moreover,
we claim an increasing number of moments of K oe
vanish. To this end we consider the odd
moments of K oe
N (\Delta) (- its even moments vanish, of course). With -
sin kt
\Gamma2
Z -N
Z -N
Integrate by parts - respectively, sum by parts the summation on the right of (2.23). Thanks
to (2.22) the boundary terms vanish and we have
sin(-N-)
d p\Gammaj
d- p\Gammaj
As an example, we consider the exponential concentration factors
oe exp Const
Z
exp
normalized so that
1. Here, the C 1
concentration factor oe exp (-)
vanishes exponentially at both ends, so that (2.22) holds for all p's. Figure 2.3, 2.4
confirms the improved localization of these exponential concentration factors.
4. Band pass filter. Bauer [3] have considered a family of what he termed as 'band pass filter',
supported in the range of middle frequencies, say suppj ae [1=4; 3=4]. We note in passing
that these are special cases of p-order admissible concentration factors, (2.22), although the
normalization used in ([3, eq. (1.35)]),
R
prevented the recovery of the
amplitude of the jumps.
To demonstrate the detection of edges by the concentration factors outlined above, consider the
following two examples of discontinuous f 's (defined on [\Gamma-]):
f a (x) := \Gammasgnx \Delta cos( x
In both cases, f a (x) and f b (x) are recovered from their Fourier coefficients using the Fourier partial
sums SN [f ](x), and we wish to recover their jump discontinuities
[f a
0; else.
0; else:

Figures

2.1 and 2.2 demonstrate the use of trigonometric and polynomial concentration factors
for the detection of edges from Fourier spectral data.
A. Gelb and E. Tadmor
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x
-2.2
-1.2
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x

Figure

2.1: Trigonometric concentration factor
for (left) f a (x) where the exact jump
value is where the exact jump values are [f ](\Sigma -
2.
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x
-2.2
-1.2
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x

Figure

2.2: Jump value obtained by the polynomial concentration factor oe p=1 (- for (left) f a (x)
and (right) f b (x).
Enhanced detection of edges in spectral data 11

Figure

2.3: Edge detection using the exponential concentration factor
oe exp vs. oe p=1 for S 40 f a (x) and (right) oe exp for SN f a (x) with modes.
-0.50.5s p1

Figure

2.4: Edge detection using the exponential concentration factor
oe exp vs. oe p=1 for S 40 f b (x) and (right) oe exp for SN f b (x) with modes.
As noted in [10, x3.4], polynomial factors of higher degree yields improved results away from
the jump discontinuities. Indeed, the corresponding concentration kernel, K oe p
N (\Delta) have additional
vanishing moments. In the limit, one arrives at exponential factors, K oe exp
Figures 2.3,2.4 demonstrate
the edge detection of these factors in Fourier expansions SN f a (x) and SN f b (x). The improved
localization is evident, due to the faster convergence rate in the smooth parts of f 's. In particular,
the superiority of the exponential factors is illustrated in the figures on the left, when compared
with the first-order accurate polynomial concentration factor, oe p=1 (-. At the same time, Gibbs
A. Gelb and E. Tadmor
oscillations can be noticed in the vicinity of the jump discontinuities.
3 Edge Detection in Non-periodic Projections
Consider a piecewise smooth f(\Delta). To simplify our presentation, we assume f experiences a single
jump discontinuity at The localization property of the appropriate concentration kernel in
the presence of a single jump applies to the case with finitely many jump discontinuities. We begin
with an alternative derivation of our results for the periodic case.
3.1 Revisiting the periodic case
If a 2-periodic f(\Delta) experiences a single jump, [f ](c), then it dictates the Fourier coefficients decay,
To extract information about the location of the jump from the phase of the leading term, we examine
the special concentration kernel, K oe
N with oe(-, where K -
ik
[f ](c) e ik(x\Gammac)
Here we used the concentration property of the Dirichlet kernel localized at
O
The same property applies to the class of concentration factors, oe(-), such that (2.15) holds,
-(
O
It then follows that the corresponding K oe
N in (2.13) is an admissible concentration kernel, so that
K oe
3.2 Non-periodic expansions
3.2.1 General Jacobi expansions
We begin with the Jacobi expansion of a piecewise smooth f(\Delta),
Enhanced detection of edges in spectral data 13
Here are the Jacobi polynomials - the eigenfunctions of the singular Sturm Liouville problem
with corresponding eigenvalues -
Different families of Jacobi polynomials are
associated with different weight functions To simplify the computations,
we assume that the P k 's are normalized so that kP k
As in the periodic case, integration by parts (against (3.28)) shows that a single jump disconti-
nuity, [f ](c), dictates the decay of the Jacobi coefficients,
To extract information about the location of jump, we consider the conjugate sum of the following
-(
\Theta P 0
corresponding to concentration factors oe(-). We shall focus our attention on the particular
case
\Theta P 0
This is the non-periodic analogue of the Fourier concentration kernel K -
with the additional
pre-factor weight of
We want to quantify the localization property of the last summation. To this end we note that
if fP (ff)
k (x)g are the Jacobi polynomials with respect to the weight function ! ff (x), then fP 0
k (x)g are
the Jacobi polynomials w.r.t. the modified weight function ! fi
-orthogonality follows from integration by parts of (3.28) against P (ff)
k . Thus,
The coefficients C k;fi are determined by normalization where by using (3.28) once more we find
and hence we set C
so that fP (fi)
is the orthonormal family w.r.t. ! fi weight. Inserted
into the leading term of (3.31), we end up with a Jacobi kernel associated with weight function
14 A. Gelb and E. Tadmor
\Theta
(c)P (fi)
\Theta
We rewrite this as
\Theta KN (c; x): (3.32)
By virtue of Christoffel-Darboux formula, e.g., [19, Theorem 3.2.2], the kernel KN (c; x) is given by
KN
and it remains to quantify the concentration property of KN (c; x). To this end we use the asymptotic
behavior of P (fi)
N which is stated as 3
denotes the separation between the interior and boundary
regions. Using this to upper bound KN (c; x) in (3.33), we find
\Theta 1
The upper bound on the right is in fact the leading term in the asymptotics of KN (c; x) for large
N 's as long as Similarly, the behavior at
The desired concentration property now follows, similar to the localization of the periodic Dirichlet
kernel DN (3.27). We restrict our attention to interior jumps, so that for
3 The first term on the right pf (3.34) follows from the classical asymptotic formula, e.g., [19, Theorem 12.1.4], which
tells us the behavior of the L 2
-normalized P (fi)
N (x) at the interior
The second term on the right of (3.34) reflects the fact that as x approaches the \Sigma1-boundaries, the L 2
-normalized
approaches to its maximal value e.g., [19, 4.7.3, 4.7.15]
r
Enhanced detection of edges in spectral data 15
large enough, c (3.35), (3.36) and (3.32) yield
\Theta KN (c; x) -
O
\Theta 1
We summarize by stating
Corollary 3.1 Let SN (f) denote the truncated Jacobi expansion (3.27) of a piecewise smooth f ,
associated with a weight function
the concentration property
Const \Delta log N
It is instructive to examine the above discussion for the special case of Chebyshev expansion
corresponding to
dx:
(Observe that except for Chebyshev expansion, the concentration bound (3.37) deteriorates as we
approach the boundaries, depending whether jxj - 1 for ff 1.) The
conjugate sum corresponding to (3.32) reads
k (c)
In this case, we can sum the corresponding Chebyshev kernel: setting
O( 1
[f
3.2.2 Chebyshev expansion
Our discussion above on edge detection in the non-periodic expansions is based on expansion of the
Jacobi coefficients to their leading order in (3.29). More precise information is obtained using the
general framework introduced in the main Theorem 2.1.
Corollary 3.2 Let f(\Delta) be a piecewise smooth function with Chebyshev expansion SN f(x) -
Consider the concentration factors, oe(-), with -(\Delta) normalized so that
A. Gelb and E. Tadmor
Then K oe
admits the concentration property (2.3), and the following estimate holds
-(
Const \Delta log N
Proof. With a piecewise smooth f(x) defined over the interval [\Gamma1; 1] we utilize the usual Chebyshev
transformation We consider the even extension f(cos '); \Gamma-.
Using Theorem 2.1 along the lines of Corollary 2.2, we find that the odd concentration kernel, K oe
recovers the jumps of f(cos '), i.e.,
log N
computation shows the sum on the left equals
-(
and the result follows.
We turn to numerical examples. The following tables summarize our results for the edge detection
in Legendre expansion , corresponding to ff = 0, and in Chebyshev expansion, corresponding to
\Gamma1=2. Scaled to the unit interval [\Gamma1; 1], we consider f a ( x
). The results confirm the
linear convergence rate stated in Corollary 3.1, both away from the jumps - consult Tables 3.1 and
3.2, as well as at the jump itself, Table 3.3.
N Legendre expansion Chebyshev expansion

Table

3.1: Pointwise error estimate j-
away from the jump
discontinuity at
We note that the critical threshold must be very high for to eliminate the artificial
jumps. This indicates that 40 nodes are not enough to resolve the jumps of f b (x) in either the
Chebyshev or Legendre case.
N Legendre expansion Chebyshev expansion

Table

3.2: Pointwise error estimate j-
away from the jump
discontinuities at
Enhanced detection of edges in spectral data 17
Legendre Chebyshev

Table

3.3: Pointwise error estimate j-
[f ](c)j at the point(s) of discontinuity,
It is clear from tables 3.1 and 3.2 that convergence is nonuniform at the boundaries. We have
observed in our numerical experiments, that the edge detector, -
experiences larger
oscillations near the boundaries which do affect the linear convergence rate there. In this context we
note the dependence of the error bounds on the smoothness of f(
The first-order convergence is re-confirmed, in table 3.4 below, when measuring the L 1 -error away
from the jumps discontinuities (and up to the boundaries) .
N Legendre Chebyshev

Table

away from discontinuities.
4 Nonlinear Enhancement
The detection of edges in Theorem 2.1 is based on separation of scales. Thus, consider for example a
piecewise smooth f with finitely many jump discontinuities at . If K ffl is an admissible
concentration kernel, then jK ffl   f(x)j !! 1 for x away from these jumps, where as at
ae O(ffl); x
The last statement refers to the asymptotic behavior of the concentration kernel as a function
of the small parameter ffl # 0. In this section we outline a new, nonlinear enhancement procedure,
which is easily implemented to 'pinpoint' finitely many edges in piecewise smooth f 0 s.
To this end we enhance the separated scales in (4.41) by considering
Const
By increasing the exponent p ? 1, we enhance the separation between the vanishing scale at the
points of smoothness (- of order O(ffl p
)), and the growing scale at the jumps (- of order
Next one must introduce a critical threshold which will eliminate all the unacceptable jumps. Only
those edges with amplitudes larger than the critical threshold, [f ](x) ? J 1=p
crit
ffl, will be detected.
A. Gelb and E. Tadmor
Thus crit is a measure which defines the small scale in our computation of edge detection. We
note that data dependent and is typically related to the variation of the smooth part of
f .
Given this critical threshold, we form our enhanced concentration kernel K ffl;J [f
ae
Clearly, with p large enough, one ends up with a sharp edge detector where K ffl;J [f
at all but O(ffl) neighborhoods of the jumps In practical applications, a moderate
enhancement exponent, p - 5 will suffice. We consider two examples.
1. The quadratic filter. Consider the peaked concentration kernel (2.10) K ffl
ffl (t). Then, with
one finds the so called quadratic filter [12],[22], where
2. Enhanced spectral concentration kernels. We apply the procedure of nonlinear enhancement
in conjunction with spectral concentration kernels K
sin kt by
considering the corresponding enhanced spectral concentration kernel
K oe
ae
K oe
The enhanced spectral concentration kernel depends on four ingredients which are at our disposal

ffl The number of modes, N
ffl The enhancement exponent, p
ffl The critical threshold, J
ffl The concentration factor, oe(-).

Figures

4.5 and 4.6 demonstrate the enhancement procedure to the spectral detection of edges
depicted earlier in the corresponding Figures 2.2 and 2.1.
Enhanced detection of edges in spectral data 19
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x
-2.2
-1.2
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x

Figure

4.5: Jump value obtained by applying the polynomial concentration factor oe(- with
where the exact jump value is
and (b) f b (x) where the exact jump values are [f ](\Sigma -
2.
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x
-2.2
-1.2
-3.1 -2.1 -1.1 -0.1 0.9 1.9 2.9
x

Figure

obtained by applying the trigonometric concentration factor oe 1
with modes and enhancement exponent where the exact jump value is
where the exact jump values are [f ](\Sigma -
2.
We conclude with non-periodic examples. In Figures 4.7 we show the detection of a single edge
in f a (x=-) from its Legendre expansion,
f a (x). The detection in Chebyshev expansion is
A. Gelb and E. Tadmor
shown in Figure 4.8 for f b (x=-). In both cases we used an enhancement factor critical
threshold
-0.5x
-0.5x

Figure

4.7: Detection of edges in Legendre expansion of f a (x=-) with exact jump value is [f a
(left) before and (right) after enhancement with
x
x

Figure

4.8: Detection of edges in Chebyshev expansion of f b (x=-) with exact jump value is [f b ](\Sigma
before and (right) after enhancement with
Concluding Remarks
Accurate reconstruction of piecewise smooth functions from their spectral projections is only plausible
when the location (and amplitude) of the underlying jump discontinuities are known, consult
Enhanced detection of edges in spectral data 21
[1],[7],[5],[6],[16],[11] and references therein.
Theorem 2.1, and its corollaries 2.2, and 3.1 provide the general framework for the detection
of edges from spectral data, in both periodic and non-periodic cases. The detection is based on
admissible concentration kernels which include as particular cases classical examples of Fej'er as
well as additional examples in recent literature, [1],[9],[13]. In particular, we introduce here a new
family of exponential concentration kernel, (2.24), with a superior convergence rate away from the
edges. A linear convergence rate is observed near the detected edges. We also introduce a nonlinear
enhancement (4.43) procedure which enables one to "pinpoint" edges with amplitude larger than a
critical threshold.
Recently the edge detection and enhancement method was applied to non-linear conservation
laws, [8], as a post-processing tool to improve the overall convergence rate of the spectral viscosity
solution. Since the edge detection occurs only at the post-processing stage, very little cost is added to
the procedure yet the results are dramatically improved. Future applications, in both one- and several
space dimensions, will also include image processing, where edge detection is needed to de-noise the
contamination by the O(1)-Gibbs' oscillations in the neighborhoods of the undetected edges.



--R

Exponential approximations using Fourier series partial sums
Treatise of
Band filters for determining shock locations
Introduction to the Theory of Fourier's Series and Integrals
Accurate reconstructions of functions of finite regularity from truncated series expansions
On a high order numerical method for functions with singularities
Detection of edges in spectral data
Enhanced spectral viscosity method for nonlinear conservation laws
Determination of the jump of a function of bounded p-variation by its Fourier series
"Progress and Supercomputing in Computational Fluid Dynamics"
On the Gibbs phenomenon and its resolution

Determination of the jump of a bounded function by its Fourier series

On the detection of singularities of a periodic function
The Fourier method for nonsmooth initial data
Multiresolution approximations and wavelets orthonormal bases of L 2 (R)


Convergence of spectral methods for nonlinear conservation laws
Family of spectral filters for discontinuous problems
Asymptotic behavior of quadratic edge filters
Cambridge University Press
--TR

--CTR
R. Pasquetti, On inverse methods for the resolution of the Gibbs phenomenon, Journal of Computational and Applied Mathematics, v.170 n.2, p.303-315, 15 September 2004
Anne Gelb, Parameter Optimization and Reduction of Round Off Error for the Gegenbauer Reconstruction Method, Journal of Scientific Computing, v.20 n.3, p.433-459, June 2004
Rick Archibald , A. Gelb, Reducing the Effects of Noise in Image Reconstruction, Journal of Scientific Computing, v.17 n.1-4, p.167-180, December 2002
Anne Gelb, A Hybrid Approach to Spectral Reconstruction of Piecewise Smooth Functions, Journal of Scientific Computing, v.15 n.3, p.293-322, Sept. 2000
Bernie D. Shizgal , Jae-Hun Jung, Towards the resolution of the Gibbs phenomena, Journal of Computational and Applied Mathematics, v.161 n.1, p.41-65, 1 December
Scott A. Sarra, The spectral signal processing suite, ACM Transactions on Mathematical Software (TOMS), v.29 n.2, p.195-217, June
Scott A. Sarra, Chebyshev super spectral viscosity method for a fluidized bed model, Journal of Computational Physics, v.186
