--T
A Survey of Optimization by Building and Using Probabilistic Models.
--A
This paper summarizes the research on population-based probabilistic search algorithms based on modeling promising solutions by estimating their probability distribution and using the constructed model to guide the exploration of the search space. It settles the algorithms in the field of genetic and evolutionary computation where they have been originated, and classifies them into a few classes according to the complexity of models they use. Algorithms within each class are briefly described and their strengths and weaknesses are discussed.
--B
Introduction
Recently, a number of evolutionary algorithms that guide the exploration of the search space by
building probabilistic models of promising solutions found so far have been proposed. These algorithms
have shown to perform very well on a wide variety of problems. However, in spite of a few
attempts to do so, the field lacks a global overview of what has been done and where the research
in this area is heading to.
The purpose of this paper is to review and describe basic principles of the recently proposed
population-based search algorithms that use probabilistic modeling of promising solutions to guide
their search. It settles the algorithms in the context of genetic and evolutionary computation,
classifies the algorithms according to the complexity of the class of models they use, and discusses
the advantages and disadvantages of each of these classes.
The next section briefly introduces basic principles of genetic algorithms as our starting point.
The paper continues by sequentially describing the classes of approaches classified according to
complexity of a used class of models from the least to the most general one. In Section 4 a few
approaches that work with other than string representation of solutions are described. The paper
is summarized and concluded in section 5.
Genetic Algorithms, Problem Decomposition, and Building Blocks
Simple genetic algorithms (GAs) (Holland, 1975; Goldberg, 1989) are population-based search
algorithms that guide the exploration of the search space by application of selection and genetic
operators of recombination/crossover and mutation. They are usually applied to problems where
the solutions are represented or can be mapped onto fixed-length strings over a finite alphabet.
The user defines the problem that the GA will attempt to solve by choosing the length and base
alphabet of strings representing the solutions and defining a function that discriminates the string
solutions according to their quality. This function is usually called fitness. For each string, the
fitness function returns a real number quantifying its quality with respect to the solved problem.
The higher the fitness, the better the solution.
GAs start with a randomly generated population of solutions. From the current population
of solutions the better solutions are selected by the selection operator. The selected solutions are
processed by applying recombination and mutation operators. Recombination combines multiple
(usually two) solutions that have been selected together by exchanging some of their parts. There
are various strategies to do this, e.g. one-point and uniform crossover. Mutation performs a slight
perturbation to the resulting solutions. Created solutions replace some of the old ones and the
process is repeated until the termination criteria given by the user are met.
By selection, the search is biased to the high-quality solutions. New regions of the search space
are explored by combining and mutating repeatedly selected promising solutions. By mutation,
close neighborhood of the original solutions is explored like in a local hill-climbing. Recombination
brings up innovation by combining pieces of multiple promising solutions together. GAs
should therefore work very well for problems that can be somehow decomposed into subproblems
of bounded difficulty by solving and combining the solutions of which a global solution can be con-
structed. Over-average solutions of these sub-problems are often called building blocks in GA liter-
ature. Reproducing the building blocks by applying selection and preserving them from disruption
in combination with mixing them together is a very powerful principle to solve the decomposable
problems (Harik, Cant'u-Paz, Goldberg, & Miller, 1997; Muhlenbein, Mahnig, & Rodriguez, 1998).
However, fixed, problem-independent recombination operators often either break the building
blocks frequently or do not mix them effectively. GAs work very well only for problems where
the building blocks are located tightly in strings representing the solutions (Thierens, 1995). On
problems with the building blocks spread all over the solutions, the simple GAs experience very poor
performance (Thierens, 1995). That is why there has been a growing interest in methods that learn
the structure of a problem on the fly and use this information to ensure a proper mixing and growth
of building blocks. One of the approaches is based on probabilistic modeling of promising solutions
to guide the further exploration of the search space instead of using crossover and mutation like in
the simple GAs.
3 Evolutionary Algorithms Based on Probabilistic Modeling
The algorithms that use a probabilistic model of promising solutions to guide further exploration of
the search space are called the estimation of distribution algorithms (EDAs) (Muhlenbein & Paa,
1996). In EDAs better solutions are selected from an initially randomly generated population of
solutions like in the simple GA. The true probability distribution of the selected set of solutions
is estimated. New solutions are generated according to this estimate. The new solutions are then
added into the original population, replacing some of the old ones. The process is repeated until
the termination criteria are met.
The EDAs therefore do the same as the simple GAs except for that they replace genetic recombination
and mutation operators by the following two steps:
(1) A model (an estimate of the true distribution) of selected promising solutions is constructed.
(2) New solutions are generated according to the constructed model.
Although EDAs process solutions in a different way than the simple GAs, it has been theoretically
and empirically proven that the results of both can be very similar. For instance, the
simple GA with uniform crossover which randomly picks a value on each position from either of the
two parents works asymptotically the same as the so-called univariate marginal distribution algorithm
(Muhlenbein & Paa, 1996) that assumes that the variables are independent (Muhlenbein,
1997; Harik et al., 1998; Pelikan & Muhlenbein, 1999).
A distribution estimate can capture a building-block structure of a problem very accurately
and ensure a very effective mixing and reproduction of building blocks. This results in a linear
or subquadratic performance of EDAs on these problems (Muhlenbein & Mahnig, 1998; Pelikan
et al., 1998). In fact, with an accurate distribution estimate that captures a structure of the
solved problem the EDAs unlike the simple GAs perform the same as GA theory with mostly used
assumptions claims. However, estimation of the true distribution is far from a trivial task. There
is a trade-off between the accuracy and efficiency of the estimate.
The following sections describe three classes of EDAs that can be applied to problems with
solutions represented by fixed-length strings over a finite alphabet. The algorithms are classified
according to the complexity of the class of models they use. Starting with methods that assume
that the variables in a problem (string positions) are independent, through the ones that take into
account some pairwise interactions, to the methods that can accurately model even a very complex
problem structure with highly overlapping multivariate building blocks.
An example model from each presented class of models will be shown. Models will be displayed
as Bayesian networks, i.e. directed acyclic graphs with nodes corresponding to the variables in a
problem (string positions) and edges corresponding to probabilistic relationships covered by the
model. An edge between two nodes in a Bayesian network relates the two nodes so that the value
of the variable corresponding to the ending node of this edge depends on the value of the variable
corresponding to the starting node.
3.1
The simplest way to estimate the distribution of promising solutions is to assume that the variables
in a problem are independent and to look at the values of each variable regardless of the remaining
solutions (see figure 1). The model of the selected promising solutions used to generate the new
ones contains a set of frequencies of all values on all string positions in the selected set. These
frequencies are used to guide further search by generating new string solutions position by position
according to the frequency values. In this fashion, building blocks of order one are reproduced and
mixed very efficiently. Algorithms based on this principle work very well on linear problems where
the variables are not mutually interacting (Muhlenbein, 1997; Harik et al., 1997).
In the population-based incremental learning (PBIL) algorithm (Baluja, 1994) the solutions
are represented by binary strings of fixed length. The population of solutions is replaced with the
so-called probability vector which is initially set to assign each value on each position with the
same probability 0:5. After generating a number of solutions the very best solutions are selected
and the probability vector is shifted towards the selected solutions by using Hebbian learning
rule (Hertz, Krogh, & Palmer, 1991). The PBIL has been also referred to as the hill-climbing with
learning (HCwL) (Kvasnicka, Pelikan, & Pospichal, 1996) and the incremental univariate marginal
distribution algorithm (IUMDA) (Muhlenbein, 1997) recently. Some analysis of the PBIL algorithm
can be found in Kvasnicka et al. (1996).
In the univariate marginal distribution algorithm (UMDA) (Muhlenbein & Paa, 1996) the population
of solutions is processed. In each iteration the frequencies of values on each position in the
selected set of promising solutions are computed and these are then used to generate new solutions

Figure

1: Graphical model with no interactions covered.
which replace the old ones. The new solutions replace the old ones and the process is repeated until
the termination criteria are met. Some theory of the UMDA can be found in Muhlenbein (1997).
The compact genetic algorithm (cGA) (Harik, Lobo, & Goldberg, 1998) replaces the population
with a single probability vector like the PBIL. However, unlike the PBIL, it modifies the probability
vector so that there is direct correspondence between the population that is represented by the
probability vector and the probability vector itself. Instead of shifting the vector components
proportionally to the distance from either 0 or 1, each component of the vector is updated by
shifting its value by the contribution of a single individual to the total frequency assuming a
particular population size. By using this update rule, theory of simple genetic algorithms can be
directly used in order to estimate the parameters and behavior of the cGA.
All algorithms described in this section perform similarly. They work very well for linear
problems where they achieve linear or sub-quadratic performance, depending on the type of a
problem, and they fail on problems with strong interactions among variables. For more information
on the described algorithm as well as theoretical and empirical results of these see the cited papers.
Algorithms that do not take into account any interdependencies of various bits (variables) fail
on problems where there are strong interactions among variables and where without taking into
account these the algorithms are mislead. That is why a lot of effort has been put in extending
methods that use a simple model that does not cover any interactions to methods that could solve
a more general class of problems as efficiently as the simple PBIL, UMDA, or cGA can solve linear
problems.
3.2 Pairwise Interactions
First algorithms that did not assume that the variables in a problem were independent could
cover some pairwise interactions. The mutual-information-maximizing input clustering (MIMIC)
algorithm (De Bonet, Isbell, & Viola, 1997) uses a simple chain distribution (see figure 2a) that
maximizes the so-called mutual information of neighboring variables (string positions). In this
fashion the Kullback-Liebler divergence (Kullback & Leibler, 1951) between the chain and the
complete joint distribution is minimized. However, to construct a chain (which is equivalent to
ordering the variables), MIMIC uses only a greedy search algorithm due to its efficiency, and
therefore global optimality of the distribution is not guaranteed.
Baluja and Davies (1997) use dependency trees (see figure 2b) to model promising solutions.
There are two major advantages of using trees instead of chains. Trees are more general than
chains because each chain is a tree. Moreover, by relaxing constraints of the model, in order to
find the best model (according to a measure decomposable into terms of order two), a polynomial
maximal branching algorithm (Edmonds, 1967) that guarantees global optimality of the solution
can be used. On the other hand, MIMIC uses only a greedy search because in order to learn chain
distributions, an NP-complete algorithm is needed. Similarly as in the PBIL, the population is
replaced by a probability vector which contains all pairwise probabilities.
In the bivariate marginal distribution algorithm (BMDA) (Pelikan & Muhlenbein, 1999) a forest
(a set of mutually independent dependency trees, see figure 2c) is used. This class of models is
even more general than the class of dependency trees because a single tree is in fact a set of one
tree. As a measure used to determine which variables should be connected and which should not,
Pearson's chi-square test (Marascuilo & McSweeney, 1977) is used. This measure is also used to
discriminate the remaining dependencies in order to construct the final model.
(a) MIMIC (b) Baluja&Davies (1997) (c) BMDA

Figure

2: Graphical models with pairwise interactions covered.
Pairwise models allow covering some interactions in a problem and are very easy to learn. The
algorithms presented in this section reproduce and mix building blocks of order two very efficiently,
and therefore they work very well on linear and quadratic problems (De Bonet et al., 1997; Baluja
Davies, 1997; Muhlenbein, 1997; Pelikan & Muhlenbein, 1999; Bosman & Thierens, 1999). The
latter two approaches can also solve 2D spin-glass problems very efficiently (Pelikan & Muhlenbein,
1999).
3.3 Multivariate Interactions
However, covering only some pairwise interactions has still shown to be insufficient to solve problems
with multivariate or highly-overlapping building blocks(Pelikan & Muhlenbein, 1999; Bosman
1999). That is why research in this area continued with more complex models. On one
hand, using general models has brought powerful algorithms that are capable of solving decomposable
problems quickly, accurately, and reliably.
On the other hand, using general models has also resulted in a necessity of using complex
learning algorithms that require significant computational time and still do not guarantee global
optimality of the resulting models. However, in spite of increased computational time spent by
learning the models, the number of evaluations of the optimized function is reduced significantly.
In this fashion the overal time complexity is reduced. Moreover, on many problems other algorithms
simply do not work. Without learning the structure of a problem, algorithms must be either given
this information by an expert or they will simply be incapable of biasing the search in order to
solve complex decomposable problems with a reasonable computational cost.
Algorithms presented in this section use models that can cover multivariate interactions. In the
extended compact genetic algorithm (ECGA) (Harik, 1999), the variables are divided into a number
of intact clusters which are manipulated as independent variables in the UMDA (see figure 3a).
Therefore, each cluster (building block) is taken as a whole and different clusters are considered to
be mutually independent. To discriminate models, the ECGA uses a minimum description length
(MDL) metric (Mitchell, 1997) which prefers models that allow higher compression of data (selected
set of promising solutions). The advantage of using the MDL metric is that it penalizes complex
models when they are not needed and therefore the resulting models are not overly complex. To
find a good model, a simple greedy algorithm is used. Starting with all variables separated, in each
iteration current groups of variables are merged so that the metric increases the most. If no more
improvement is possible, the current model is used.
Following from theory of the UMDA, for problems that are separable, i.e. decomposable into
non-overlapping subproblems of a bounded order, the ECGA with a good model should perform in
a sub-quadratic time. A question is whether the ECGA finds a good model and how much effort
it takes. Moreover, many problems contain highly overlapping building blocks (e.g., 2D spin-glass
systems) which can not be accurately modeled by simply dividing the variables into distinct classes.
This results in a poor performance of the ECGA on these problems.
The factorized distribution algorithm uses
a factorized distribution as a fixed model throughout the whole computation. The FDA is not
capable of learning the structure of a problem on the fly. The distribution and its factorization
are given by an expert. Distributions are allowed to contain marginal and conditional probabilities
which are updated according to the currently selected set of solutions. It has been theoretically
proven that when the model is correct, the FDA solves decomposable problems quickly, reliably, and
accurately (Muhlenbein, Mahnig, & Rodriguez, 1998). However, the FDA requires prior information
about the problem in form of its decomposition and its factorization. Unfortunately, this is usually
not available when solving real-world problems, and therefore the use of FDA is limited to problems
where we can at least accurately approximate the structure of a problem.
The Bayesian optimization algorithm (BOA) (Pelikan, Goldberg, & Cant'u-Paz, 1998) uses a
more general class of distributions than the ECGA. It incorporates methods for learning Bayesian
networks (see figure 3b) and uses these to model the promising solutions and generate the new
ones. In the BOA, after selecting promising solutions, a Bayesian network that models these is
constructed. The constructed network is then used to generate new solutions. As a measure of
quality of networks, any metric can be used, e.g. Bayesian-Dirichlet (BD) metric (Heckerman,
Geiger, & Chickering, 1994), MDL metric, etc. In recently published experiments the BD scoring
metric has been used. The BD metric does not prefer simpler models to the more complex ones. It
uses accuracy of the encoded distribution as the only criterion. That is why the space of possible
models has been reduced by specifying a maximal order of interactions in a problem that are to
be taken into account. To construct the network with respect to a given metric, any algorithm
that searches over the domain of possible Bayesian networks can be used. In recent experiments, a
greedy algorithm has been used due to its efficiency.
The BOA uses an equivalent class of models as the FDA; however, it does not require any
information about the problem on input. It is able to discover this information itself. Nevertheless,
prior information can be incorporated and the ratio of prior information and information contained
in the set of high-quality solutions found so far can be controlled by the user. Not only does the
BOA fill the gap between the FDA and uninformed search methods but also offers a method that is
efficient even without any prior information (Pelikan et al., 1998; Schwarz & Ocenasek, 1999; Pelikan
et al., 1999) and still does not prohibit further improvement by using this. Another algorithm that
uses Bayesian networks to model promising solutions, called the estimation of Bayesian network
(a) ECGA (b) BOA

Figure

3: Graphical models with multivariate interactions covered.
algorithm (EBNA), has been later proposed by Etxeberria and Larra~naga (1999).
The algorithms that use models capable of covering multivariate interactions achieve a very
good performance on a wide range of decomposable problems, e.g. 2D spin-glass systems (Pelikan
et al., 1998; Muhlenbein & Mahnig, 1998), graph partitioning (Schwarz & Ocenasek, 1999), communication
network optimization (Rothlauf, 1999), etc. However, problems which are decomposable
into terms of bounded order can still be very difficult to solve. Overlapping the subproblems can
mislead the algorithm until the right solution to a particular subproblem is found and sequentially
distributed across the solutions (e.g., see F 0\Gammapeak
in Muhlenbein and Mahnig (1998)). Without
generating the initial population with the use of problem-specific information, building blocks of
size proportional to size of a problem have to be used which results in an exponential performance
of the algorithms. This brings up a question on what are the problems we aim to solve by algorithms
based on reproduction and mixing of building blocks that we have shortly discussed earlier
in section 2. We do not attempt to solve all problems that can be decomposed into terms of a
bounded order. The problems we approach to solve are decomposable in a sense that they can be
solved by approaching the problem on a level of solutions of lower order by combining the best
of which we can construct the optimal or a close-to-optimal solution. This is how we bias the
search so that the total space explored by the algorithm substantially reduces by a couple orders
of magnitude and computationally hard problems can be solved quickly, accurately, and reliably.
4 Beyond String Representation of Solutions
All algorithms described above work on problems defined on fixed-length strings over a finite alpha-
bet. However, recently there have been a few attempts to go beyond this simple representation and
directly tackle problems where the solutions are represented by vectors of real number or computer
programs without mapping the solutions on strings. All these approaches use simple models that
do not cover any interactions in a problem.
In the stochastic hill-climbing with learning by vectors of normal distributions (SHCLVND)
(Rudlof & Koppen, 1996) the solutions are represented by real-valued vectors. The population of
solutions is replaced (and modeled) by a vector of mean values of Gaussian normal distribution
for each optimized variable (see figure 4a). The standard deviation oe is stored globally and
it is the same for all variables. After generating a number of new solutions, the mean values  i
are shifted towards the best of the generated solutions and the standard deviation oe is reduced to
x
Variable 4
Variable 3
Variable 5
(a) SHCLVND
a
a
a
a b b b b
Variable 4
Variable 3
z
z
z
z 14(b) (Servet et al., 1998)

Figure

4: Probabilistic models of real vectors of independent variables.
make future exploration of the search space narrower. Various ways of modifying the oe parameter
have been exploited in (Sebag & Ducoulombier, 1998). In another implementation of a real-coded
PBIL (Servet, Trave-Massuyes, & Stern, 1997), for each variable an interval (a
) and a number
are stored (see figure 4b). The z i
stands for a probability of a solution to be in the right half of
the interval. It is initialized to 0:5. Each time new solutions are generated using the corresponding
intervals, the best solutions are selected and the numbers z i
are shifted towards them. When z i
for a variable gets close to either 0 or 1, the interval is reduced to the corresponding half of it. In
figure 4b, each z i is mapped to the corresponding interval (a
In the probabilistic incremental program evolution (PIPE) algorithm (Salustowicz & Schmid-
huber, 1997) computer programs or mathematical functions are evolved as like in genetic programming
(Koza, 1992). However, pair-wise crossover and mutation are replaced by probabilistic
modeling of promising programs. Programs are represented by trees where each internal node
represents a function/instruction and leaves represent either input variable or a constant. In the
PIPE algorithm, probabilistic representation of the program trees is used. Probabilities of each
instruction in each node in a maximal possible tree are used to model promising and generate new
programs (see figure 5). Unused portions of the tree are simply cut before the evaluation of the
program by a fitness function. Initially, the model is set so that the trees are generated at random.
From the current population of programs the ones that perform the best are selected. These are
then used to update the probabilistic model. The process is repeated until the termination criteria
are met.
5 Summary and Conclusions
Recently, the use of probabilistic modeling in genetic and evolutionary computation has become
very popular. By combining various achievements of machine learning and genetic and evolutionary
computation, efficient algorithms for solving a broad class of problems have been constructed.
The most recent algorithms are continuously proving their powerfulness and efficiency, and offer a
promising approach to solving the problems that can be resolved by combining high-quality pieces
of information of a bounded order together.
In this paper, we have reviewed the algorithms that use probabilistic models of promising
p(sdasd) 231
p(x)=12 p(sdasd) 231
p(x)=12 p(sdasd) 231
p(x)=12 p(sdasd) 231
p(x)=12 p(sdasd) 231

Figure

5: Graphical model of a program with no interactions covered used in PIPE.
solutions found so far to guide further exploration of the search space. The algorithms have been
classified in a few classes according to the complexity of the class of models they use. Basic
properties of each of these classes of algorithms have been shortly discussed and a thorough list of
published papers and other references has been given.
6

Acknowledgments

The authors would like to thank Erick Cant'u-Paz, Martin Butz, Dimitri Knjazew, and Jiri Pospichal
for valuable discussions and useful comments that helped to shape the paper.
The work was sponsored by the Air Force Office of Scientific Research, Air Force Materiel Com-
mand, USAF, under grant number F49620-97-1-0050. Research funding for this project was also
provided by a grant from the U.S. Army Research Laboratory under the Federated Laboratory
Program, Cooperative Agreement DAAL01-96-2-0003. The U.S. Government is authorized to reproduce
and distribute reprints for Governmental purposes notwithstanding any copyright notation
thereon. The views and conclusions contained herein are those of the authors and should not be
interpreted as necessarily representing the official policies and endorsements, either expressed or
implied, of the Air Force of Scientific Research or the U.S. Government.



--R


Using optimal dependency-trees for combinatorial optimization: Learning the structure of the search space
Linkage information processing in distribution estimation algorithms.

Optimum branching.

Genetic algorithms in search
Linkage learning via probabilistic modeling in the ECGA (IlliGAL Report No.


The compact genetic algorithm.

Learning Bayesian networks: The combination of knowledge and statistical data (Technical Report MSR-TR-94-09)
Introduction to the theory of neural compu- tation
Adaptation in natural and artificial systems.
Genetic programming: on the programming of computers by means of natural selection.
On information and sufficiency.
Hill climbing with learning (An abstraction of genetic algorithm).
Nonparametric and distribution-free methods for the social sciences
Machine learning.
The equation for response to selection and its use for prediction.
Convergence theory and applications of the factorized distribution algorithm.



BOA: The Bayesian optimization algo- rithm
The bivariate marginal distribution algorithm.
Communication network optimization.
Stochastic hill climbing with learning by vectors of normal distributions.
Probabilistic incremental program evolution: Stochastic search through program space.

Extending population-based incremental learning to continuous search spaces
Telephone network traffic overloading diagnosis and evolutionary computation techniques.
Analysis and design of genetic algorithms.
--TR
Adaptation in natural and artificial systems
Genetic programming
Genetic Algorithms in Search, Optimization and Machine Learning
Machine Learning
Schemata, Distributions and Graphical Models in Evolutionary Optimization
Probabilistic Incremental Program Evolution
Using Optimal Dependency-Trees for Combinational Optimization
Extending Population-Based Incremental Learning to Continuous Search Spaces
From Recombination of Genes to the Estimation of Distributions I. Binary Parameters
Telephone Network Traffic Overloading Diagnosis and Evolutionary Computation Techniques
Fuzzy Recombination for the Breeder Genetic Algorithm
Population-Based Incremental Learning: A Method for Integrating Genetic Search Based Function Optimization and Competitive Learning

--CTR
Radovan Ondas , Martin Pelikan , Kumara Sastry, Scalability of genetic programming and probabilistic incremental program evolution, Proceedings of the 2005 conference on Genetic and evolutionary computation, June 25-29, 2005, Washington DC, USA
Martin Pelikan , David E. Goldberg, A hierarchy machine: learning to optimize from nature and humans, Complexity, v.8 n.5, p.36-45, May/June
Paul Winward , David E. Goldberg, Fluctuating crosstalk, deterministic noise, and GA scalability, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
J. M. Pea , J. A. Lozano , P. Larraaga, Unsupervised learning of Bayesian networks via estimation of distribution algorithms: an application to gene expression data clustering, International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems, v.12 n.SUPPLEMENT, p.63-82, January 2004
Chao-Hong Chen , Wei-Nan Liu , Ying-Ping Chen, Adaptive discretization for probabilistic model building genetic algorithms, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
Juergen Branke , Clemens Lode , Jonathan L. Shapiro, Addressing sampling errors and diversity loss in UMDA, Proceedings of the 9th annual conference on Genetic and evolutionary computation, July 07-11, 2007, London, England
Jun Sakuma , Shigenobu Kobayashi, Real-coded crossover as a role of kernel density estimation, Proceedings of the 2005 conference on Genetic and evolutionary computation, June 25-29, 2005, Washington DC, USA
Paul Winward , David E. Goldberg, Fluctuating crosstalk, deterministic noise, and GA scalability, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
Joseph Reisinger , Risto Miikkulainen, Selecting for evolvable representations, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
Fernando G. Lobo , Cludio F. Lima, A review of adaptive population sizing schemes in genetic algorithms, Proceedings of the 2005 workshops on Genetic and evolutionary computation, June 25-26, 2005, Washington, D.C.
J. L. Shapiro, Drift and Scaling in Estimation of Distribution Algorithms, Evolutionary Computation, v.13 n.1, p.99-123, January 2005
Hung , Ying-ping Chen , Hsiao Wen Zan, Characteristic determination for solid state devices with evolutionary computation: a case study, Proceedings of the 9th annual conference on Genetic and evolutionary computation, July 07-11, 2007, London, England
Shigeyoshi Tsutsui , Martin Pelikan , Ashish Ghosh, Edge histogram based sampling with local search for solving permutation problems, International Journal of Hybrid Intelligent Systems, v.3 n.1, p.11-22, January 2006
Peter A. N. Bosman , Jrn Grahl , Franz Rothlauf, SDR: a better trigger for adaptive variance scaling in normal EDAs, Proceedings of the 9th annual conference on Genetic and evolutionary computation, July 07-11, 2007, London, England
Jrn Grahl , Peter A.N. Bosman , Franz Rothlauf, The correlation-triggered adaptive variance scaling IDEA, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
Dong-Il Seo , Byung-Ro Moon, An Information-Theoretic Analysis on the Interactions of Variables in Combinatorial Optimization Problems, Evolutionary Computation, v.15 n.2, p.169-198, Summer 2007
A. Mendiburu , J. Miguel-Alonso , J. A. Lozano , M. Ostra , C. Ubide, Parallel EDAs to create multivariate calibration models for quantitative chemical applications, Journal of Parallel and Distributed Computing, v.66 n.8, p.1002-1013, August 2006
Martin Pelikan , Kumara Sastry , David E. Goldberg, Sporadic model building for efficiency enhancement of hierarchical BOA, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
Xavier Llor , Kumara Sastry , David E. Goldberg , Abhimanyu Gupta , Lalitha Lakshmi, Combating user fatigue in iGAs: partial ordering, support vector machines, and synthetic fitness, Proceedings of the 2005 conference on Genetic and evolutionary computation, June 25-29, 2005, Washington DC, USA
Marcus Gallagher , Marcus Frean, Population-Based Continuous Optimization, Probabilistic Modelling and Mean Shift, Evolutionary Computation, v.13 n.1, p.29-42, January 2005
Yunpeng , Sun Xiaomin , Jia Peifa, Probabilistic modeling for continuous EDA with Boltzmann selection and Kullback-Leibeler divergence, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
Steven Thierens , Mark De Berg, On the Design and Analysis of Competent Selecto-recombinative GAs, Evolutionary Computation, v.12 n.2, p.243-267, June 2004
Martin V. Butz , Martin Pelikan, Studying XCS/BOA learning in Boolean functions: structure encoding and random Boolean functions, Proceedings of the 8th annual conference on Genetic and evolutionary computation, July 08-12, 2006, Seattle, Washington, USA
Martin V. Butz , David E. Goldberg , Kurian Tharakunnel, Analysis and improvement of fitness exploitation in XCS: bounding models, tournament selection, and bilateral accuracy, Evolutionary Computation, v.11 n.3, p.239-277, Fall
Mark Hauschild , Martin Pelikan , Claudio F. Lima , Kumara Sastry, Analyzing probabilistic models in hierarchical BOA on traps and spin glasses, Proceedings of the 9th annual conference on Genetic and evolutionary computation, July 07-11, 2007, London, England
Martin V. Butz , Kumara Sastry , David E. Goldberg, Strong, Stable, and Reliable Fitness Pressure in XCS due to Tournament Selection, Genetic Programming and Evolvable Machines, v.6 n.1, p.53-77, March     2005
Martin Pelikan , Kumara Sastry , David E. Goldberg, Multiobjective hBOA, clustering, and scalability, Proceedings of the 2005 conference on Genetic and evolutionary computation, June 25-29, 2005, Washington DC, USA
Martin Pelikan , David E. Goldberg , Shigeyoshi Tsutsui, Getting the best of both worlds: discrete and continuous genetic and evolutionary algorithms in concert, Information Sciences: an International Journal, v.156 n.3-4, p.147-171, 15 November
Kumara Sastry , Hussein A. Abbass , David E. Goldberg , D. D. Johnson, Sub-structural niching in estimation of distribution algorithms, Proceedings of the 2005 conference on Genetic and evolutionary computation, June 25-29, 2005, Washington DC, USA
Martin V. Butz , Martin Pelikan , Xavier Llor , David E. Goldberg, Extracted global structure makes local building block processing effective in XCS, Proceedings of the 2005 conference on Genetic and evolutionary computation, June 25-29, 2005, Washington DC, USA
Martin Pelikan , James D. Laury, Jr., Order or not: does parallelization of model building in hBOA affect its scalability?, Proceedings of the 9th annual conference on Genetic and evolutionary computation, July 07-11, 2007, London, England
Martin Pelikan , Rajiv Kalapala , Alexander K. Hartmann, Hybrid evolutionary algorithms on minimum vertex cover for random graphs, Proceedings of the 9th annual conference on Genetic and evolutionary computation, July 07-11, 2007, London, England
Ying-Ping Chen , David E. Goldberg, Convergence Time for the Linkage Learning Genetic Algorithm, Evolutionary Computation, v.13 n.3, p.279-302, September 2005
Martin V. Butz , Martin Pelikan , Xavier Llor , David E. Goldberg, Automated Global Structure Extraction for Effective Local Building Block Processing in XCS, Evolutionary Computation, v.14 n.3, p.345-380, September 2006
Martin V. Butz , Martin Pelikan , Xavier Llor , David E. Goldberg, Automated global structure extraction for effective local building block processing in XCS, Evolutionary Computation, v.14 n.3, p.345-380, September 2006
J. M. Pea , J. A. Lozano , P. Larraaga, Globally Multimodal Problem Optimization Via an Estimation of Distribution Algorithm Based on Unsupervised Learning of Bayesian Networks, Evolutionary Computation, v.13 n.1, p.43-66, January 2005
Martin Pelikan , Kumara Sastry , David E. Goldberg, Sporadic model building for efficiency enhancement of the hierarchical BOA, Genetic Programming and Evolvable Machines, v.9 n.1, p.53-84, March     2008
