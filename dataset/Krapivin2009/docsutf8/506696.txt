--T
Skepticism and floating conclusions.
--A
The purpose of this paper is to question some commonly accepted patterns of reasoning involving nonmonotonic logics that generate multiple extensions. In particular, I argue that the phenomenon of floating conclusions indicates a problem with the view that the skeptical consequences of such theories should be identified with the statements that are supported by each of their various extensions.
--B
Introduction
One of the most striking ways in which nonmonotonic logics can differ from classical logic, and even
from standard philosophical logics, is in allowing for multiple sanctioned conclusion sets, known as
extensions. The term is due to Reiter [12], who thought of default rules as providing a means for
extending the strictly logical conclusions of a knowledge base with plausible information. Multiple
extensions arise when a knowledge base contains conflicting default rules, suggesting different, often
inconsistent ways of supplementing its strictly logical conclusions.
The purpose of this paper is to question some commonly accepted patterns of reasoning involving
theories that generate multiple extensions. In particular, I argue that the phenomenon of floating
conclusions indicates a problem with the view that the skeptical consequences of such theories
should be identified with the statements that are supported by each of their various extensions.
Multiple extensions
The canonical example of a knowledge base with multiple extensions is the Nixon Diamond, depicted
in

Figure

1. Here, the statements Qn, Rn, and Pn represent the propositions that Nixon is a
Quaker, a Republican, and a pacifist; statements of the form A
ordinary logical implications and "default" implications respectively, with A
abbreviating A ) :B and A ! :B; and the special statement ? represents truth. What the
knowledge base tells us, of course, is this: Nixon is both a Quaker and a Republican, the fact that
he is a Quaker provides a good reason for concluding that he is a pacifist, and the fact that he is a
Republican provides a good reason for concluding that he is not a pacifist.
This example can be coded into default logic as the theory
representing the basic facts of the situation and
representing the two defaults. The theory yields two extensions:
f:Png). The first results when the basic facts of the situation are extended by
an application of the default concerning Quakers; the second results when the facts are extended
by an application of the default concerning Republicans.
In light of these two extensions, what are we to conclude from the initial information: is Nixon a
pacifist or not? More generally, when a default theory leads to more than one extension, what should
we actually infer from that theory-how should we define its set of consequences, or conclusions?
Several proposals have been discussed in the literature. One option is to suppose that we should
arbitrarily select a particular one of the theory's several extensions and endorse the conclusions
contained in it; a second option is to suppose that we should be willing to endorse a conclusion just
in case it is contained in some extension of the theory. These first two options are sometimes said
to reflect a credulous reasoning policy. A third option, now generally described as skeptical, is to
suppose that we should endorse a conclusion just in case it is contained in every extension of the
theory. 1
Of these three options, the first-pick an arbitrary extension-really does seem to embody a
sensible policy, or at least one that is frequently employed. Given conflicting defeasible information,
we often simply adopt some internally coherent point of view in which the conflicts are resolved in
some particular way, regardless of the fact that there are other coherent points of view in which
the conflicts are resolved in different ways. Still, although this reasoning policy may be sensible, it
1 The use of the credulous/skeptical terminology in this context was first introduced by Touretzky et al. [15], but
the distinction itself is older than this; it was already implicit in Reiter's paper on default logic, and was described
explicitly by McDermott [10] as the distinction between brave and cautious reasoning. Makinson [8] refers to the first
of the two credulous options described here as the choice option.
s
s
s
s
\Gamma'
@
@
@
@
@
@I
Rn
Pn
Qn

Figure

1: The Nixon Diamond
is hard to see how it could be codified in a formal consequence relation. If the choice of extension
really is arbitrary, different reasoners could easily select different extensions, or the same reasoner
might select different extensions at different times. Which extension, then, would represent the real
conclusion set of the original theory?
The second of our three options-endorse a conclusion whenever it is contained in some extension-
could indeed be codified as a consequence relation, but it would be a peculiar one. According to this
policy, the conclusion set associated with a default theory need not be closed under standard logical
consequence, and might easily be inconsistent, even in cases in which the underlying default theory
itself seems to be consistent. The conclusion set of the theory representing the Nixon Diamond, for
example, would contain both Pn and :Pn, since each of these formulas belongs to some extension
of the default theory, but it would not contain Pn - :Pn, since this formula is not contained in
any extension.
One way of avoiding these peculiar features of the second option is to think of the conclusions
generated by a default theory as being shielded by a kind of modal operator. Where A is a
statement, let B(A) mean there is good reason to believe that A; and suppose a theory provides us
with good reason to believe a statement whenever that statement is included in some extension of
the theory, some internally coherent point of view. Then we could define the initial conclusions of a
default theory as the set that extends W with a formula B(A) whenever A belongs to
some extension of \Delta, and we could go on to define the theory's conclusion set as the logical closure
of its initial conclusions.
This variant of the second option has some interest. It results in a conclusion set that is
both closed under logical consequence and consistent as long as W itself is consistent. And Reiter's
original paper on default logic [12, Section 4] provides a proof procedure, sound and complete under
certain conditions, that could be used in determining whether B(A) belongs to the conclusion set
as defined here. Unfortunately, however, this variant of the second option also manages to sidestep
our original question. We wanted to know what conclusions we should actually draw from the
information provided by a default theory-whether or not, given the information from the Nixon
Diamond, we should conclude that Nixon is a pacifist, for example. But according to this variant, we
are told only what there is good reason to believe-that both B(Pn) and B(:Pn) are consequences
of the theory, so that there is good reason to believe that Nixon is a pacifist, but also good reason
to believe that he is not. This may be useful information, but it is still some distance from telling
us whether or not to conclude that Nixon is a pacifist. 2
Of our three options for defining a notion of consequence in the presence of multiple exten-
sions, only the third, skeptical proposal-endorse a conclusion whenever it is contained in every
extension-seems to hold any real promise. This option leads to a single conclusion set, which is
both closed under logical consequence and consistent as long as the initial information is. And it
provides an answer that is at least initially attractive to our original question concerning proper
conclusions. In the case of the Nixon Diamond, for example, since neither Pn nor :Pn belongs to
every extension, this third option tell us that we should not conclude that Nixon is a pacifist, but
that we should not conclude that Nixon is not a pacifist either. Since there is a good reason for
each of these conflicting conclusion, we should remain skeptical.
Floating conclusions
logic defines a direct, unmediated relation between a particular default theory and the statement
sets that form its extensions. Another class of formalisms-known as argument systems-takes
a more roundabout approach, analyzing nonmonotonic reasoning through the study of interactions
among competing defeasible arguments. 3
Although the arguments themselves that are studied in these argument systems are often com-
plex, we can restrict our attention here entirely to linear arguments, analogous to the reasoning
paths studied in theories of defeasible inheritance. 4 These linear arguments are formed by starting
with a true statement and then simply stringing together strict and defeasible implications; each
such argument can be said to support the final statement it contains as its conclusion. As an
abstract example, the structure ? can be taken to represent an argument of the
form "A is true, which defeasibly implies B, which strictly implies :C," supporting the conclusion
:C. As a less abstract example, we can see that the Nixon Diamond provides the materials for
constructing the two arguments ? supporting the conflicting
conclusions Pn and :Pn.
Where ff is an argument, we will let   ff represent the particular conclusion supported by ff.
Where \Phi is a set of arguments, we will let   \Phi represent the set of conclusions supported by the
arguments in \Phi-that is, the set containing the statement   ff for each argument ff belonging to \Phi.
The primary technical challenge involved in the development of an argument system is the
specification of the coherent sets of arguments that an ideal reasoner might be willing to accept on
the basis of a given body of initial information. We will refer to these coherent sets of arguments
as argument extensions, to distinguish them from the statement extensions defined by theories such
as default logic. Again, the actual definition of argument extensions is often complicated in ways
that need not concern us here. Without going into detail, however, we can simply note that, just
as theories like default logic allow multiple statement extensions, argument systems often associate
multiple argument extensions with a single body of initial information. In the case of the Nixon
Diamond, for example, an argument system patterned after multiple-extension theories of defeasible
2 Note that this objection is directed only against the use of modal operators to capture the epistemic interpretation
of default logic. Other interpretations, involving other modal operators, are possible; it is shown in [4], for example,
that a deontic interpretation, with default conclusions wrapped inside of deontic operators, generates a logic for
normative reasoning corresponding to that originally suggested by van Fraassen [16].
3 A recent survey of a variety of argument systems can be found in Prakken and Vreeswijk [11].
4 The development of the path-based approach to inheritance reasoning was initiated by Touretzky [14]; a survey
can be found in [5].
inheritance would generate the two extensions
The first results from supplementing the initial information with the argument that Nixon is a
pacifist because he is a Quaker, the second from supplementing this information with the argument
that Nixon is not a pacifist because he is a Republican.
When a knowledge base leads to multiple argument extensions, there are, as before, several
options for characterizing the appropriate set of conclusions to draw on the basis of the initial infor-
mation. Again, we might adopt a credulous reasoning policy, either endorsing the set of conclusions
supported by an arbitrary one of the several argument extensions, or perhaps endorsing a conclusion
as believable whenever it is supported by some extension or another. In the case of the Nixon
Diamond, this policy would lead us to endorse either   \Phi 1
Png or   \Phi 2
as the conclusion set of the original knowledge base, or perhaps simply to endorse the statements
belonging to the union of these two sets as believable.
As before, however, we might also adopt a kind of skeptical policy in the presence of these
multiple argument extensions, defining the appropriate conclusion set through their intersection.
In this case, though, since these new extensions contain arguments rather than statements, there are
now two alternatives for implementing such a policy. First, we might decide to endorse an argument
just in case it is contained in each argument extension associated with an initial knowledge base, and
then to endorse a conclusion just in case that conclusion is supported by an endorsed argument.
Formally, this alternative leads to the suggestion that the appropriate conclusions of an initial
knowledge base \Gamma should be the statements belonging to the set
is an extension of \Gammag):
Or second, we might decide to endorse a conclusion just in case that conclusion is itself supported
by each argument extension of the initial knowledge base \Gamma, leading to the formal suggestion that
the appropriate conclusions of the knowledge base should be the statements belonging to the set
f   \Phi : \Phi is an extension of \Gammag;
where the order of   and T is reversed.
Of course, these two alternatives for implementing the skeptical policy come to the same thing in
the case of the Nixon Diamond: both lead to fQn; Rng as the appropriate conclusion set. But there
are other situations in which the two alternatives yield different results. A well-known example,
due to Ginsberg, appears in Figure 2, where Qn and Rn are interpreted as before, Dn and Hn are
interpreted to mean that Nixon is a dove or a hawk respectively, and En as meaning that Nixon
is politically extreme (regarding the appropriate use of military force). What this diagram tells us
is that Nixon is both a Quaker and a Republican, that there is good reason to suppose that Nixon
is a dove if he is a Quaker, a hawk if he is a Republican, and that he is politically extreme if he is
either a dove or a hawk.
Again, a system patterned after multiple-extension inheritance theories would associate two
argument extensions with this knowledge base, as follows:
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
s
s
Rn
Hn
Dn
Qn
En

Figure

2: Is Nixon politically extreme?
Since no arguments except for the trivial ? ) Qn and ? ) Rn are contained in both of these ex-
tensions, the first of our two alternatives for implementing the skeptical policy, which involves intersecting
the argument extensions themselves, would lead to fQn; Rng as the appropriate conclusion
set, telling us nothing more than the initial information that Nixon is a Quaker and a Republican.
On the other hand, each of these two argument extensions supports the statement En-one through
the argument ? the other through the argument ? En. The
second of our two alternatives for implementing the skeptical policy, which involves intersecting
supported statements rather than the arguments that support them, would therefore lead to the
conclusion set fQn; Rn; Eng, telling us also that Nixon is politically extreme.
Statements like En, which are supported in each extension associated with a knowledge base,
but only by different arguments, are known as floating conclusions. This phrase, coined by Makinson
and Schlechta [9], nicely captures the picture of these conclusions as floating above the different
and conflicting arguments that might be taken to support them.
The phenomenon of floating conclusions was first investigated in the context of defeasible inheritance
reasoning, particularly in connection with the theory developed by Thomason, Touretzky,
and myself in [6]. In contrast to the multiple-extension accounts considered so far, that theory
first defined a single argument extension that was thought of as containing the "skeptically accept-
able" arguments based on a given inheritance network. The skeptical conclusions were then defined
simply as the statements supported by those skeptically acceptable arguments.
Ginsberg's political extremist example was meant to show that no approach of this sort, relying
on a single argument extension, could correctly represent skeptical reasoning. A single argument
extension could not consistently contain both the arguments ?
since the strict information in the knowledge base shows that each of these
arguments conflicts with an initial segment of the other. The single argument extension could not
contain either of these arguments without the other, since that would involve the kind of arbitrary
decision appropriate only for credulous reasoning. And if the single argument extension were to
contain neither of these two arguments, it would not support the conclusion En, which Ginsberg
considers to be an intuitive consequence of the initial information: "given that both hawks and
doves are politically [extreme], Nixon certainly should be as well" [3, p. 221]. 5
Both Makinson and Schlechta [9] and Stein [13] also consider floating conclusions in the context
of defeasible inheritance reasoning. Makinson and Schlechta share Ginsberg's view that the
appropriate conclusions to derive from a knowledge base are those that are supported by each of
its argument extensions:
It is an oversimplification to take a proposition A as acceptable . iff it is supported
by some [argument] path ff in the intersection of all extensions. Instead A must be
taken as acceptable iff it is in the intersection of all outputs of extensions, where the
output of an extension is the set of all propositions supported by some path within it
[9, pp. 203-204].
From this they likewise argue, not only that the particular theory developed in [6] is incorrect,
but more generally, that any theory attempting to define the skeptically acceptable conclusions by
reference to a single set of acceptable arguments will be mistaken. And Stein reaches a similar
judgment, for similar reasons:
The difficulty lies in the fact that some conclusions may be true in every credulous
extension, but supported by different [argument] paths in each. Any path-based theory
must either accept one of these paths-and be unsound, since such a path is not in every
extension-or reject all such paths-and with them the ideally skeptical conclusion-
and be incomplete [13, p. 284].
What lies behind these various criticisms, of course, is the widely-held assumption that the
second, rather than the first, of our two skeptical alternatives is correct-that floating conclusions
should be accepted, and that a system that fails to classify them among the consequences of a
defeasible knowledge base is therefore in error. The purpose of this paper is to question that
assumption.
4 An example
Why not accept floating conclusions? Their precarious status can be illustrated through any number
of examples, but we might as well choose a dramatic one.
Suppose, then, that my parents have a net worth of one million dollars, but that they have
divided their assets in order to avoid the United States inheritance tax, so that each parent currently
possess half a million dollars apiece. And suppose that, because of their simultaneous exposure to
a fatal disease, it is now settled that both of my parents will die within a month. This is a fact:
medical science is certain.
Imagine also, however, that there is some expensive item-a yacht, say-whose purchase I
believe would help to soften the blow of my impending loss. Although the yacht I want is currently
5 Although, as far as I know, this example was first published in the textbook cited here, it had previously been
part of the oral tradition for many years-I first heard it during the question session after the AAAI-87 presentation
of [6], when Ginsberg raised it as an objection to that theory.
available, the price is good enough that it is sure to be sold by the end of the month. I can now
reserve the yacht for myself by putting down a large deposit, with the balance due in six weeks.
But there is no way I can afford to pay the balance unless I happen to inherit at least half a million
dollars from my parents within that period, and if I fail the pay the balance on time, I will lose my
large deposit. Setting aside any doubts concerning the real depth of my grief, let us suppose that
my utilities determine the following conditional preferences: if I believe I will inherit half a million
dollars from my parents within six weeks, it is very much in my benefit to place a deposit on the
yacht; if I do not believe this, it is very much in my benefit not to place a deposit.
Now suppose I have a brother and a sister, both of whom are extraordinarily reliable as sources
of information. Neither has ever been known to be mistaken, to deceive, or even to misspeak-
although of course, like nearly any source of information, they must be regarded as defeasible.
My brother and sister have both talked with our parents about their wills, and feel that they
understand the situation. I have written to each of them describing my delicate predicament
regarding the yacht, and receive letters back. My brother writes: "Father is going to leave his
money to me, but Mother will leave her money to you, so you're in good shape.'' My sister writes:
"Mother is going to leave her money to me, but Father will leave his money to you, so you're in
good shape." No further information is now available: the wills are sealed, my brother and sister
are trekking together through the Andes, and our parents, sadly, have slipped into a coma.
Based on my current information, what should I conclude? Should I form the belief that I will
inherit half a million dollars-and therefore place a large deposit on the yacht-or not?
The situation is depicted in Figure 3, where the statement letters are interpreted as follows: F
represents the proposition that I will inherit half a million dollars from my father, M represents the
proposition that I will inherit half a million dollars from my mother, BA(:F - M ) represents the
proposition that my brother asserts that I will inherit my mother's money but not my father's, and
represents the proposition that my sister asserts that I will inherit my father's money
but not my mother's. The defeasible links BA(:F - M
reflect the fact that any assertion by my brother or sister provides good reason for concluding that
the content of that assertion is true. The strict links in the diagram record various implications
and inconsistencies. Notice that, although the contents of my brother's and sister's assertions-the
statements :F -M and F -:M-are jointly inconsistent, the truth of either entails the disjunctive
which is, of course, all I really care about. As long as I can conclude that I will
inherit half a million dollars from either my father or my mother, I should go ahead and place a
deposit on the yacht.
A multiple-extension approach would associate the following two argument extensions with this
knowledge base:
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
@
s
s

Figure

3: Should I buy the yacht?
Again, the first of our two alternatives for implementing the skeptical reasoning policy, which
involves intersecting arguments, would lead to fBA(:F - M ); SA(F - :M )g as the appropriate
conclusion set, telling me only that my brother and sister asserted what they did. But since each of
the two extensions contains some argument supporting the statement F -M , the second alternative,
which involves intersecting supported statements, leads to the conclusion set fBA(:F-M ); SA(F-
telling me also-as a floating conclusion-that I will inherit half a million dollars
from either my father or my mother.
In this situation, then, there is a vivid practical difference between the two skeptical alternatives.
If I were to reason according to the first, I would not be justified in concluding that I am about to
inherit half a million dollars, and so it would be foolish for me to place a deposit on the yacht. If
I were to reason according to the second, I would be justified in drawing this conclusion, and so it
would be foolish for me not to place a deposit.
Which alternative is correct? I have not done a formal survey, but most of the people to
whom I have presented this example are suspicious of the floating conclusion, and so favor the first
alternative. Most do not feel that the initial information from Figure 3 would provide sufficient
justification for me to conclude, as the basis for an important decision, that I will inherit half
a million dollars. Certainly, this is my own opinion-that the example shows, contrary to the
widely-held assumption, that it is at least coherent for a skeptical reasoner to withhold judgment
from floating conclusions. Although both my brother and sister are reliable, and each supports the
conclusion that I will inherit half a million dollars, the support provided by each of these reliable
sources is undermined by the other; there is no unopposed reason supporting the conclusion. Since
either my brother or sister must be wrong, it is therefore easy to imagine that they might both
be wrong, and wrong in this way: perhaps my father will leave his money to my brother and my
mother will leave her money to my sister, so that I will inherit nothing.
5 Comments on the example
First, in case this example does not yet seem convincing, it might help to modify things a bit.
Suppose, then, that I had written only to my brother, and received his response-that my father
had named him as sole beneficiary, but that my mother would leave her money to me. That is,
suppose my starting point is the information depicted in the left-hand side of Figure 3. In this new
situation, should I conclude that I will inherit half a million dollars, and therefore place a deposit
on the yacht?
Some might say no-that even in this simplified situation I should not make such a important
decision on the basis of my brother's word alone. But this objection misses the point. Most of what
we know, we know through sources of information that are, in fact, defeasible. By hypothesis, we
can suppose that my brother is arbitrarily reliable, as reliable as any defeasible source of information
could possibly be-as reliable as perception, for instance, or the bank officer's word that the money
has actually been deposited in my account. If we were to reject information like this, it is hard
to see how we could get by in the world at all. When a source of defeasible information that is,
by hypothesis, arbitrarily reliable tells me that I will inherit half a million dollars, and there is no
conflicting evidence in sight, it is reasonable for me to accept this statement, and to act on it. Note
that both of the two skeptical alternatives yield this outcome in our simplified situation, since the
initial information, represented by the left-hand side of Figure 3, generates only a single argument
extension, in which the conclusion that I will inherit half a million dollars is supported by a single
argument.
Now suppose that, at this point, I hear from my equally reliable sister with her conflicting
information-that she is my mother's beneficiary, but that my father will leave his money to me.
As a result, I am again in the situation depicted in the full Figure 3, with two argument extensions,
and in which the statement that I will inherit half a million dollars is supported only as a floating
conclusion. Ask yourself: should my confidence in the statement that I will inherit half a million
dollars be diminished in this new situation, now that I have heard from my sister as well as my
brother? If it seems that my confidence can legitimately be diminished-that this new information
casts any additional doubt on the outcome-then it follows that floating conclusions are somewhat
less secure than conclusions that are uniformly supported by a common argument. And that is all
we need. The point is not that floating conclusions might be wrong; any conclusion drawn through
defeasible reasoning might be wrong. The point is that a statement supported only as a floating
conclusion seems to be less secure than the same statement when it is uniformly supported by
a common argument. As long as there is this difference in principle, it is coherent to imagine a
skeptical reasoner whose standards are calibrated so as to accept statements that receive uniform
support, but to reject floating conclusions.
As a second comment, notice that, if floating conclusions pose a problem, it is not just a problem
for argument systems, but also for traditional nonmonotonic formalisms, such as default or model-
preference logics. Indeed, the problem is even more serious for these traditional formalisms. With
argument systems, where the extensions generated are argument extensions, it is at least possible
to avoid floating conclusions by adopting the first of our two skeptical alternatives-endorsing
only those arguments belonging to each extension, and then endorsing only the conclusions of the
endorsed arguments. Since arguments are represented explicitly in these systems, they can be
used to filter out floating conclusions. In most traditional nonmonotonic logics, arguments are
suppressed, and so the materials for carrying out this kind of filtering policy are not even available.
To illustrate, a natural representation of the information from our yacht example in default
logic is the theory
describes what my brother and sister said and
reflects the defaults that whatever my brother and sister say should be taken as true. This theory
has two extensions:
The extensions of default logic are statement extensions, and so the only possible policy for skeptical
reasoning appears to be: intersect the extensions. Since the statement F - M belongs to both
extensions, skeptical reasoning in default logic tells me, immediately and without ambiguity, that
I will inherit half a million dollars.
Of course, default logic is essentially a proof-theoretic formalism, and it is easy to see how
it could be modified so that the extensions defined would contain proofs rather than statements;
such a modification would then allow for floating conclusions to be filtered out by a treatment
along the lines of our first alternative. 6 It is harder to see how floating conclusions could be
avoided in model-preference logics. In a circumscriptive theory, for instance, the yacht example
could naturally be expressed by supplementing the facts BA(:F - M ) and SA(F - :M ) with
the statements (BA(:F - M ) - :Ab b
preferring those models in which as few as possible of the propositions Ab b
and Ab s
-the abnormalities
associated with the rare situations in which my brother or sister is mistaken-are true. Of
course, there can be no models in which neither Ab b
not Ab s
is true. The most preferred models
will therefore be those in which only one of these abnormalities holds. The statement F - M is
true in all of these models, and would therefore follow as a circumscriptive consequence. 7
6 Objections to the example
I have heard two objections worth noting to the yacht example as an argument against floating
conclusions.
The first focuses on the underlying methodology of logical formalization. Even though what
my brother literally said is "Father is going to leave his money to me, but Mother will leave her
money to you," one might argue that the real content of his statement-what he really meant-is
better conveyed through the two separate sentences "Father is going to leave his money to me"
and "Mother will leave her money to you." In that case, rather than formalizing my brother's
assertion through the single conjunction :F - M , it would be more natural to represent its content
through the separate statements :F and M ; and the content of my sister's assertion could likewise
be formalized through the separate statements F and :M .
Considered from the standpoint of default logic, the situation could then be represented through
the new default theory
6 One suggested modification of default logic that is particularly relevant, because it bears directly on examples of
the sort considered here, can be found in Brewka and Gottlob [2].
7 This form of circumscription, which involved minimizing the truth of statements rather than the extensions of
predicates, is a special case of the more usual form; see Lifschitz [7, pp. 302-303] for a discussion.
describing what now appear to be the four independent assertions made by my brother and sister,
and with
carrying the defaults that any assertion by my brother or sister should be taken as true, if possible.
This new default theory would then have four extensions:
And since not all of these extensions contain the statement F - M , the policy of defining skeptical
conclusions simply by intersecting the statements supported by each extension no longer leads, in
this case, to the conclusion that I will inherit half a million dollars.
The idea behind this objection is that the problems presented by floating conclusions might be
avoided if we were to adopt a different strategy for formalizing the statements taken as inputs by
the logical system, which would involve, among other things, articulating conjunctive inputs into
their conjuncts. This idea is interesting, has some collateral benefits, and bears certain affinities
to proposals that have been suggested in other contexts. 8 Nevertheless, in the present setting,
the strategy of factoring conjunctive statements into their conjuncts in order to avoid undesirable
floating conclusions suggests a procedure that might be described as "wishful formalization"-
carefully tailoring the inputs to a logical system so that the system then yields the desired outputs.
Ideally, a logic should take as its inputs formulas conforming as closely as possible to the natural
language premises provided by a situation, and then the logic itself should tell us what conclusions
follow from those premises. Any time we are forced to adopt a less straightforward representation
of the input premises in order to avoid inappropriate conclusions-replacing conjunctions with their
conjuncts, for example-we are backing away from that ideal. By tailoring the inputs in order to
assure certain outputs, we are doing some work for the logic that, in the ideal case, the logic should
be doing for us.
The second objection to the yacht example as an argument against floating conclusions concerns
the method for evaluating supported statements. Part of what makes this example convincing as a
reason for rejecting the floating conclusion that I will inherit half a million dollars is the fact that it is
developed within the context of an important practical decision, where an error carries significant
consequences: I will lose my large deposit. But what if the consequences were less significant?
Suppose the deposit were trivial: one dollar, say. In that case, many people would then argue that
the support provided for the proposition that I will inherit half a million dollars-even as a floating
8 Imagine, for example, that my brother asserts a statement of the form P - Q, where it turns out that P is
a logical contradiction-perhaps a false mathematical statement-but Q expresses a perfectly sensible proposition
that just happens to be conjoined with P for reasons of conversational economy. Here, the representation of the
situation through the default theory hW;Di with
would prevent us from drawing either P or Q as a conclusion, since the justification for the default could not be
satisfied. But if the situation were represented through the articulated theory hW;Di with
and we could at least draw the conclusion Q. This idea of articulating
premises into simpler components, in order to draw the maximum amount of information out of a set of input
statements without actually reaching contradictory conclusions, has also been studied in the context of relevance
logic; a carefully formulated proposal can be found in Section 82.4 of Anderson et al. [1].
conclusion- would be sufficient, when balanced against the possibility for gain, to justify the risk
of losing my small deposit. The general idea behind this objection is that the proper notion of
consequence in defeasible reasoning is sensitive to the risk of being wrong. The evaluation of a logic
for defeasible reasoning cannot, therefore, be made outside of some particular decision-theoretic
setting, with particular costs assigned to errors; and there are certain settings in which one might
want to act even on the basis of propositions supported only as floating conclusions.
This is an intriguing objection. I will point out only that, if accepted, it suggests a major revision
in our attitude toward nonmonotonic logics. Traditionally, a logic-unlike a system for probabilistic
or evidential reasoning-is thought to classify statements into only two categories: those that follow
from some set of premises, and those that do not. The force of this objection is that nonmonotonic
logics should be viewed, instead, as placing statements into several categories, depending on the
degree to which they are supported by a set of premises, with floating conclusions then classified,
not necessarily as unsupported, but perhaps only as less firmly supported than statements that are
justified by the same argument in every extension.
7 Other examples
Once the structure of the yacht example is understood, it is easy to construct other examples along
similar lines: just imagine a situation in which two sources of information, or reasons, support a
common conclusion, but also undermine each other, and therefore undermine the support that each
provides for the common conclusion.
Suppose you are a military commander pursuing an enemy that currently holds a strong defensive
position. It is suicide to attack while the enemy occupies this position in force, but you
have orders to press ahead as quickly as possible, and so you send out your reliable spies. After a
week, one spy reports back that there can now be only a skeleton force remaining in the defensive
position; he has seen the main enemy column retreating through the mountains, although he also
noticed that they sent out a diversionary group to make it appear as if they were retreating along
the river. The other spy agrees that only a skeleton force remains in the defensive position; he has
seen the main enemy column retreating along the river, although he notes that they also sent out
a diversionary group to make it appear is if they were retreating through the mountains. Based
on this information, should you assume at least that the main enemy force has retreated from the
defensive position-a floating conclusion that is supported by both spies-and therefore commit
your troops to an attack? Not necessarily. Although they support a common conclusion, each
spy undermines the support provided by the other. Perhaps the enemy sent out two diversionary
groups, one through the mountains and one along the river, and managed to fool both your spies
into believing that a retreat was in progress. Perhaps the main force still occupies the strong
defensive position, awaiting your attack.
Or suppose you attend a macroeconomics conference during a period of economic health, with
low inflation and strong growth, and find that the community of macroeconomic forecasters is
now split right down the middle. One group, working with a model that has been reliable in
the past, predicts that the current strong growth rate will lead to higher inflation, triggering an
economic downturn. By tweaking a few parameters in the same model, the other group arrives at a
prediction according to which the current low inflation rate will actually continue to decline, leading
to a dangerous period of deflation and triggering an economic downturn. Both groups predict an
economic downturn, but for different and conflicting reasons-higher inflation versus deflation-and
so the prediction is supported only as a floating conclusion. Based on this information, should you
accept the prediction, adjusting your investment portfolio accordingly? Not necessarily. Perhaps
the extreme predictions are best seen as undermining each other and the truth lies somewhere in
between: the inflationary and deflationary forces will cancel each other out, the inflation rate will
remain pretty much as it is, and the period of economic health will continue.
There is no need to labor the point by fabricating further examples in which floating conclusions
are suspect. But what about the similar cases, exemplifying the same pattern, that have actually
been advanced as supporting floating conclusions, such as Ginsberg's political extremist example
from

Figure

I have always been surprised that this particular example has seemed so persuasive to so many
people. The example relies on our understanding that individuals adopt a wide spectrum of attitudes
regarding the appropriate use of military force, but that Quakers and Republicans tend to be
doves and hawks, respectively-where doves and hawks take the extreme positions that the use of
military force is either never appropriate, or that it is appropriate in response to any provocation,
even the most insignificant. Of course, Nixon's own position on the matter is well known. But
if I were told of some other individual that he is both a Quaker and a Republican, I would not
be sure what to conclude. It is possible that this individual would adopt an extreme position,
as either a dove or a hawk. But it seems equally reasonable to imagine that such an individual,
rather than being pulled to one extreme of the other, would combine elements of both views into
a more balanced, measured position falling toward the center of the political spectrum-perhaps
believing that the use of military force is sometimes appropriate, but only as a response to serious
provocation. Given this real possibility, it might be appropriate to take a skeptical attitude, not
only toward the questions of whether this individual would be a dove or a hawk, but also toward
the question whether he would adopt a politically extreme position at all.
Another example appears in Reiter's original paper on default logic, where he suggests [12,
pp. 86-87] defaults representing the facts that people tend to live in the same cities as their spouses,
but also in the cities in which they work, and then asks us to consider the case of Mary, whose
spouse lives in Toronto but who works in Vancouver. Coded into default logic, this information
leads to a theory with two extensions, in one of which Mary lives in Toronto and in one of which
she lives in Vancouver. Reiter seems to favor the credulous policy of embracing a particular one
of these extensions, either concluding that Mary lives in Toronto or concluding that Mary lives in
But then, in a footnote, he also mentions what amounts to the skeptical possibility of
forming only the belief that Mary lives in either Toronto or Vancouver-where this proposition is
supported, of course, as a floating conclusion.
Given the information from this example, I would, in fact, be likely to conclude that Mary lives
either in Toronto or Vancouver. But I am not sure this conclusion should follow as a matter of
logic, even default logic. In this case, the inference seems to rely on a good deal of knowledge about
the particular domain involved, including the vast distance between Toronto and Vancouver, which
effectively rules out any sort of intermediate solution to Mary's two-body problem.
By contrast, consider the happier situation of Carol, who works in College Park, Maryland, but
whose spouse works in Alexandria, Virginia; and assume the same two defaults-that people tend
to live in the same cities as their spouses, but also tend to live in the cities in which they work.
Represented in default logic, this information would again lead to a theory with multiple extensions,
in each of which, however, Carol would live either in College Park or in Alexandria. Nevertheless,
I would be reluctant to accept the floating conclusion that Carol lives either in College Park or in
Alexandria. Just thinking about the situation, I would consider it equally likely that Carol and her
spouse live together in Washington, DC, within easy commuting distance of both their jobs.
Why is it so widely thought that floating conclusions should be accepted by a skeptical reasoner,
so that a system that fails to generate these conclusions is therefore incorrect? It is hard to be
sure, since this point of view is generally taken as an assumption, rather than argued for, but we
can speculate.
Suppose an agent believes that either the statement B or the statement C holds, that B implies
A, and that C also implies A. Classical logic then allows the agent to draw A as a conclusion;
this is a valid principle of inference, sometimes known as the principle of constructive dilemma.
The inference to a floating conclusion is in some ways similar. Suppose a default theory has two
, that the extension
contains the statement A, and that the extension
also contains the statement A. The standard view is that a skeptical reasoner should then draw A
as a conclusion, even if it is not supported by a common argument in the two extensions.
Notice the difference between these two cases, though. In the first case, the classical reasoning
agent believes both that B and C individually imply A, and also that either B or C holds. In the
second case, we might as well suppose that the skeptical reasoner knows that A belongs to both
the extensions
, so that both E 1
individually imply A. The reasoner is therefore
justified in drawing A as a conclusion by something like the principle of constructive dilemma-as
long as it is reasonable to suppose, in addition, that either E 1
or
is correct. This is the crucial
assumption, which underlies the standard view of skeptical reasoning and the acceptance of floating
conclusions. But is this assumption required? Is it necessary for a skeptical reasoner to assume,
when a theory leads to multiple extensions, that one of those extensions must be correct?
Suppose that each of the theory's multiple extensions is endorsed by some credulous reasoner.
Then the assumption that one of the theory's extensions must be correct is equivalent to the
assumption that one of these credulous reasoners is right. But why should a skeptical reasoner
assume that some credulous reasoner, following an entirely different reasoning policy, must be
right? Of course, there may be situations in which it is appropriate for a skeptical reasoner to
adopt this standard view-that one of the various credulous reasoners must be right, but that it is
simply unclear which one. That might be the extent of the skepticism involved. But there also seem
to be situations in which a deeper form of skepticism is appropriate-where each of the multiple
extensions is undermined by another to such an extent that it seems like a real possibility that
all of the credulous reasoners could be wrong. The yacht, spy, and economist examples illustrate
situations that might call for this deeper form of skepticism.
As a policy for reasoning with conflicting defaults, the notion of skepticism was originally
introduced into the field of nonmonotonic logic to characterize the particular system presented in
[6], which did not involve the assumption that one of a theory's multiple extensions must be correct,
and did not support floating conclusions. By now, however, the term is used almost uniformly to
describe approaches that do rely on this assumption, so that the "skeptical conclusions" of a theory
are generally identified as the statements supported by each of its multiple extensions, including
the floating conclusions. Of course, there is nothing wrong with this usage of the term, as a
technical description of the statements supported by each extension-except that it might tend to
cut off avenues for research, suggesting that we now know exactly how to characterize the skeptical
conclusions of a theory, so that the only issues remaining are matters concerning the efficient
derivation of these conclusions. On the contrary, if we think of skepticism as the general policy of
withholding judgment in the face of conflicting defaults, rather than arbitrarily favoring one default
or another, there is a complex space of reasoning policies that could legitimately be described as
skeptical, many of which involve focusing on the arguments that support particular conclusions,
not just the conclusions themselves.

Acknowledgments

This paper got its start in a series of conversations with Tamara Horowitz. I am grateful for
valuable comments to Aldo Antonelli, David Makinson, and Richmond Thomason, and to a number
of participants in the Fifth International Symposium on Logical Formalizations of Commonsense
Reasoning, particularly Leora Morgenstern, Rohit Parikh, Ray Reiter, and Mary Anne Williams.



--R

Entailment: The Logic of Relevance and Necessity

Essentials of Artificial Intelligence.
Moral dilemmas and nonmonotonic logic.
Some direct theories of nonmonotonic inheritance.
A skeptical theory of inheritance in nonmonotonic semantic networks.

General patterns in nonmonotonic reasoning.
"directly skeptical"

Logics for defeasible argumentation.
A logic for default reasoning.
Resolving ambiguity in nonmonotonic inheritance hierarchies.
The Mathematics of Inheritance Systems.
A clash of intuitions: the current state of nonmonotonic multiple inheritance systems.
Values and the heart's command.
--TR
The mathematics of inheritance systems
A skeptical theory of inheritance in nonmonotonic semantic networks
Floating conclusions and zombie paths
Resolving ambiguity in nonmonotonic inheritance hierarchies
Essentials of artificial intelligence
General patterns in nonmonotonic reasoning
Some direct theories of nonmonotonic inheritance
Circumscription
Well-founded semantics for default logic

--CTR
Shingo Hagiwara , Satoshi Tojo, Stable legal knowledge with regard to contradictory arguments, Proceedings of the 24th IASTED international conference on Artificial intelligence and applications, p.323-328, February 13-16, 2006, Innsbruck, Austria
Pietro Baroni , Massimiliano Giacomin , Giovanni Guida, SCC-recursiveness: a general schema for argumentation semantics, Artificial Intelligence, v.168 n.1, p.162-210, October 2005
Yoshitaka Suzuki, Additive Consolidation with Maximal Change, Electronic Notes in Theoretical Computer Science (ENTCS), 165, p.177-187, November, 2006
Pietro Baroni , Massimiliano Giacomin , Giovanni Guida, Self-stabilizing defeat status computation: dealing with conflict management in multi-agent systems, Artificial Intelligence, v.165 n.2, p.187-259, July 2005
