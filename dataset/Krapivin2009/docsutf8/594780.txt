--T
A Multi-Resolution Content-Based Retrieval Approach for Geographic Images.
--A
Current retrieval methods in geographic image databases use only pixel-by-pixel spectral information. Texture is an important property of geographical images that can improve retrieval effectiveness and efficiency. In this paper, we present a content-based retrieval approach that utilizes the texture features of geographical images. Various texture features are extracted using wavelet transforms. Based on the texture features, we design a hierarchical approach to cluster geographical images for effective and efficient retrieval, measuring distances between feature vectors in the feature space. Using wavelet-based multi-resolution decomposition, two different sets of texture features are formulated for clustering. For each feature set, different distance measurement techniques are designed and experimented for clustering images in a database. The experimental results demonstrate that the retrieval efficiency and effectiveness improve when our clustering approach is used.
--B
Introduction
Satellite remote sensing development generated huge amount of image data during the last two
decades. With the launch of the new breed of high spatial resolution satellite systems, the volume
This research is partially supported by Xerox Corporation and NCGIA at Buffalo.
of digital image data will significantly increase. Paralleling with the remote image sensing is the
availability of Geographic Information System (GIS) data such as digital orthophotographs and
digital elevation models that are available in pixel format and in sheer volumes. Thus, there is
a great demand for effective retrieval mechanisms. In processing these geographic images, the
ultimate interest is to recognize and locate specific contents. A content-based retrieval approach is
paramount to organizing geographic images. In the design of such retrieval approaches, significant
features must first be extracted from geographical data in their pixel format. The features are
numerical measurements to characterize an image. These features can then be used to cluster and
index the images for efficient retrieval. Methods have been developed for indexing and accessing
alpha-numerical data in traditional databases. However, the traditional approaches to indexing
may not be appropriate in the context of content-based image retrieval [CYDA88, RS91, BPJ93].
In this context, a challenging problem arises with many image databases, within which queries are
posed via visual or pictorial examples (termed visual queries). A typical visual query might entail
the location of all images in a database that contain a subimage similar to a given query image.
Such a query is well suited to and most appropriate for geographic images in identifying specific
geographic contents such as land use/land cover types.
Texture in images has been an important aspect for geographic image classification and retrieval
[Har79, Joh94, RW96, WH90], due primarily to the heterogeneity nature of geographic
images and the association between the texture patterns and the geographic contents. The variety
and complexity of geographic texture present a challenge as well as an impetus for seeking
more effective approaches in feature representation. We have conducted experimental research
on image data retrieval based on texture feature extraction [SZ97, RSZSM97, SZB97]. In most
existing content-based retrieval approaches, feature vectors of images are first constructed (e.g.,
from wavelet transforms), which are then used to distinguish images through measuring distances
between feature vectors. Our experimental results demonstrate that this type of approaches can be
effectively used to perform content-based retrieval based on similarity comparison between images.
However, we encounter a critical problem that the feature vectors of some semantically irrelevant
images may be located very close in the feature space. Figure 1 presents two images of water
and stone between which the distance of the feature vectors is very small, but these images are
semantically not similar. Given a query such that its feature vector is located in the neighborhood
of the feature vectors of the two given images, both images are highly possible to be retrieved
together in response to the query. Thus, indexing alone, using R-tree or its variants based on the
closeness of feature vectors in the feature space, sometimes may not provide satisfactory solutions.
An effective clustering approach needs to be integrated into indexing techniques for efficient and
effective retrieval of image data. Once the query is narrowed to a specific category, image retrieval
can then proceed efficiently.
(a) (b)

Figure

1: Semantically different Images with similar feature vectors.

Figure

shows two arbitrary shape semantic clusters C 1 and C 2 in a two-dimensional feature
space. We may assume that C 1 and C 2 represent the images of stone and water in the feature space.
Consider the query image q which belongs to the cluster C 1 . If we only consider the closeness of
feature vectors in the feature space to return relevant images, we may retrieve many images from
cluster C 2 that are semantically irrelevant. Indexing trees such as R-trees are very efficient in
retrieving the nearest neighbors of the query image, but since they do not consider semantics
of images, the retrieved images might be semantically irrelevant. If we successfully classify the
database images into different semantic clusters, a visual query can be quickly narrowed to a
specific category. Therefore, combining clustering with R-tree related indexing, image retrieval can
proceed both effectively and efficiently.
x
x
x
x
x
x
x
x
x
x
x
xx
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

Figure

2: Two semantic clusters.
In this paper, we present an approach to effective and efficient retrieval of images in large
geographical image database systems. The goal is, given a query image of size n \Theta n pixels, to
retrieve all the database images of size N \Theta N (where n - N ), that contain a portion similar to
the query image. Database images have been decomposed into smaller segments (down to n \Theta n
segments) offline. The query image will be compared to the corresponding segments (as will be
discussed later). A clustering approach is designed to be incorporated into the existing indexing
methods [SRF87, BKSS90, LJF94] to achieve the effectiveness and efficiency. Similar to most of
other current clustering methods, our approach cannot distinguish overlapping clusters 1 . Thus,
1 The proposed method in [SCZ98] handles the overlapping clusters using heterogeneous features.
we assume that different clusters do not overlap in the feature space. The semantic clusters can
have arbitrary shapes or can be disconnected. We first choose a set of training samples to identify
predefined semantics clusters (for example, residential or agriculture). These clusters include the
semantically similar images. Then using a hierarchical method we find template images representing
each cluster. This approach helps consider both semantics and feature vectors in classifying images.
Using the multi-resolution property of wavelet transforms, we extract the features at different scales
where only the coarse features are used in clustering. In our clustering approach, distribution of
feature vectors in the feature space is also considered. Combining the proposed clustering with any
existing indexing approach, our experiments demonstrate that retrieval from clustered database
outperforms the methods that are based only on nearest neighbor retrieval. In addition, since the
retrieval of images is narrowed to a specific category, image retrieval can proceed more efficiently.
Since geographical images (specially airphoto images) are rich in texture, and have relatively well-defined
clusters, it makes our approach, which extracts multi-resolution texture features and clusters
the images, a good candidate to be used.
The remainder of this paper is organized as follows. Section 2 presents the approach to multi-resolution
texture feature extraction. Section 3 discusses the application of the feature extraction
approach on image clustering and retrieval. Experiments are presented in Section 4. Concluding
remarks are offered in Section 5.
In this section, we will first discuss the importance of texture features in retrieval. We will then
introduce wavelet transforms and the wavelet-based texture features extracted from images.
2.1 Texture Features
In the current methods, spectral features (pixel values) are usually used to retrieve images from a
geographical image database. However, spectral features alone may not be sufficient to characterize
a geographical image because they fail to provide information about spatial pattern of pixels.
One way of obtaining better classifications and retrieval is the use of spatial pattern recognition
techniques that are sensitive to factors such as image texture and pixel content. In addition, using
texture features of a group of pixels instead of individual pixels can reduce the information to be
processed. Hence it decreases the required memory storage and computation for image retrieval
and clustering. Because of the spatial nature of geographic images, texture has been used to
distinguish among the images [RW96, Lan80, HK69, MM96, Joh94, GT83]. However, compared to
purely spectral based procedures, texture-based retrieval systems have received limited attention
in remote sensing in the past [LK94].
Different methods defining texture were proposed to model natural texture feature or to be
used in classification. These approaches have included the use of Fourier transforms [SF86], fractals
[Man77], random mosaic models [AR81, JMV81], mathematical morphology [DP89], syntactic
methods, and linear models [CJ83]. However, most of these approaches have been used in the field
of pattern recognition and have not been applied to the analysis of remotely sensed data [RW96].
One method in texture feature extraction that has been used for remotely sensed data is to pass a
filter over the images and use the variance of the pixels covered by the filter as the value of the pixel
in the texture image [AN91, BN91, Jen79]. Woodcock and Ryherd found that using the above local
variance texturing technique in an adaptive windowing procedure resulted in an improved image
for certain applications [WR89]. The location of the adaptively located window used to calculate
local variance is the window with the lowest local variance of all windows that include the pixel.
They then apply a multi-pass, pair-wise, region-growing algorithm to find spatially cohesive units,
or "regions", in the image [RW96].
Johnson used a knowledge-based approach to classification of built-up land from multi-spectral
data. The approach involves spectral classification, determination of size and neighbor relations for
the segments in the spectrally classified image, and rule-based classification of the image segments
into land-use categories [Joh94]. The implementation is slow, and performance problems were
encountered due to the large number of objects being processed [Joh94].
Gray-level co-occurrence matrix, a matrix of second order probabilities, has been used in texture
analysis [BL91, HTC86]. The element s(i; j; v) of the co-occurrence matrix is the estimated
probability of going from gray-level i to j, given the displacement vector \Deltay). A set of
statistical values computed from co-occurrence matrices, such as entropy, angular second momen-
tum, and inverse difference moment have also been used [HSD73, PF91]. In practice, there are two
problems regarding this approach. The first is that the co-occurrence matrix depends not only on
the spatial relationship of gray-levels, but also on regional intensity background variation within
the image. The second issue is the choice of displacement vector because the co-occurrence
matrix characterizes the spatial relationship between pixels for a given vector v [WH90].
Wang and He presented a statistical method for texture analysis, where they define texture unit as
the smallest complete unit that best characterizes the local texture in eight directions from a pixel.
The distribution of texture units results in texture spectrum which can be used in texture analysis
[WH90]. Since the local texture information for a pixel is extracted from a neighborhood of 3 \Theta 3
pixels, instead of one displacement vector used in the gray-level co-occurrence matrix, their method
is more complete for the characterization of texture. They provided limited experimental results.
The textural structures that can be described within a neighborhood are naturally limited to
those which are observable within the size of neighborhood. Hence, features that are extracted based
on measurements within a fixed size neighborhood (for example 3 \Theta 3 pixels window) have poor
discrimination power when applied to textures not observable within the neighborhood because of
wrong scale [BGW91]. All the above texture analysis methods share this common problem. This
issue motivates the use of a multi-resolution method.
Bigun et al formulated a general n-D least mean square problem whose solution facilitates the
extraction of dominant orientation [BGW91]. In 2-D space, they used the linear symmetry along
with the Laplacian pyramids approach, to produce feature images. The linear symmetry features
directly measure the dominant orientation information in the frequency channels [BGW91]. QBIC is
a content-based image retrieval system which retrieves images based on their color, shape, or texture
In QBIC, texture features are based on modified versions of the coarseness, contrast,
and directionality features proposed in [TMY78]. The distance between the three-elements feature
vectors is measured by weighted Euclidean distance. However, new mathematical representations of
image attributes are needed in QBIC [FSN 95]. Features that describe new image properties such
as alternate texture measures or that are based on fractals or wavelet representations, for example,
may offer advantages of representations, indexability, and ease of similarity matching [FSN
Jacobs et al presented a searching algorithm for query images in an image database [JFS95].
They apply wavelet transform on query and database images. The wavelet coefficients are then
truncated and only the coefficients with largest magnitudes are used in comparing images. They
developed an image query metric which uses those truncated and quantized wavelet coefficients.
According to them, wavelet coefficients provide information that is independent of the original
resolution. Thus, a wavelet scheme allows queries to be specified to any resolution (potentially
different to that of database images) [JFS95]. Hence they call their method multi-resolution image
querying. Manjunath and Ma used Gabor wavelet transform to extract texture features and showed
that it performed better than other texture classification methods [MM96]. They used mean and
variance of frequency sub-bands to represent texture. In our method, we take advantage of multi-resolution
property of wavelet explicitly.
In our approach, as will be explained later, we apply wavelet transform to extract texture
features. Based on the property that was mentioned in [JFS95], a query image can have a different
size from that of a database image, which we can use. In addition to that, by applying wavelet
transform, we can have information about images at different scales (resolutions) from fine to coarse
at the same time. Our interpretation of the term (multi)resolution is different from that of [JFS95].
In their case, resolution indicates number of pixels in the image, and since number of pixels of
the query image and the database image do not necessarily have to be the same, they call their
method multi-resolution image querying. In our method, since we extract the image features at
different scales or levels of details (based on number of levels in wavelet transform), we have a
multi-resolution representation of the image. Having information about images at different scales
(resolutions), we can control the desired level of accuracy in comparing images. For example, in
clustering images where we roughly categorize images, we use only the coarse features, whereas
in image retrieval, all the fine details of images will be used. However, the method proposed in
[JFS95] uses a distance metric with fixed accuracy. Moreover, their method directly compares
the m largest wavelet coefficients of images one by one. Thus, if the image is translated, so will
the corresponding wavelet coefficients. Hence the result of comparison will be very different. In
our method, we compare derived values (mean, variance, or number of edge pixels) from each
of the corresponding frequency sub-bands, resulting in less sensitive comparison with respect to
translation. The method by Jacobs et al has the advantage of being fast. However, it has the
common problem of the nearest neighbor retrieval approaches that just rely on the closeness of
the feature vectors without considering the semantics of images. As we explained in the previous
section, such methods sometimes may not provide satisfactory solutions. In our approach, we
consider the semantics of images through clustering which results in more effective retrieval.
Feature extraction may be performed on either a whole image or the segments of images. We
assume that images are decomposed into segments properly. Some decomposition approaches can
be found in [SC94a, SC94b, RSZSM97, SRGZ97]. Upon the proper decomposition of images, the
system extracts the features of all the segments of images. The query image will be compared to
the corresponding segments of database images with the proper size. In our implementation, we
used nona-tree decomposition [RSZSM97, SRGZ97].
Nona-tree decomposition is a block-oriented approach in which images (and their segments)
are hierarchically decomposed into nine quadrants. The nine overlapping quadrants are uniformly
distributed segments. If there are k levels in nona-tree, the size of its segments will be N 2 , N 2
, where N 2 is the size of the original image. A query image is compared to the smallest
segments in nona-tree whose size is greater than or equal to the size of the query image. If the size
of nona-tree's smallest segments is larger than that of the query image, the query image will not
be compared to any of the segments. For example, if a nona-tree has segments of sizes 128\Theta128,
64\Theta64, and 32\Theta32, given a query image of size 64\Theta64, it will be compared to the 64\Theta64 segments.
A query image of size 60\Theta60 will be compared to the 64\Theta64 segments but a 24\Theta24 query image
will not be compared to any of the segments. In general, the segments generated by block-oriented
decomposition methods such as quad-tree, quin-tree, or nona-tree may not perfectly align the
portion which matches the query image. For example, in quad-tree, in the worst case, only 25% of
the matching segment will be covered. However, in [RSZSM97, SRGZ97], we proved that nona-tree
segments at least cover 56% of the matching segment. In average case, a larger portion of matching
segment will be covered, and our experiments showed that nona-tree performs better than other
block-oriented decomposition approaches [RSZSM97, SRGZ97].
2.2 Wavelet Transform
Wavelet transform is a type of signal representation that can give the frequency content of the signal
at a particular instant of time. In this context, one row/column of image pixels can be considered
as a signal. Applying a wavelet transform on such a signal decomposes the signal into different
frequency sub-bands (for example, high frequency and low frequency sub-bands). Initially, regions
of similar texture need to be separated out. This may be achieved by decomposing the image in
the frequency domain into a full sub-band tree using filter banks [Vai93]. Each of the sub-bands
obtained after filtering has uniform texture information. A filter bank based on wavelets could be
used to decompose the image into low-pass and high-pass spatial-frequency bands [Mal89a].
We will now briefly review the wavelet-based multi-resolution decomposition. More details can
be found in Mallat's paper [Mal89b]. To have the multi-resolution representation of signals we can
use a discrete wavelet transform. We can compute a coarser approximation of input signal A 0 by
convolving it with the low pass filter ~
H and down sampling the signal by two [Mal89b]. By down
sampling, we mean skipping every other signal sample (for example a pixel in an image). All the
discrete approximations A j , is the maximum possible scale), can thus be computed
from A 0 by repeating this process. Scales become coarser with increasing j. Figure 3 illustrates
the method.
A
A
A
G
G

Figure

3: Block diagram of multi-resolution wavelet transform.
We can extract the difference of information between the approximation of signal at scale
and j. D j denotes this difference of information and is called detail signal at the scale j. We
can compute the detail signal D j by convolving A j \Gamma1 with the high pass filter ~
G and returning
every other sample of output. The wavelet representation of a discrete signal A 0 can therefore be
computed by successively decomposing A j into A j+1 and D j+1 for This representation
provides information about signal approximation and detail signals at different scales. We denote
wavelet representation of signal A 0 after K levels as . The
idea of using multi-resolution property of wavelets in clustering is to use the features of the wavelet
coefficients at the coarse scale levels.
Corresponding to the lowpass filter, there is a continuous-time scaling function OE(t), and corresponding
to the highpass filter, there is a wavelet !(t). The dilation equation produces OE(t), and
the wavelet equation produces !(t) [SN96]. For example, for Haar wavelet transform with ~
[1=
2], and ~
2], the dilation equation is
and the wavelet equation is

Figure

4 shows the Haar wavelet !(t).1t
w(t)

Figure

4: The Haar wavelet !(t).
We can easily generalize wavelet model to 2 dimensions for images, in which we can apply 2
separate one-dimensional transforms [HJS94]. The image is first filtered along the horizontal (x)
dimension, resulting in a lowpass image L and a highpass image H. We then down sample each
of the filtered images in the x dimension by 2. Both L and H are then filtered along the vertical
(y) dimension, resulting in four subimages: LL, LH, HL, and HH. Once again, we down sample
the subimages by 2, this time along the y dimension. The two-dimensional filtering decomposes an
image into an average signal (LL) and three detail signals which are directionally sensitive: LH
emphasizes the horizontal image features, HL the vertical features, and HH the diagonal features.

Figure

5-a shows a sample airphoto image. Figures 5-b,c, and d show the wavelet representation
of the image at three scales from fine to coarse. At each level, sub-band LL (the wavelet approximation
of the original image) is shown in the upper left quadrant. Sub-band LH (horizontal edges)
is shown in the upper right quadrant, sub-band HL (vertical edges) is displayed in the lower left
quadrant, and sub-band HH (corners) is in the lower right quadrant.
Our feature extraction and clustering methods can use any appropriate wavelet transforms such
as Haar, Daubechies, Cohen-Daubechies-Feauveau ((2,2) and (4,2)), or Gabor wavelet transforms
a) b) c) d)

Figure

5: Multi-resolution wavelet representation of an airphoto image: a)original image; b) wavelet
representation at scale 1; c) wavelet representation at scale 2; d) wavelet representation at scale 3.
[Vai93, SN96, URB97, MM96]. Applying wavelet transform on images results in wavelet coefficients
corresponding to each sub-band. We can extract different features from wavelet coefficients of each
of these sub-bands. Next subsection explains the features that we used in the experiments.
2.3 Image Features
In clustering database images, different kinds of features such as shape, color, texture, layout, and
position of various objects in images can be used. Texture in images has been recognized as an
important aspect of human visual perception [TMY78, Har79, Joh94, RW96, WH90]. Tamura et al.
[TMY78] have discussed various texture features including contrast, directionality, and coarseness.
Contrast measures the vividness of the texture and is a function of gray-level distribution. Some
factors influencing the contrast are dynamic range of gray-levels, polarization of the distribution
of black and white on the gray-level histogram, and sharpness of edges. Directionality measures
the "peakedness" of the distribution of gradient directions in the image. Coarseness measures
the scale of texture. When two patterns differ only in scale, the magnified one is coarser. In
a geographical image database we classify images into residential, agriculture, water, and grass
clusters. These clusters have different textures. For example, their contrast is usually different;
or, the cluster of water images does not have any directionality, whereas residential images are
considered as directional images. These texture features of geographical images contain main visual
characteristics of images that can be utilized in geographical image clustering and retrieval.
Applying wavelet transform on images can provide information about the contrast of images.
Also, different sub-bands generated by wavelet transform have information about horizontal, verti-
cal, and diagonal edges in images [Mal89b], which helps in extracting features related to directionality
of images. Moreover, multi-resolution aspect of wavelet transform provides information about
images at different scales (from coarse to fine). These properties make wavelet transform a good
candidate to extract texture features of geographical images.
We calculated the mean and variance of wavelet coefficients to represent the contrast of the
image. We also count number of edge pixels in horizontal, vertical, and diagonal directions to have
an approximation of directionality of the image. These features are extracted at different scales
to use the multi-resolution property of wavelets. Edge pixels in the image have high amplitude in
detail signals (LH; HL, and HH). It means that the wavelet coefficient of such pixels has high
positive/negative value. Let Image(i; j) be a pixel in the image of size n \Theta m. Let WLH (i; j),
WHL (i; j), and WHH (i; j) be the corresponding wavelet coefficients of Image(i; j), for LH;HL,
and HH sub-bands, respectively. We define mLH as the maximum of absolute value of WLH (i; j).
That is,
To detect horizontal edge pixels, we first compute mLH . We consider Image(i; as a horizontal
edge pixel if
where ff is a factor that is determined by experiments. In our experiments, we chose ff as 0.35.
Similarly, we define
and
Image(i; is considered as an edge pixel if

Tables

1, 2, and 3 show the wavelet coefficients of Figure 5-a at scale 3 using Haar wavelet
transform. The corresponding edge pixels are shown in Figure 5-d.

Table

1: Wavelet coefficients WLH of Figure 5-a at scale 3.

Table

2: Wavelet coefficients WHL of Figure 5-a at scale 3.
28
26 43 -40 -45
28

Table

3: Wavelet coefficients WHH of Figure 5-a at scale 3.
Figure

The seven sub-bands generated after applying two levels of wavelet transform.
We tested our approach using two different sets of features. To obtain the features in feature set
1, we apply a two-level wavelet transform. For the sub-band LL of the coarsest scale of the wavelet
transform, we consider mean and variance of absolute value of wavelet coefficients as its features
?. For the other sub-bands, in addition to mean and variance, the system
counts number of edge pixels in the sub-band. So the feature vector for each of these sub-bands is
number of edge pixels ?. In this feature set, we will have seven sub-bands with
features. Figure 6 shows the seven sub-bands of image schematically. In clustering, we
just consider the features of the sub-bands of the coarsest scale of wavelet transform (11 features)
to compute the distance. Table 4 shows the extracted feature set 1 for Figure 5-a.
Number of
Sub-band Mean Variance edge pixels

Table

4: Feature set 1 of Figure 5-a.
In feature set 2, the two-level wavelet transform is applied giving seven sub-bands. The feature
vector for each sub-band is ! mean; variance ?. Each subsegment of the image has 14 features.
To compute the distance between feature vectors in clustering, we only consider the features of the
second scale of the wavelet transform (4 sub-bands, 8 features). We have extracted the feature sets
using both Haar and Daubechies wavelet transforms [SN96]. Feature set 2 for Figure 5-a is shown
in

Table

5 where Haar wavelet transform is applied.
Sub-band Mean Variance

Table

5: Feature set 2 of Figure 5-a.
To give equal contributions to all the features in determining the similarity, and to remove the
arbitrary affects of different measurement units, we normalize the feature values and recast them
in dimensionless units. To normalize the features, we first compute the mean -
f i and variance oe i of
each feature f i using the training samples. Our training samples include residential, agriculture,
water, and grass areas. Let a feature vector be normalized feature
vector be -
f n ). We normalized f i using Equation (8):
f i is the normalized value of f i . Our experiments show that we should give more (controlled)
contribution to the more important features. We can do so, by assigning weights to the features
and giving more weights to the more important features. Let
vector, where w i is the weight that is assigned to feature f i . The weighted feature vector ~
f of
feature vector f will be:
~
3 Clustering and Retrieval
Applying the feature sets introduced in Section 2, we will now present template-based image clustering
and retrieval approaches. We first describe how cluster templates are chosen. Given clustering
templates and features, images in a database can be classified based on their similarity to the
cluster templates. Based upon the resulting clusters, image retrieval can be efficiently supported.
3.1 Clustering - Related Work
Given a set of feature vectors, the feature space is usually not uniformly occupied. Clustering
the data identifies the sparse and the dense places, and hence discovers the overall distribution of
patterns of the feature vectors. In many existing clustering algorithms, k-medoid methods have been
used, where each cluster is represented by the center of gravity of the cluster. For example, PAM
(Partitioning Around Medoids) [KR90] was proposed to determine the most centrally located object
medoid for each cluster. Each non-selected object is grouped with the medoid to which it is the
most similar. CLARA (Clustering LARge Applications) [KR90] draws a sample of data set, applies
PAM on the sample, and finds the medoids of the sample. Ng and Han introduced CLARANS
(Clustering Large Applications based on RANdomaized Search) which is an improved k-medoid
method [NH94]. Ester et al presented a clustering algorithm DBSCAN relying on a density-based
notion of clusters which is designed to discover clusters of arbitrary shapes [EKSX96]. The key idea
in DBSCAN is that for each point of a cluster, the neighborhood of a given radius must contain
at least a minimum number of points, i.e. the density in the neighborhood has to exceed some
threshold. BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies) incrementally
and dynamically clusters incoming data points to produce the best clusters with the available
resources (i.e. available memory and time constraints) [ZRL96]. Ma and Manjunath used a neural
network to learn the similarity measure and partition the feature space into clusters representing
visually similar patterns [MM95].
As mentioned in Section 1, retrieval only based on closeness of feature vectors may not necessarily
give satisfactory results, because it is possible that semantically irrelevant images have
close feature vectors. Indexing trees such as R-trees and its variants have been successfully used
in the past and are very efficient in retrieving the nearest neighbors of the query image in the
feature space. However, they retrieve all the nearest neighbors, whether or not they have the same
semantic as that of the query image.
Our goal in clustering is to group together images considering their semantics. In other words,
we want to cluster images such that images with the same semantics belong to the same cluster.
These semantic clusters can be used to narrow down the search to the areas in the feature space
where images have similar semantics to that of the query image. Searching only the semantically
relevant images makes the retrieval more effective, and also more efficient. Note that, our proposed
approach is not an alternative to R-tree or its variants. These indexing trees can be integrated within
each cluster to provide better efficiency, while the clusters preserve the similarity in semantics.
Semantics of images is application dependent, for example, in a GIS visual database, we can
consider residential, water, grass, and agriculture clusters.
3.2 Template-based Clustering
To support efficient content-based image retrieval, methods have been proposed to first cluster
database images based on their similarity to predefined image templates, which are termed cluster
templates or cluster icons [WAL To retrieve database images which are similar to or
contain a query image, the query image will first be compared to the cluster templates. Only
database images in the clusters corresponding to the chosen cluster templates will be searched.
The cluster templates and their associated information (as will be explained later) approximate
the clusters. An effective clustering of database images can greatly reduce the number of images to
be searched, resulting in a more efficient retrieval. Indexing techniques can be incorporated within
each cluster to provide a faster retrieval.
R-trees can be used to find the templates representing the clusters. But since in practice,
we have high dimensional feature vectors (20 features), R-trees might suffer from "dimensionality
curse" [BKK96]. Thus, we decided to apply hierarchical clustering to find the cluster templates.
Using separate training data for each cluster, we classify images considering their semantics. The
x

x
x
x
x
x
x
x
x
x
x
x
x
x
x
x
x

(a) (b)

Figure

7: a) arbitrary shaped clusters. b) circular sub-clusters of clusters.
type of semantic clusters is application dependent and should be determined by the application
experts.
For example, in a geographical image database, we can define the clusters of residential, agricul-
ture, water, grass, and a special cluster other. The cluster other contains all images which cannot
be included in any of the residential, agriculture, water, or grass clusters. We represent clusters
by cluster templates to organize database images. In the feature space, since semantically different
image data may have their feature vectors close to each other, each cluster may have arbitrary
shape.

Figure

7-a shows an example in two dimensional space where clusters have arbitrary shapes.
Our proposed method is a hybrid (both supervised and unsupervised) approach. Using supervised
classification approach, we choose a set of training samples for each cluster. Then using
unsupervised classification we find the sub-clusters within each cluster. The centroids of those
sub-clusters are used as the cluster templates of the cluster. Figure 7-b shows such centroids within
each cluster as black square dots. Cluster other should include all the objects in Figure 7-a shown
by "   ". In a hierarchical approach, sub-clusters are defined within each cluster at different levels.
Suppose the training set of a cluster C c has n objects. Initially, we assume there are n sub-clusters
corresponding to the n objects in the cluster. We compute the distances between all pairs of
sub-clusters. We then group together the two closest sub-clusters, resulting in
We repeat the process of computing the distances between all pairs of current sub-clusters, and
grouping the two closest ones until having only one sub-cluster.
This hierarchically nested set of sub-clusters can be represented by a tree-diagram, or a dendrogram
[Gor81]. Figure 8 shows a group of 5 objects and their corresponding dendrogram. Each of
n leaves of the tree represents the single object whose label appears below it. Each position up the
tree at which branches join, has an associated numerical value d, which determines the distance
between the two grouped sub-clusters. The smaller the value of d, the more similar two sub-clusters
will be. We considered the distance between the centroids of sub-clusters as the distance between
sub-clusters. We call this method as centroid method. There are different methods to define the distance
between sub-clusters. In unweighted pair-group method using arithmetic averages (UPGMA),
the distance between two sub-clusters is the arithmetic average of the distances between the objects
d d
d2
(a) (b)

Figure

8: A group of objects and the corresponding dendrogram.
in one cluster and the objects in the other [Rom84]. In single linkage clustering method (SLINK),
the distance is the minimum of the distances between the objects in one cluster and the objects in
the other one (distance between two closest objects). The distance between sub-clusters in complete
linkage clustering method (CLINK), is defined as the maximum of the distances between objects in
the two sub-clusters [Rom84]. Applying either of these methods may give a different dendrogram.
We can cut the dendrogram of each cluster at different levels to obtain k number of sub-clusters
(cluster templates). The choice of k and the corresponding cutting distance is one of the most
difficult problems of cluster analysis, for which no unique solution exists. For example, if we cut
the dendrogram in Figure 8-b, where the distance between sub-clusters is d 1 , we will have two
sub-clusters, whereas if we cut at level d 2 , we will have three sub-clusters. Let
be the sub-cluster containing objects e 1 . If we cut a dendrogram at the level in which
the distance between the last two grouped sub-clusters is d i , then the maximum distance between
the children of the remaining sub-clusters will be d i . For example, in Figure 8-b, if we cut the
dendrogram at level d 1 , the distance between sub-clusters f1g and f2g, or f3g and f4g, or f3,4g
and f5g, will be less than d 1 .
A measure of the quality of clustering can be obtained by computing the average silhouette
width of the n image samples for each k value. Given an image i, which is assigned to
a cluster C be the average distance of i to all other images in cluster C j and b i
be the average distance of i to all images in cluster C h , where C h is the nearest neighbor cluster of
cluster C j (h 6= j). The s k is calculated as follows:
1:0. The value of s k can be used to select an optimal value of k such that s k will
be as high as possible. The maximum value of s k is known as the silhouette coefficient. In general,
a silhouette coefficient value of 0.70 or higher indicates a good clustering selection [KR90].
Assume that a cluster C c consists of m sub-clusters S c1 In clustering database im-
ages, whenever a sub-cluster S ci is chosen, the database images will be assigned to the corresponding
cluster C c . Similarly, in image retrieval, if a sub-cluster S ci is chosen, only the corresponding cluster
C c will be searched.
We also tested different methods in determining the distance between sub-clusters, to make the
dendrograms.
3.3 Clustering
To cluster database images, we first compute the distance between the cluster feature vectors of
cluster templates and all database images. Using the multi-resolution property of the wavelet trans-
form, we extract the image features at different scales. In comparing cluster feature vectors, only
coarse scale features will be used; while in retrieving images all the features will be compared. In
Section 2.2, we used the notation fAK as the wavelet representation
of signal A 0 after K levels of the wavelet transform. We define clustering scale (K; c) as the
number of coarsest scales that will be used in clustering after applying K levels of the wavelet trans-
form. It means that in clustering only the features extracted from fAK ; DK will
be used, where 1 - K - J , 1 - c - J , and c ! K. For example, clustering scale (5, 2) means that
the 5-level wavelet transform will be applied and the features of the 2 coarsest scales (fA 5
will be used in clustering. We define retrieval scale (K; r) as the number of scales that will be used
in retrieval after applying K levels of transform. In retrieving images, the features extracted from
will be used, where 1 - K - J , usually r ? c. In
retrieving, we will use all the features. Clustering scale and retrieval scale for both feature sets 1
and 2 are (2,1) and (2,2), respectively.
Let X and Y be two undecomposed images (for example, a query image, a cluster template, or
an undecomposed segment of a database image). Let CFX
be their cluster feature vectors extracted from the subbands fAK based
on the clustering scale (K; c). Let RFX be the retrieval
feature vectors of X and Y respectively, extracted from the subbands fAK
according to the retrieval scale (K; r). To measure the similarity between X and Y in clustering,
we define the clustering distance d c as follows:
where dist could be any appropriate distance function. Here, we use Euclidean distance for dist. To
measure the similarity between X and Y in retrieval, we define the retrieval distance d r as follows:
d r (X; Y
A database image Y can be decomposed into a set of smaller segments fY g. To measure
the distance between the database image Y and the undecomposed image X (a query image, or a
cluster template) in clustering, we use D c :
Similarly, in retrieval, we use D r to compute the distance between the query image X and the
database image Y:
In determining the correct cluster(s) for a database image, we use the distribution of objects
(feature vectors) in each sub-cluster. For each sub-cluster we define a scope. Let - i and - i be the
mean and variance of clustering distances d c of objects to the centroid of the sub-cluster i. The
scope of sub-cluster i is part of the feature space whose distance to the centroid of sub-cluster is less
than Parameter fi is a factor that is determined by experiments. In a two dimensional
space, the scope of a sub-cluster is a circle with radius In our clustering approach,
whenever a database image Y falls within the scope of any sub-cluster, it will be assigned to the
cluster corresponding to the sub-cluster. The reason is that a database image may contain the
features of several different cluster templates and it should be assigned to all the corresponding
clusters.
If the database image Y is not within the scope of any of the sub-clusters, but the distance
between the database image and the closest cluster template t is less than a threshold T ,
it will be assigned to the corresponding cluster represented by the closest cluster template. If there
is no cluster template for which the distance between the database image and the cluster template
is less than T , the database image will be assigned to the special cluster other. The cluster other
contains all the database images that cannot be assigned to the predefined clusters.
As an example, Figure 9 shows the scope of 3 sub-clusters A, B, and C in a two dimensional
space. In general, these sub-clusters do not necessarily belong to different clusters. The object
denoted by point 1 falls in the scope of sub-clusters A and B and will be assigned to both.
x
x
Cx
x
x
x
x
x
x
x
x
x
x
x
x
x
A
x
x
x
x
x3

Figure

9: Three sample sub-clusters.
However, some objects may not fall in any of the scopes considered above. For example, Point
2 in

Figure

9 is not in the scope of any of sub-clusters. Our clustering approach assigns such an
object to the closest sub-cluster. Although the distance d c between point 2 and the centroid of
sub-cluster C is less than that of sub-clusters A and B, but based on the distribution of objects
within clusters, it is more logical to assign object 2 to sub-cluster A. So, we first compute the
distance between the object and the border of the sub-clusters' scope, and then choose the closest
cluster. Hence, object 2 will be assigned to sub-cluster A. The object shown as point 3 in Figure 9
will be assigned to the cluster other, because it is far away from all clusters and its distance d c to
the closest cluster is greater than threshold T .
Algorithm 1 shows the steps in choosing the cluster(s) for database images. After generating
the templates, for each image, the time complexity of choosing clusters (either for adding the image
to the clusters or for retrieving images) would be O(t) where t is the number of templates. The
required time to assign database images to the clusters is O(tN) where N is the number of images.
Since the number of templates is generally far less than the number of images, that is t !! N , the
time complexity will be O(N ). That is, the time complexity of generating clusters will be
linear in terms of number of database images. So it can process large image databases efficiently. As
it will be shown in the experiments, just by clustering database images, the system avoids searching
more than 75% of the database images.
Algorithm 1
Choose Cluster To Add(Image)
/* Based on distance between Image and subclusters, */
adds Image to the corresponding cluster(s). */
f
/* compute the distance D c between all */
/* the subclusters and database image */
to Number Of Subclusters
Adjusted Distance
/* distance to the border of subcluster's scope */
/* find the index of the closest subcluster */
Closest Find Min(Adjusted Distance);
if (Adjusted DistanceClosest
f/* add to special cluster other */
Add Image T
return;
/* add image to "all" clusters that are close enough */
to Number Of Subclusters
fif (Distance
f/* add to the corresponding cluster of subcluster i */
Add Image T
if (Cluster Added == FALSE) /* image not added to any cluster */
/* add to the closest cluster */
Add Image T
3.4 Image Retrieval
To retrieve database images similar to or containing the query icon, the distance d c between query
icon and cluster templates will first be computed. If the query icon is within the scope of any
cluster template, the corresponding cluster(s) will be searched. To measure the similarity of query
icon and the database images in the cluster(s), the distance D r will be used. If the query icon
does not fall in scope of any cluster template, but its distance to the closest cluster template is less
than a threshold T , then the cluster corresponding to the closest one will be searched. Otherwise,
the cluster other will be searched to retrieve the relevant images. Given a good set of features,
comparing with the nearest-neighbor search used in R-tree and its variants, retrieval on the clustered
image database can potentially eliminate those images which are close to the query in the feature
space, but semantically not similar.
4 Experiments
As test data we used 1032 air photo images. To find the cluster templates representing each of
residential, water, grass, and agriculture clusters, we used between 50 to 100 training image data
per cluster. The training images were chosen such that the clusters do not overlap in the feature
space. We tried the four different methods to compute the distance between sub-clusters: centroid
method, CLINK, SLINK, and UPGMA. Figure 10 shows the sample cluster templates found by
the hierarchical approach using these methods.
Residential Water Grass Agriculture
a)
c)
d)

Figure

images: a) Centroid method; b) CLINK; c) SLINK; d) UPGMA.
It should be noted if additional terrains (such as jungle, or connifer forest) need to be added as
new clusters, a set of training samples should be chosen for them. By applying the clustering method
given in Section 3.2, the corresponding templates (subclusters) and their scopes can be determined.
Using the new templates and the previously chosen templates (for the current clusters), database
images can be easily reclustered. In other words, given new clusters (that are separate from current
clusters), our system can accommodate them.
To evaluate the performance of our clustering approach, we first visually inspected all database
images and assigned them to their corresponding clusters. We consider these clusters as ideal
clusters. We then compared the result of our clustering approach to the ideal clusters. Let C c be
the set of images in the system's output for cluster c. Let I c be the set of images in the ideal cluster
for cluster c. We define P c , the precision of clustering for cluster c as
The recall of cluster c, R c , is defined as
The higher P c and R c are, the better the clustering will be. As mentioned in Section 3.3, scope
of a subcluster S i is determined by - . The values - i and - i are calculated by the system
while generating the dendrogram. In our experiments a value between -0.5 to -1.5 for fi gives
reasonable results. The threshold T is used to assign a database image (or search) in the cluster
other. Based on our experiments, T - 2   max(- i ) can give satisfactory results. To find appropriate
values for ff, fi, and T , we can first choose a sample set of database images with known clusters. We
then determine the ideal clusters I c for the images in the sample set. After applying the clustering
method on the sample data, precision and recall of clustering (P c and R c ) can be calculated. We
can tune the values of ff, fi, and T by trail and error to obtain the desired P c and R c for the sample
set. The optimal values of these parameters can then be used to cluster the whole database.
In our experiments we chose 150 as the value of threshold T . We then tried the system for
different values of parameter fi. In the experiments, we used the original extracted features (without
any processing), normalized features, and weighted-normalized features. For weighted-normalized
features, we assigned a weight of 4 to the first feature of the feature vector, and equal weight of 1
to the rest of features. We chose these weights on a trail and error basis. Assigning weights is an
important issue that affects the results. The tables report the results when Haar wavelet transform
is applied. Table 6 shows P c and R c for different methods of finding distance between sub-clusters
when weighted-normalized features are used.
A good clustering should have high recall and precision. But recall is more important than
precision in clustering, because in retrieval from a cluster, we want to miss as few images as possible
comparing to retrieval from the whole database. In our experiments, the results obtained by CLINK
(maximum distance between objects in two sub-cluster) and UPGMA (average of distances between
objects) are better than those of others. They yield both very high precision and recall of clustering
Water 0.90 0.98 0.86 1.00 0.85 1.00 0.84 1.00
Agriculture 0.98 0.88 0.98 0.88 0.97 0.90 0.96 0.93
Residential
Grass 0.83 0.86 0.85 0.83 0.86 0.82 0.88 0.81
a) Centroid
Water 0.95 0.98 0.94 0.97 0.94 0.97 0.94 0.97
Agriculture
Residential 0.98 0.95 0.99 0.94 1.00 0.93 1.00 0.92
Grass 0.94 0.91 0.93 0.93 0.91 0.93 0.89 0.92
Water 0.92 0.97 0.89 0.98 0.87 0.99 0.78 1.00
Agriculture 0.96 0.84 0.96 0.84 0.96 0.84 0.96 0.84
Residential 0.98 0.90 0.98 0.90 0.98 0.90 0.98 0.90
Grass 0.79 0.87 0.81 0.85 0.82 0.83 0.82 0.77
c) SLINK
Water 0.90 0.98 0.86 1.00 0.85 1.00 0.84 1.00
Agriculture
Residential 0.97 0.98 0.97 0.98 0.97 0.98 0.97 0.98
Grass 0.97 0.86 0.98 0.84 0.98 0.83 0.98 0.81
d) UPGMA

Table

Precision and recall of clustering for different values of fi. Weighted-normalized feature
set 1.
(more than 0.90). As Table 6 shows, varying the value of fi makes slight changes in the performance
of clustering.
To study the impact of clustering on effectiveness of retrieval, we chose 10 query icons of size 32 \Theta
pixels. Our system processes queries such as "retrieve top N (say 50) images that have the same
texture as the query icon". We calculated the effectiveness of retrieval in terms of retrieval \Gamma rate.
Retrieval rate for top n images is defined as
retrieval number of relevant images in top n images
A high retrieval rate means that most of retrieved images are what the user looks for, and thus it
shows a better performance in retrieval. We calculated retrieval rates for values 10, 20, 30, 40, and
50 of n for the 10 query icons and then found their average value. We first computed retrieval rate
without using clustering. In this context, we consider nearest neighbor search approaches (such as
R-tree or serial search) as without clustering methods. We then computed the retrieval rate when
the clustering approach is used (with value 150 for threshold T and values 0.0, -0.5, -1.0, and -1.5
for fi). Different feature sets form different feature spaces. By normalizing features or assigning
weights to them, the feature space changes which results in altering the shape of clusters or the
location of query images. Also, different distance methods (centroid, CLINK, SLINK, UPGMA)
result in different shapes of clusters. As a consequence, we get different performances from these
various feature spaces and clusters. Given the appropriate feature vectors and distance method our
proposed approach can outperform nearest neighbor methods in retrieval.

Table

7 shows the average retrieval rate of top n images
set 1.

Table

8 has the same information for feature set 2. Tables 7 and 8 show that retrieval from
clustered database (using all different distance methods) outperforms the retrieval from the whole
database without clustering. In general, when a query image is near the boundary of the cluster, our
method avoids retrieving the images outside the cluster (the ones that are semantically irrelevant)
resulting in better performance. When the query image is in the middle of clusters, retrieving
nearest neighbors (without clustering), and retrieval using our clustering approach would be the
same. The retrieval rates obtained from CLINK and UPGMA are higher than those of others. It
confirms with our previous clustering results where these two methods had higher precision and
recall of clustering. In our experiments, we achieved the highest improvement in retrieval rate (from
0.70 to 0.95) when using original features set 2 and CLINK as shown in Table 8-a.
Original feature set 1 provides a higher retrieval rate than that of feature set 2. Normalizing
and then assigning weights to the features improves the retrieval rate when clustering is not used
for both feature sets 1 and 2. When clustering is applied, weighted-normalized features provide a
higher retrieval rate for feature set 2 (comparing to the original feature set), but not for feature set
1. In the latter case, another set of weights should be chosen. In general, a better method should
be used to find the best weights for the features. For the same distance method and feature set,
different values of fi do not make major changes in the retrieval rate.
DB Ret DB Ret DB Ret DB Ret
Centroid
Clustering 1.00 0.73 1.00 0.73 1.00 0.73 1.00 0.73
a) Original features
DB Ret DB Ret DB Ret DB Ret
Centroid
UPGMA
b) Normalized features
DB Ret DB Ret DB Ret DB Ret
Centroid
Clustering 1.00 0.76 1.00 0.76 1.00 0.76 1.00 0.76
c) Weighted-normalized features

Table

7: DB-Ratio DB, and retrieval-rate Ret for different values of fi. a) Original features; b)
Normalized features; c) Weighted-normalized features. (feature set 1).
The other issue that should be considered is the number of images that are searched in retrieval
from a clustered database. We define the ratio of database search DB \Gamma ratio as
number of images searched in database
total number of images in database
The lower DB \Gamma ratio is, the better clustering would be. The time to search the database is
directly proportional to the number of images to be searched. Thus a low DB \Gamma ratio means that
less time is used to search the database. Tables 7 and 8 show the average DB \Gamma ratio for the 10
query icons. In average our clustering approach yields a DB \Gamma ratio of about 0.25, that is, about
75% of irrelevant images will not be searched. We performed the experiments on a SUN SPARC
workstation using 168 MHz UltraSparc CPU with SunOS operating system and 1024 MB memory.
The average time to search the whole database was 1.5 seconds, whereas after clustering, it only
took about 0.23 seconds to return the relevant images. Integrating current indexing methods such
as R-tree or its variants can speed up the retrieval process more.

Figure

11 shows the 10 closest retrieved images (ordered from left to right) for a sample grass
query image without clustering and using clustering, respectively. For the query image in Figure 11,
DB Ret DB Ret DB Ret DB Ret
Centroid 0.22 0.94 0.23 0.95 0.23 0.96 0.23 0.96
Clustering 1.00 0.70 1.00 0.70 1.00 0.70 1.00 0.70
a) Original features
DB Ret DB Ret DB Ret DB Ret
Centroid
Clustering 1.00 0.71 1.00 0.71 1.00 0.71 1.00 0.71
b) Normalized features
DB Ret DB Ret DB Ret DB Ret
Centroid
Clustering 1.00 0.78 1.00 0.78 1.00 0.78 1.00 0.78
c) Weighted-normalized features

Table

8: DB-Ratio DB, and retrieval-rate Ret for different values of fi. a) Original features; b)
Normalized features; c) Weighted-normalized features. (feature set 2)
the first 10 retrieved images without clustering include four cases (images 6 through 10) which are
not grass images. As shown in Figure 11-c, those semantically irrelevant images are not retrieved
when our clustering approach is applied, which demonstrates the advantage of our method.
a) Query icon
Retrieved images without clustering
c) Retrieved images with clustering

Figure

11: Retrieval results
5 Conclusion
We have designed a content-based retrieval system that supports novel clustering and retrieval for
geographical images. This system utilizes the rich texture features existing in the geographical
images to assist content-based retrieval. A clustering approach is designed to automatically categorize
images based on themes such as land use or land cover. Using the multi-resolution property
of wavelet transforms, we extracted the features at different scales where only the coarse features
were used in clustering. Since the semantic distribution of feature vectors in the feature space is
considered in the clustering, the retrieval of the relevant images can be performed by narrowing
down to the relevant clusters. Thus, more precise image searching can be supported rather than
the plain nearest-neighbor search. Through the experimental analysis, we have shown that texture
features can be effectively used to cluster geographical images. In addition, our experimental results
demonstrated that retrieval from the clustered database can be more effective than that of
the whole database, given the appropriate feature sets and distance methods.

Acknowledgments

We would like to thank the reviewers of this paper for their constructive criticism and useful
comments throughout the revision of the paper.



--R

Comparisons between spectral mapping units derived from spot image texture and field soil map units.
Mosaic models for texture.
Multidimensional orientation estimation with applications to texture analysis and optical flow.


Sar sea ice discrimination using texture statistics: A multivariate approach.
Seasonal variation of heterogeneity in the tallgrass prairie: A quantitative measure using remote sensing.
A Visual Information Management System for the Interactive Retrieval of Faces.
Markov random field texture models.
An Intelligent Image Database System.

A Density-Based Algorithm for Discovering Clusters in Large Spatial Databases with Noise
Query by image and video content: The QBIC system.
Classification Methods for the Exploratory Analysis of Multivariate Data.
The use of contextual information in the classification of remotely sensed data.
Statistical and Structural Approaches to Texture.
Compressing Still and Moving Images with Wavelets.
Pattern recognition with measurement space and spatial cluster ing for multiple image.
Textural features for image classi- fication
Use of texture operators in segmen- tation
Spectral and texture features to classify elusive land cover at the urban fringe.
Fast multiresolution image querying.


Finding Groups in Data: an Introduction to Cluster Analysis.
The development of a spectral-spatial classifier for earth observational data

Remote Sensing and Image Interpretation.
Multiresolution approximation and wavelet orthonormal bases of L 2 (R).
A theory for multiresolution signal decomposition: the wavelet representa- tion

Image indexing using a texture dictionary.
Texture Features for Browsing and Retrieval of Image Data.
Efficient and Effective Clustering Methods for Spatial Data Mining.
Image texture processing and data integration for surface pattern discrimination.
Analysis for Researchers.
Automatic Image Indexation and Retrieval.
Supporting Content-Based Retrieval in Large Image Database Systems
Combining spectural and texture data in the segmentation of remotely sensed images.
Transform Features For Texture Classification and Discrimination in Large Image Databases.

Semantic clustering and querying on heterogeneous features for visual data.
A Fourier-based textural feature extraction procedure


Image decomposition and representation in large image database systems.
An Approach to Clustering Large Visual Databases Using Wavelet Transform.
Geographical Data Classification and Re- trieval
Texture Features Corresponding to Visual Perception.
Wavelet transforms using lifting scheme.
Multirate Systems And
Facial Images Retrieval
A new statistical approach to texture analysis.
Generation of texture image using adaptive windows.
BIRCH: An Efficient Data Clustering Method for Very Large Databases.
--TR

--CTR
Wei Wang , Daoying Ma , Yimin Wu , Aidong Zhang , David M. Mark, Webview: a distributed geographical image retrieval system, Proceedings of the 2002 annual national conference on Digital government research, p.1-4, May 19-22, 2002, Los Angeles, California
Gholamhosein Sheikholeslami , Wendy Chang , Aidong Zhang, SemQuery: Semantic Clustering and Querying on Heterogeneous Features for Visual Data, IEEE Transactions on Knowledge and Data Engineering, v.14 n.5, p.988-1002, September 2002
Tao Li , Qi Li , Shenghuo Zhu , Mitsunori Ogihara, A survey on wavelet applications in data mining, ACM SIGKDD Explorations Newsletter, v.4 n.2, p.49-68, December 2002
