--T
Social role awareness in animated agents.
--A
This paper promotes {\itshape social role awareness\/} as a desirable capability of animated agents, that are by now strong affective reasoners, but otherwise often lack the social competence observed with humans. In particular, humans may easily adjust their behavior depending on their respective role in a socio-organizational setting, whereas their synthetic pendants tend to be driven mostly by attitudes, emotions, and personality. Our main contribution is the incorporation of `social filter programs' to mental models of animated agents. Those programs may qualify an agent's expression of its emotional state by the social context, thereby enhancing the agent's believability as a conversational partner or virtual teammate. Our implemented system is entirely web-based and demonstrates socially aware animated agents in an environment similar to Hayes-Roth's Cybercaf\'{e}.
--B
INTRODUCTION
Ever since Bates and Reilly promoted believable agents in
their 'Oz project' [2], there has been continued interest to
give animated agents the illusion of life. It is now widely accepted
that emotion expression and personality are key components
of believable agents. Moreover, Cassell and her co-workers
recently provided convincing evidence of the importance
of non-verbal 'embodied' (conversational) behavior
for believable lifelike agents. Animated agents with believable
behavior are used as virtual tutors in interactive learning
environments (e.g., Johnson et al. [16]), as virtual presenters
on the web (e.g., Andr-e et al. [1], Ishizuka et al. [14]),
and as virtual actors for entertainment (e.g., Rousseau and
Hayes-Roth [28]). Although those agents achieve convinc-
Permission to make digital or hard copies of all or part of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for pro-t or commercial advantage and that copies
bear this notice and the full citation on the -rst page. To copy otherwise, to
republish, to post on servers or to redistribute to lists, requires prior speci-c
permission and/or a fee.
AGENTS'01, May 28-June 1, 2001, Montr- eal, Quebec, Canada.
ing behavior in their respective predefined roles, they might
fall short of 'social robustness' when put into a di#erent sce-
nario. E.g., a tutor agent might be believable for a student
(in the teacher role) but not in the role of a peer. Humans,
on the other hand, are always aware of the roles they play
in a certain social setting and typically behave accordingly.
In this paper, we will argue that social role awareness
is an important feature of human-human communication
which should be integrated to existing animated agents ap-
proaches. Social role awareness is easily illustrated, as in
the following conversation.
Aspirant (to secretary): I need a copy of this document.
Secretary (to aspirant): So what?
Manager (to secretary): I need a copy of this document.
Secretary (to manager): Sure. I will do it immediately.
The secretary's polite behavior towards the manager is
consistent with her unfriendly reaction to the aspirant, simply
because she is aware of her role-specific rights and duties
in the socio-organizational context of an o#ce environment.
Awareness of her role as secretary allows her to ignore the
(indirect) request from the aspirant (whose role is assumed
to be lower than the secretary's on the power scale). We
believe that the conversation above cannot be understood
(or generated) by means of reasoning about personality and
attitudes alone. Even if the secretary happens to have a
rather aggressive personality and she does not like her man-
ager, she would respect the manager's rights and obey to
his or her request. Similarly, we will argue that an agent's
role determines its way of emotion expression. Consider a
situation where the (aggressive) secretary is angry with her
manager. She will presumably not show her emotion to the
manager, being aware of her social role as an employee. On
the other hand, she might express her anger to a fellow secretary
who has equal social power.
Our goal is to create autonomous agents that can serve as
dramatically interesting conversational partners for the task
of web-based language conversation training. Specifically,
the animated agent approach will be used to improve English
conversation skills of native speakers of Japanese. Since
interactions are set up as role-playing dramas and games,
strong requirements are imposed on the agents' social abili-
ties. Social reasoning will be blended with a rather standard
theory of reasoning about emotion (Ortony et al. [25, 24])
and a simple model of personality. We employ Moulin and
Rousseau's [22] approach to model and simulate conversa-
tions, which provides a rich framework for many aspects of
inter-agent communication. The programmable interface of
the Microsoft Agent package [19] is used to run our role-playing
scenarios. Although these o#-the-shelf agent characters
are quite restricted in the number of behaviors, the
package comes ready with a speech recognizer and text-
to-speech engine that allow client-side execution in a web
browser.
The rest of this paper is organized as follows. The next
section discusses related work. In Section 3, we describe a
framework for modeling and simulating conversations. In
the following section, we introduce a simple a#ective reasoner
and argue that reasoning about emotion and personality
is not su#cient to achieve believable emotion expression.
Section 5 describes the basic notions underlying social reasoning
and introduces social filter programs that function as
a filter between a#ective state and emotion expression. In
Section 6, we first explain the web technology used to run the
animated agents. After that, we illustrate our approach by
example runs of a Cybercaf-e-style role-playing drama. Section
7 discusses the paper and suggests further extensions
and refinements. Finally, we summarize the paper.
2. RELATED WORK
Several research groups have addressed the problem of
socially intelligent agents in the framework of multi-agent
systems (e.g., Jennings [15], Castelfranchi [5]). On the other
hand, there are relatively few researchers who focus on social
role related behavior from the perspective of the believability
of animated character agents.
A notable exception is Hayes-Roth and her co-workers
(Hayes-Roth et al. [13], Rousseau and Hayes-Roth [28]). In
[13], role-specific behavior is studied in the context of characters
(animated agents) that function as actors in a master-
servant scenario. Social roles are defined by behaviors that
represent a character's status, e.g., high status is e#ected
through a quiet manner and ways of talking that forbid in-
terrupting. A character's believability in a specific role is
justified by adopting guidelines from the literature on the art
of drama, rather than by exploiting a social-psychological
model. Thus, no attention is paid to a character's representation
of its role. Rousseau and Hayes-Roth [28], however,
propose an elaborate social-psychological model that considers
personality, emotions (moods), and attitudes. Rules
are defined that allow to select appropriate behavior depending
on a character's personality and attitudes, thereby
enhancing the character's believability. Interestingly, the
social roles discussed in [13] are only of marginal importance
in this model. By contrast, we believe that an agent's
awareness of its social role is equally important for action
selection, and may even overrule the influence of personality.
Walker et al. [29] promote linguistic style as a key aspect
for believable agents. Linguistic choices are seen as realizations
of agents' personality, and subject to social variables
such as social distance between agents or the power one
agent has over another. The Linguistic Style Improvisation
(LSI) framework is based on speech acts theory and a theory
of linguistic social interaction. As a theory of social conver-
sation, LSI is clearly superior to our approach, which does
not provide a formalization of speech acts and uses a simpler
algorithm to decide the linguistic style of utterances.
However, we will provide a subtler account of the interaction
between an agent's emotional state, personality, social
role, and emotion expression.
Gratch [10] introduces 'social control programs' on top of
a general purpose planning system. In this system, plan
generation and execution are biased by the characteristics
of the social context. A so-called 'personality GUI' contains
the agent's goals, its social status, etiquette, (in)dependence,
and attitudes towards other agents. Besides those static features
of the agent's mental state, Gratch [10] introduces dynamic
features of the social context such as the communicative
state, the plan state, and the agent's emotional state.
Social rules encode commonsense rules of social interaction,
e.g., help a friend or avoid that some other agent interferes
with your plan. For the rather rigid organizational setting
in which military commander agents operate, Gratch and
Hill [11] introduce social concepts similar to ours. The main
di#erence to our work is that we place social control programs
at the interface of the module that reasons about
emotion and the module that renders the emotional state to
actual behavior. By considering the social context, we aim
to achieve believable emotion expression rather than generate
socially adjusted plans.
Guye-Vuill-eme and Thalmann recently started to work on
an architecture for believable social agents which is based on
four sociological concepts: social norms, values, world view,
and social role (see abstract [12]).
Finally, the research most relevant to ours is done by
Moulin and collaborators [21, 22]. It will be described in
the following section. We also continue work of Prendinger
and Ishizuka [27] who motivate the role-playing metaphor
for interactive learning environments.
3. A CONCEPTUAL FRAMEWORK FOR
SIMULATING CONVERSATIONS
A conversation is typically seen as an activity where multiple
(locutor-)agents participate and communicate through
multiple channels, such as verbal utterances, gestures and
facial display. Each agent has its own goals and will try to
influence other participants' mental states (e.g., emotions,
beliefs, goals). Moulin and Rousseau [22] distinguish three
levels of communication:
. At the communication level agents perform activities
related to communication maintenance and turn-taking.
. At the conceptual level agents transfer concepts.
. At the social level agents manage and respect the social
relationships that hold between agents.
Our system integrates the second and third level. The communicative
level basically implements conversational features
of human-human communication, as proposed by Cassell
and Th-orisson [4]. At the conceptual level, information is
passed from one agent to other agents as a (simplified) symbolic
representation of the utterance, e.g., if an agent orders
a beer, this is simply represented as order beer. According
to their role in the social context, the social level puts behavioral
constraints on agents' actions and emotion expression
(Moulin [21]). This issue will be discussed in detail below.
As an example, consider an agent character playing the
role of a customer called 'Al' and an agent character in the
role of a waiter called 'James'. Al orders a beer from James
by saying "May I order a beer please?". The corresponding
communicative act is formalized as
com act(al,james,order beer,polite,happiness,s0)
where the argument 'polite' is a qualitative evaluation of the
linguistic style (LS) of the utterance, the argument 'happi-
ness' refers to Al's emotion expression, and s0 denotes the
situation in which the utterance takes place.
As in [22], we assume that a conversation is governed by
. a conversational manager that maintains a model of
the conversation, and
. an environmental manager that simulates the environment
in which the agents are embedded.
For simplicity, we assume that the conversational manager
operates on a shared knowledge base that is visible to all
agents participating in the conversation (except for the user).
It stores all concepts transferred during the conversation by
updating the knowledge base with
com act(S,H,C,LS,E,Sit)
facts. The resulting 'model' of the conversation will eventually
be substituted by a less simple-minded conversation
model incorporating a formalization of speech acts (as, e.g.,in
Moulin and Rousseau [22]). Moreover, the conversational
manager maintains a simple form of turn-taking manage-
ment, by assigning agents to take turns based on their personality
traits. E.g., if James is an extrovert waiter, he
would tend to start a conversation with a customer, which
is formalized as
The environmental manager simulates the world that agents
inhabit and updates its (shared) knowledge base with consequences
of their actions. E.g., if the agent character Al
got his beer in situation s5, this will be stored as
holds(al,has beer,s5)
The characteristics of the environment are encoded by a set
of facts and rules. Situation calculus is used to describe and
reason about change in the environment (Elkan [7]).
4. MENTAL MODELS
Each agent involved in the conversation is assumed to have
its own mental model. A mental model may contain di#erent
kinds of entities, including world knowledge (beliefs, plans)
and a#ective mental states (emotions, personality, moods,
goals, attitudes). In this paper, we will concentrate on reasoning
about a#ective states and social reasoning.
4.1 Reasoning about Emotion vs. Emotion
Expression
It is widely accepted that animated agents expressing emotions
are important to make the interaction with them more
enjoyable and compelling for users (e.g., Lester et al. [17]).
Emotional behavior can be conveyed through various chan-
nels, such as facial display, speech and body movement. The
so-called 'basic emotions' approach (Ekman [6]) distills those
emotions that have distinctive (facial) expressions associated
with them: fear, anger, sadness, happiness, disgust, and sur-
prise. Murray and Arnott [23] describe the vocal e#ects on
Emotion type 'joy': agent L is in a `joy' state about
state-of-a#airs F with intensity # in situation S if
wants F in S with desirability degree # Des(F )
and F holds in S and # Des(F ) .
Emotion type 'angry-at': agent L1 is angry at
another agent L2 about action A with intensity # in S if
agent L2 performed action A prior to S
and action A causes F to hold in S
and agent L1 wants -F with degree # Des(-F ) in S
and L1 considers A blameworthy with degree # Acc(A)

Figure

1: Specifications for joy and angry-at.
the basic emotions found in [6], e.g., if a speaker expresses
the emotion 'happiness', his or her speech is typically faster,
higher-pitched, and slightly louder.
Although a 'basic emotions' theory allows relating emotion
to behavior (emotion expression), it cannot answer the
question why an agent is in a certain emotional state. How-
ever, reasoning about emotions is considered equally important
for presentation, pedagogical, and entertainment agents
(e.g., Andr-e et al. [1], Johnson et al. [16], Rousseau and
Hayes-Roth [28]). Many systems that reason about emo-
tions, so-called a#ective reasoners, derive from the influential
'cognitive appraisal for emotions' model of Ortony,
Clore, and Collins [25], also known as the OCC model (e.g.,
Elliott [8], O'Rorke and Ortony [24]). Here, emotions are
seen as valenced reactions to events, agents' actions, and ob-
jects, qualified by the agents' goals (what the agent wants),
standards (what the agent considers acceptable), and attitudes
(what the agent considers appealing). The OCC
model groups emotion types according to cognitive eliciting
conditions. In total, twenty-two classes of eliciting conditions
are identified and labeled by a word or phrase, such as
'joy', or `angry at'. We defined rules for a subset of the OCC
emotion types: joy, distress, hope, fear, happy for, sorry for,
angry at, gloats, and resents (see also O'Rorke and Ortony
[24], Gratch [9]). In Fig. 1, the emotion types joy and angry-
at are described. 1 The intensities of emotions are computed
as follows (for all intensity degrees, # {1, 2, . , 5}). In case
of 'joy', we set # Des(F ) . For emotions, where intensities
# and # have to be combined, such as in the specification of
the 'angry-at' emotion, logarithmic combination is employed
By example, let us explain the 'angry at' emotion type.
Assume that a secretary is angry at her manager because
she is refused to take a vacation. If the secretary has the
goal to take vacation with desirability degree #Des = 3, and
considers the refusal as blameworthy with degree
then she will be angry at her manager with intensity degree
how will she react to her manager? Presumably
she will nod, showing that she understood the manager's
1 The specification of the 'joy' emotion is related to the specification
of the 'satisfaction' emotion, whereby the latter one
is prospect-based. An agent L is satisfied if a hoped-for
state-of-a#airs F holds, where L hopes for F if L wants F
and anticipates F . See Gratch [9] for an in-depth treatment
of computing intensities for prospect-based emotions.
answer, and try to convince the manager that she really
needs some days o# in a calm voice, with a rather neutral
facial expression.
The secretary's behavior-suppressing the expression of
her emotional state-can be explained in at least two ways.
First, she might have personality traits that characterize
her as very friendly. Second, and probably more important
in this scenario, she might be aware of her social role as an
employee which puts behavioral restrictions on her answer to
the manager. Having said this, we should make explicit that
we only consider deliberative forms of emotion (expression),
as opposed to automatic 'hard-wired' processes of emotion
expression (see Picard [26]).
Below, we provide a brief characterization of personality,
and in the following we will try to explicate the impact of the
social dimension on emotion expression in communication.
4.2 Personality
Personality traits are typically characterized by patterns
of thought, attitude, and behavior that are permanent or
at least change very slowly. Most importantly, believable
agents should be consistent in their behavior (Rousseau and
Hayes-Roth [28]). To keep things simple, we consider only
two dimensions of personality, which seem crucial for social
interaction. Extroversion refers to an agent's tendency
to take action (e.g., being active, talkative). Agreeableness
refers to an agent's disposition to be sympathetic (e.g., being
friendly, good-natured). We assume numerical quantification
of dimensions, with a value out of {-3, -2, -1, 1, 2, 3}.
If an animated agent called 'James' is very outgoing and
slightly unfriendly, it is formalized as
personality
As mentioned in Section 3, we consider the first dimen-
sion, extroversion, in the conversational manager: outgoing
agents try to take turn in a conversation whenever possi-
ble, whereas introverted agents only respond when o#ered
to take turn.
Mo#at [20] points out the close relationship between personality
and emotion, although they seem very di#erent:
emotions are short-lived and focused whereas personality is
stable and global. He also considers mood which is rather
short-lived (like emotion) and not focused (like personality).
Later on, we will consider personality (or mood) to bias
emotion expression given a certain emotional state. Con-
sequently, an agent that is sorry for another agent and is
friendly will express its emotion more intensely than an unfriendly
agent.
5. SOCIAL FILTER PROGRAMS
Basically, a social filter program consists of a set of rules
that encode qualifying conditions for emotion expression.
The program acts as a 'filter' between the agent's a#ective
state and its rendering in a social context, such as a conver-
sation. Hence, we prefer to talk about social filter programs
rather than control programs (Gratch [10]). We consider the
agent's personality and the agent's social role as the most
important emotion expression qualifying conditions.
5.1 Roles, Conventions, and Social Networks
A significant portion of human conversation takes place
in a socio-organizational setting where participating agents
have clearly defined social roles, such as sales person and
customer, or teacher and student (Moulin [21]). Each role
has associated behavioral constraints, i.e., responsibilities,
rights, duties, prohibitions, and possibilities. Depending
on its role, an agent has to obey communicative conventions
(Lewis [18]). These conventions function as a regulatory
for the agent's choice of verbal expressions in a given
context. Conventional practices (i.e., behavioral constraints
and communicative conventions) can be conceived as guidelines
about socially appropriate behavior in a particular organizational
setting. In this paper, we will focus on the
choice of verbal and non-verbal behavior (emotion expres-
sion), depending on the agent's social role and personality.
Formally, in social or organizational groups roles are ordered
according to a power scale, which defines the social
power of an agent's role over other roles. For agents L i and
the power P of L i over L j is expressed as
considers itself as of the
same rank as L i . The social network is specified by the social
roles and associated power relations. Walker et al. [29]
also consider social distance between speaker and hearer to
determine an appropriate linguistic style. Similarly, we use
to express the distance between two agents
(D # {0, 1, 2, 3}). Given values for power and distance, an
agent L i computes the (social) threat # from agent L j , by
just adding the values, i.e.,
This is of course a very simple view of a social network
but, as shown below, it already allows us to explain various
phenomena in actual conversations. Observe that a zero
value for threat can be interpreted in three ways: (i) there
is no threat for an agent L, (ii) L chooses not to respect
conventional practices, and (iii) L is not aware of any threat.
5.2 Social Filter Rules
In the following, we will give some examples of social filter
rules. We assume that emotion expression (e.g., facial
display or linguistic style) is determined by personal expe-
rience, background knowledge, and cultural norms (Walker
et al. [29]), as well as the 'organizational culture' (Moulin
[21]). Our rules are consistent with Brown and Levinson's
theory of social interaction, as reported in [29].
If the conversational partner has more social power or
distance is high (i.e., # is high), the expression of 'nega-
tive' emotions is typically suppressed, resulting in 'neutral-
ized' emotion expression (see Fig. 2). The first condition
of the rule for emotion expression of 'anger' concerns the
social context, the second condition the agent's personality
(agreeableness), and the third accounts for the output of
the a#ective reasoner, the emotional state. The intensity #
of emotion expression is computed as #-(1+#). Consider
the case of an agent that is very angry (i.e.,
rather unfriendly (i.e., considers the social
threat as maximal (i.e., meaning that
the angry emotion is completely suppressed. On the other
hand, if the agent's agreeableness dimension comes
into force, resulting in
five the maximal intensity level, greater values are cut o#.
As shown in the second rule in Fig. 2, an agent might
even express happiness about something which-the agent
believes-distresses another agent. Observe that here, the
agent has to reason about the emotions of another agent.
Currently, we employ two mechanisms to model the ap-
Emotion expression 'anger': agent L1 displays
expression 'anger' towards L2 with intensity # if
the social threat for L1 from L2 is #
and L1's agreeableness has degree #
and L1 is angry at L2 with intensity #
Emotion expression 'happiness': agent L1 displays
expression 'happiness' towards L2 with intensity # if
the social threat for L1 from L2 is #
and L1's agreeableness has degree #
and L1 is gloats at L2 with intensity #
Emotion expression 'happiness': agent L1 displays
expression 'happiness' towards L2 with intensity # if
the social threat for L1 from L2 is #
and L1's agreeableness has degree #
and L1 is joyful with intensity #
and #).

Figure

2: Some examples of social filter rules.
praisal of another agent. If the observing agent has beliefs
about the observed agent's mental states and their desirabil-
ity, the agent infers the emotional state of the other agent
by using its emotion rules. Else, the observing agent uses
the other agent's perceived emotion, communicated via the
com act/6 representation discussed in Section 3, to assess
the other agent's emotion.
The third rule in Fig. 2 demonstrates the e#ect of personality
and social context on 'positive' emotions. We compute
the intensity of positive emotions as #). As a con-
sequence, the agent's unfriendliness or a high social threat
will diminish the expression of positive emotions. E.g., if a
very happy rather unfriendly agent
communicates with a slightly distant agent (i.e.,
the agent will express happiness with rather low intensity
Finally, notice an interesting consequence of our frame-
work. Since we clearly distinguish between emotional state
and expression of emotion, we may add another possibility of
an agent's misinterpretation of other agents' behavior. First,
an agent never has direct access to others mental states,
it can only have (possibly false) beliefs about their mental
(e.g., emotional) states. Second, our distinction allows that
agents cheat in their behavior by expressing a misleading
emotion. E.g., an agent may express a sad emotion, pretending
to be in a distressed emotional state, although it is
in a 'happy' state. This option is required for entertainment
purposes, where 'levels of indirection' are beneficial.
5.3 Violations of Conventional Practices
Despite the fact that obedience to conventional practices
is expected in real-world socio-organizational settings, violations
of conventional practices occur, and in particular, they
seem to be dramatically more interesting. What happens if
a manager requests something from his or her secretary and
the secretary refuses to follow the order? Consider the following
conversation fragment:
Manager (to secretary): I quickly need a copy of this.
Secretary (to manager): Sorry, I am busy right now.
Here, the secretary violates conventional practices by ignoring
the manager's indirectly formulated order. This situation
typically triggers a negotiation process where the agent
with higher social role makes his or her request more explicit,
or the even directly refers to his or her role and associated
rights, e.g., the power to request tasks from subordinates
(Moulin [21]). From an emotion expression point of view,
the manager agent will typically be in an 'angry at' (the sec-
retary) emotional state and may express its anger emotion
due to its higher rank on the power scale. The crucial belief
in the manager agent's mental model is, e.g.,
blameworthy(manager,conventional practice violated,4)
i.e., managers (typically) consider it as blameworthy if their
higher rank is ignored by employees. On the other hand,
we might imagine a manager with friendly personality traits
who is distressed about the secretary's behavior, and expresses
the emotion 'sadness'. Another possibility is that
the manager shows 'neutral' emotion expression, if manager
and secretary are old friends and-according to the very organizational
culture-typical conventional practices are not
applicable.
6. ROLE-PLAYING ON THE WEB
Our interactive environment for English conversation training
for Japanese speakers assumes that users (language stu-
dents) would enjoy getting involved in a role-play with animated
character agents, and thereby overcome their uneasiness
to converse in a foreign language. Inspired by the
examples of Rousseau and Hayes-Roth [28], we implemented
an interactive theater (or drama) that o#ers the role of a customer
in a virtual co#ee shop. An interactive role-playing
game employing animated agents, the Wumpus Game, is
currently under development.
6.1 Implementation
The programmable interface of the Microsoft agent package
[19] is used to run a virtual co#ee shop session in a web
browser (Internet Explorer 5). This choice put some serious
restrictions from the outset: the characters available for this
package have only a limited number of behaviors ('anima-
tions'), confining the realization of various emotions as well
as some features of embodied conversational behavior (Cas-
sell and Th-orisson [4]). However, our goal is believablity on
the level of adequate emotion expression rather than life-likeness
(in the sense of realistic behavior). The Microsoft
Agent package provides controls to embed animated characters
into a web page based JavaScript interface, and includes
a voice recognizer and a text-to-speech engine. Prolog programs
implement all reasoning related to conversation and
environmental management and agents' mental models (af-
fective and social reasoning). We use Jinni (Java Inference
engine and Networked Interactor) to communicate between
Prolog code and the Java objects that control the agents
through JavaScript code (BinNet Corp. [3]).
In a role-playing session, the user can promote the development
of the conversation by uttering one of a set of pre-defined
sentences that are displayed on the screen. Unlike
the setup of Hayes-Roth's `Virtual Theater Project' [28], the
emotion type 'angry at' in situation s1
holds(did(order beer,customer),s1).
causes(order beer,regulation violated),s0).
blameworthy(james,order beer,4).
wants(james,regulation respected,3,s1).
emotion expression 'anger' in situation s1
personality type(james,extrovert,-2,agreeable,-3).
social power(customer,james,0).
social distance(james,customer,0).
emotion type 'angry at' in situation s5
holds(did(refuse vacation,manager),s5).
causes(refuse vacation,no vacation,s4).
blameworthy(james,refuse vacation,3).
wants(james,get vacation,5,s5).
emotion expression 'neutral' in situation s5
social power(manager,james,3).
social distance(james,manager,2).

Figure

3: Some facts in the waiter agent's mental
model for first example run.
user does not need an avatar in the play. Animated agents
will respond by synthetic speech, facial display, and ges-
tures. Verbal and non-verbal behavior is synthesized in the
agent's mental model and interpreted in the browser. The
parameters for speech output are set in accordance with the
vocal e#ects associated with the basic emotions [6, 23]. Of
course, the facial display of characters is limited to the pre-defined
'animations' from the Agent package (e.g., `pleased',
'sad'). To some extent, we also implemented conversational
behavior (Cassell and Th-orisson [4]). E.g., the animations
'confused' (lifting shoulders) and `don't-recognize' (put hand
to ear) are used if the user's utterance is not recognized.
6.2 Example Runs
We will illustrate our system by showing some example
runs. In the first example, the user takes the role of a
(friendly) customer who interacts with an unfriendly waiter
agent James, who himself interacts with a friendly manager
agent as an employee. Fig. 3 describes some relevant facts
stored in the waiter agent's brain. For the rule part, the
reader is referred to Figures 1 and 2. The following is an
annotated trace from our conversation system.
[s0] Customer: I would like to drink a beer. [User can also
choose other beverages, and for each, he or she may select
the linguistic style (polite, neutral, rude).]
James (to customer): No way, this is a co#ee shop.
[Considers it as blameworthy to be asked for alcohol and
shows his anger. We assume that the waiter ignores the
social threat from the customer.]
[The manager of the co#ee shop appears.]
[s3] James (to manager): Good afternoon, boss. May I take
a day o# tomorrow? [Welcome gesture. Following conventional
practices, the waiter is polite to his manager.]
[s4] Manager: It will be a busy day. So I kindly ask you
to come. [Uses polite linguistic style in accordance with his
personality traits.]
[s5] Waiter: Ok, I will be there. [Considers it as blameworthy
to be denied a vacation and is angry. However, he is
aware of the social threat and thus does not show his anger.
Instead, he shows neutral emotion expression.]
The communicative act of the customer has the form
com act(customer,james,order beer,polite,neutral,s0)
Since the animated agents do not understand English, a library
is used to associate the user's utterance with an 'ef-
fect', e.g., the regulations of the co#ee shop are violated,
and an evaluation of its linguistic style, such as polite, rude
or neutral. Moreover, as an emotion (expression) recognition
module is not part of our system, we set 'neutral' as
the default value for user input (but see the work of Picard
[26]). The waiter's answer is formalized as
com act(james,customer,refuse beer,rude,anger,s1)
Similarly, the library is employed to generate the syntactic
form of the animated agent's response. As described in
Section 3, the environmental manager simulates the envi-
ronment. In this example, it includes the fact act(manager,
appears, s2) which triggers the waiter's reaction in situation
s3. In accordance with the contents of James' mental model
and our rules for a#ective and social reasoning, the waiter
agent expresses its anger towards the customer (user), but
its anger towards its manager.
The second example run is a variation of the previous
example where we assume an extrovert, friendly waiter who
respects conventional practices towards customers but not
towards his indi#erent manager.
James: Welcome to our co#ee shop! May I take your
[Starts the conversation because of his extrovert per-
Bring me beer, right away. [User chooses
rude linguistic style.]
James (to customer): I am sorry but I am not allowed to
serve alcoholic beverages here. [Concludes that the customer
is distressed and feels sorry for the customer.]
[s3] [The manager of the co#ee shop appears.]
James (to manager): Good to see you, boss. Tomorrow
I want to take a day o#. [Performs welcome gesture.]
[s5] Manager: Actually, I need you tomorrow. Thank you.
[Uses neutral linguistic style for his request.]
James: Too bad for you. I will not be here. [Waiter is
angry as the manager refuses to give him a vacation. Since
the waiter does not respect conventional practices, he expresses
his anger and refuses to obey the manager's order.]
In situation s3, we assume James to believe that the customer
wants a beer (urgently) and is distressed as a consequence
of the waiter's refusal. James' agreeableness is
responsible for feeling sorry about having to refuse the cus-
tomer's order. However, the linguistic style of James' response
is slightly lower in its politeness, since the customer
approaches the waiter in a rude way (a rudimentary form of
a reciprocal feedback loop).
There are limitless ways to vary social encounters between
agents, even in the restricted context of a co#ee shop en-
vironment. Consider, for instance, a situation where an
unfriendly waiter shows rude behavior towards a customer,
who turns out to be the waiter's new manager. A 'socially
robust' waiter agent will show a form of `behavior switching'
(assuming that the agent respects conventional practices).
6.3 User Feedback
We conducted a rather preliminary experiment on the impact
of agents featuring social role awareness. As in the
example runs of the previous section, users would play the
role of a customer in a co#ee shop and interact with an animated
agent portraying a waiter. The waiter agent interacts
with a manager agent, a fellow waiter agent or a customer
agent. Although our general goal is to employ the animated
agents approach to language conversation training, the focus
here is to show that (i) users can recognize whether the
agents behave according to their social roles, and (ii) the
animated agents' responses are believable. Five users were
asked to rate the appropriateness of the agents' responses.
Furthermore, we asked them whether they think the agents'
reactions could occur in real-world situations.
As we expected, users could identify the social roles played
by the animated agents, which are easily detected in the coffee
shop environment. Users could also recognize when conventional
practices have been violated. However, answers
varied when asked for what they think went wrong in case
of violation: including, that the agent is in a bad mood, or
does not like the boss (or customer agent). When we run
the experiment with agents that only reason about emotion
and personality (i.e., without social role awareness), users
would generally not consider those agents as 'unbelievable',
but they expected to get hints regarding the motivation for
the violation of conventional practices, and appropriate reactions
from the other agents. Our (preliminary) findings
reinforce the belief that an agent should show an overall consistency
in its behavior in order to come across as believable
and that social role awareness facilitates consistency.
7. DISCUSSION
Our work aims to account for an important feature of
human-human communication, namely social role aware-
ness, that seems to have strong influence on our ways of
emotion expression and our behavior in general. Social role
awareness is approached from the viewpoint of the believability
of animated agents. It is shown that this feature of
social interaction may explain phenomena such as suppressing
(the expression) of emotions, as well as other forms of
'cheating' about an agent's emotion. As such, social role
awareness can significantly contribute to the design of dramatically
interesting characters (as in Hayes-Roth et al. [13]
or Rousseau and Hayes-Roth [28]). More recently, sensitivity
to socio-organizational contexts is also pointed out as
a crucial issue in military training simulations (Gratch and
Hill [11], Gratch [10]). Here, interesting conflicts can arise
between an agent's goal (or self-interest) and role-specific
duties imposed by orders from a commander agent.
Although we believe that social role awareness makes animated
agents more 'socially robust', our approach su#ers
from several shortcomings. In the following paragraphs, we
discuss work relevant to future refinements of our approach.
Social reasoning and planning. In the emotion model
called
Emile, Gratch [9] interleaves emotional reasoning with
an explicit planning model. There are obvious advantages
of considering an agent's plans, e.g., `prospective' emotional
states such as hope and fear assume reasoning about future
situations and typically induce plan generation or the modification
of current plans. Similarly, social reasoning would
benefit from an explicit representation of plans. Often, an
agent's choice of emotion expression depends on the state of
its current plan: e.g., if an employee agent plans to get fired,
its violation of conventional practices towards its manager
should be seen in the light of this high-level goal, and not be
considered as part of the agent's concept of its social role.
Social action. Besides appropriate emotion expression,
other (possibly more important) behavioral constraints apply
to socio-organizational settings. The role of an agent is
associated with certain responsibilities, rights, duties, pro-
hibitions, and decision power (Moulin [21]). A broader perspective
of social agency will require explicit representations
of those behavioral constraints, as well as formalisations
of social concepts such as 'commitment'. In this respect
we may heavily draw on well-established research work
on multi-agent systems and distributed artificial intelligence
(e.g., Jennings [15], Castelfranchi [5]).
Social communication. As mentioned throughout the pa-
per, an obvious weakness of our approach is that we do
not provide an explicit formalization of speech acts. Conse-
quently, all of the dialogue contributions have to be carefully
hand-crafted. In fact, we employed a simplified version of
Moulin and Rousseau's conversation model [21, 22]. In [21],
Moulin introduces a new notation for speech acts that is
tailored to communication in socio-organizational settings,
in particular conversational schemas that allow an agent to
select speech acts in accordance with communicative con-
ventions. In addition, we should consider the linguistic style
strategies discussed by Walker et al. [29]. Those strategies
determine semantic content, syntactic form and acoustical
realization of a speech act, qualified by the social situ-
ation. Application of LS strategies supports social interactions
that allow agents to maintain public face (i.e., autonomy
and approval). If speaker and hearer have equal social
rank, 'direct' strategies can be applied (e.g., "Bring me a
beer!"). On the other extreme, if the rank distance is very
large, 'o# record' strategies are chosen (e.g., "Someone has
not brought me a beer.
8. CONCLUSION
In this paper, we propose to integrate social reasoning to
mental models of animated agents, in addition to an a#ective
reasoning component. The novel aspect of our work is that
we explicate the social role of agents and associated constraints
on emotion expression, which allows for enhanced
believability of animated characters beyond reasoning about
emotion and personality. We believe that considering the social
dimension in animated agents approaches adds value for
the following reasons:
. Believability. It may increase the illusion of life, which
is often captured by emotion and personality only.
. Social Communication. By respecting an important
feature of human conversation, it adds 'social robust-
ness' to agent-human and inter-agent communication.
. Explanatory power. It explains the frequent mismatch
between the output of emotional reasoning (the emotional
state) and emotion expression.
We have described a web-based interactive drama scenario
featuring animated agents as an entertaining testbed to experiment
with new capabilities of agents. By considering
the issues described in the discussion section, we hope to
gain a better understanding of the social dimension in communication

9.

ACKNOWLEDGMENTS

We would like to thank the anonymous referees for their
very helpful and detailed comments. The first author was
supported by a grant from the Japan Society for the Promotion
of Science (JSPS).
10.



--R

The automated design of believable dialogue for animated presentation teams.
The role of emotion in believable agents.
BinNet Corp.
The power of a nod and a glance: Envelope vs. emotional feedback in animated conversational agents.
Modeling social action for AI agents.
An argument for basic emotions.



Socially situated planning.
Continuous planning and collaboration for command and control in joint synthetic battlespaces.

Acting in character.
MPML: A multimodal presentation markup language with character control functions.
Commitments and conventions: The foundation of coordination in multi-agent systems
Animated pedagogical agents: Face-to-face interaction in interactive learning environments
Achieving a
A Philosophical Study.


The social dimension of interactions in multiagent systems.
An approach for modeling and simulating conversations.
Implementation and testing of a system for producing emotion-by-rule in synthetic speech
Explaining emotions.
The Cognitive Structure of Emotions.

Carrying the role-playing metaphor to interactive learning environments
A social-psychological model for synthetic actors
Improvising linguistic style: Social and a
--TR
The affective reasoner
The role of emotion in believable agents
Implementation and testing of a system for producing emotion-by-rule in synthetic speech
Affective computing
Improvising linguistic style
Developing for Microsoft Agent
A social-psychological model for synthetic actors
Requirements for an architecture for believable social agents
MYAMPERSANDEacute;mile
The automated design of believable dialogues for animated presentation teams
Personality Parameters and Programs
Acting in Character
The Social Dimension of Interactions in Multiagent Systems

--CTR
Patrick Gebhard , Michael Kipp , Martin Klesen , Thomas Rist, Authoring scenes for adaptive, interactive performances, Proceedings of the second international joint conference on Autonomous agents and multiagent systems, July 14-18, 2003, Melbourne, Australia
Matthias Rehm , Elisabeth Andr, Catch me if you can: exploring lying agents in social settings, Proceedings of the fourth international joint conference on Autonomous agents and multiagent systems, July 25-29, 2005, The Netherlands
Jonathan Gratch , Jeff Rickel , Elisabeth Andr , Justine Cassell , Eric Petajan , Norman Badler, Creating Interactive Virtual Humans: Some Assembly Required, IEEE Intelligent Systems, v.17 n.4, p.54-63, July 2002
Han Noot , Zsfia Ruttkay, Variations in gesturing and speech by GESTYLE, International Journal of Human-Computer Studies, v.62 n.2, p.211-229, February 2005
Robert C. Hubal , Geoffrey A. Frank , Curry I. Guinn, Lessons learned in modeling schizophrenic and depressed responsive virtual humans for training, Proceedings of the 8th international conference on Intelligent user interfaces, January 12-15, 2003, Miami, Florida, USA
Zsfia Ruttkay , Claire Dormann , Han Noot, Embodied conversational agents on a common ground, From brows to trust: evaluating embodied conversational agents, Kluwer Academic Publishers, Norwell, MA, 2004
Mitsuru Ishizuka , Helmut Prendinger, Describing and generating multimodal contents featuring affective lifelike agents with MPML, New Generation Computing, v.24 n.2, p.97-128, January 2006
Catherine Pelachaud , Isabella Poggi, Multimodal embodied agents, The Knowledge Engineering Review, v.17 n.2, p.181-196, June 2002
