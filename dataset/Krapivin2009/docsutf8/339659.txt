--T
Energy-driven integrated hardware-software optimizations using SimplePower.
--A
With the emergence of a plethora of embedded and portable applications, energy dissipation has joined throughput, area, and accuracy/precision as a major design constraint. Thus, designers must be concerned with both optimizing and estimating the energy consumption of circuits, architectures, and software. Most of the research in energy optimization and/or estimation has focused on single components of the system and has not looked across the interacting spectrum of the hardware and software. The novelty of our new energy estimation framework, SimplePower, is that it evaluates the energy considering the system as a whole rather than just as a sum of parts, and that it concurrently supports both compiler and architectural experimentation.
We present the design and use of the SimplePower framework that includes a transition-sensitive, cycle-accurate datapath energy model that interfaces with analytical and transition sensitive energy models for the memory and bus subsystems, respectively. We analyzed the energy consumption of ten codes from the multidimensional array domain, a domain that is important for embedded video and signal processing systems, after applying different compiler and architectural optimizations. Our experiments demonstrate that early estimates from the SimplePower energy estimation framework can help identify the system energy hotspots and enable architects and compiler designers to focus their efforts on these areas.
--B
INTRODUCTION
With more than 95% of current microprocessors going into
embedded systems, the need for low power design has become
vital. Even in environments not limited by battery
life, power has become a major constraint due to concerns
about circuit reliability and packaging costs. The increasing
need for low power systems has motivated a large body
of research on low power processors. Most of this research,
however, focuses on reducing the energy 1 in isolated sub-systems
(e.g. the processor core, the on-chip memory, etc.)
rather than the system as a whole [7]. The focus of our re-search
is to provide insight into the energy hotspots in the
system and to evaluate the implications of applying a combination
of architectural and software optimizations on the
overall energy consumption.
In order to perform this research, architectural-level power
estimation tools that provide a fast evaluation of the energy
impact of various optimizations early in the design cycle are
essential [2]. However, only prototype research tools and
methodologies exist to support such high-level estimation.
In this paper, we present the design of an architectural-level
energy estimation framework, SimplePower. To our knowl-
edge, this is the first framework with a capability to evaluate
the integrated impact of hardware and software optimizations
on the overall system energy. In contrast to coarse
grain current measurement-based techniques [26; 17], our
new tool is cycle-accurate, and provides a fine-grained energy
consumption estimate of the processor core (currently a
five-stage pipelined instruction set architecture (ISA)) while
also accounting for the energy consumed by the memory and
bus subsystems. SimplePower also leverages from the SimpleScalar
toolset [3] as it is executes the integer subset of
SimpleScalar ISA.
The memory subsystem is the dominant source of power
dissipation in various video and signal processing embedded
systems [6]. Existing low power work has focused on addressing
this problem through the design of energy efficient
memory architectures and power-aware software [12; 25; 23].
However, most of these efforts do not study the influence on
the energy consumption of the other system components and
even fewer consider the integrated impact of the hardware
and software optimizations. It is important to evaluate the
influence of optimizations on the overall system energy savings
and the power distribution across different components
of the system. Such a study can help identify the changes
1 The dynamic energy consumed by CMOS circuits is given
by is the switching activity on the lines,
C is the capacitive load and V is the supply voltage. We do
not consider the impact of leakage power.
in system energy hotspots and enable the architects and
compiler designers to focus their efforts on addressing these
areas.
This study embarks on this ambitious goal, specifically trying
to answer the following questions:
ffl What is the energy consumed across the different parts of
the system? Is it possible to evaluate this energy distribution
in a fast and accurate fashion for different applications?
ffl What is the effect of the state-of-the-art performance-oriented
compiler optimizations on the overall system energy
consumption and on each individual system compo-
nent? Does the application of these optimizations cause a
change in the energy hotspot of the system?
ffl What is the impact of power and performance-oriented
memory system modifications on the energy consumption?
How do compiler optimizations influence the effectiveness of
these modifications?
ffl What is the impact of advances in process technology on
the energy breakdown of the system? Can emerging new
technologies (e.g., embedded DRAMs [22]) result in major
paradigm shifts in the focus of architects and compiler writers

To our knowledge, there has been no prior effort that has
extensively studied all these issues in a unified framework
for the entire system. This paper sets out to answer some
of the above questions using codes drawn from the multi-dimensional
array domain, a domain that is important for
signal and video processing embedded systems.
The rest of this paper is organized as follows. The next
section presents the design of our energy estimation frame-
work, SimplePower. Section 3 presents the distribution of
energy across the different system components using a set
of benchmark codes. The influence of performance-oriented
compiler optimizations on system energy is examined in Section
4. Section 5 investigates the influence of energy-efficient
cache architectures on system power. Section 6 studies the
implications of emerging memory technologies on system en-
ergy. Finally, Section 7 summarizes the contributions of this
work and outlines directions for future research.
2. SIMPLEPOWER:ANENERGYESTIMA-
TION FRAMEWORK
Answering the questions posed in Section 1 requires tools
that allow the architect and compiler writer to estimate the
energy consumed by the system. The energy estimation
framework that we have developed for this purpose, Sim-
plePower, is depicted in Figure 1. For the purposes of this
work, we are using a system consisting of the processor core,
on-chip instruction and data caches, off-chip memory, and
the interconnect buses between the core and the caches and
between the caches and the off-chip memory. What we need
in our framework are tools that allow us to estimate the
energy consumed by each of the modules in the system.
Analytical models for memory components have been used
successfully by several researchers [13; 25] to study the power
Code
Energy
Object file
Energy
I/O Pads
Memory Bus
Optimization Module
Energy Energy
Energy Statistics
SimplePower
SimplePower
Executables
SimpleScalar
Assembly
Main
Memory
Icache Dcache
Cache/Bus Simulator
Power Estimation Interface
5.0V
2.0u 0.8u

Tables

SimplePower
SimpleScalar
GCC
SimpleScalar
GLD
GAS
SimpleScalar
Optimizations
RT Level
Low Level
Compiler
Optimizations
Compiler
High Level
Optimizations
Output
Module

Figure

1: SimplePower energy estimation frame-
work. It consists of the compilation framework and
the energy simulator that captures the energy consumed
by a five-stage pipeline instruction set archi-
tecture, the memory system and the buses.
tradeoffs of different cache/memory configurations. These
models attempt to capture analytically the energy consumed
by the memory address decoder(s), the memory core, the
read/write circuitry, sense amplifiers, and cache tag match
logic. Some of these models can also accommodate low
power cache and memory optimizations such as cache block
buffering [13], cache subbanking [25; 13], bit-line segmentation
[12], etc. These analytical models estimate the energy
consumed per access, but do not accommodate the energy
differences found in sequences of accesses. For example,
since energy consumption is impacted by switching activ-
ity, two sequential memory accesses may exhibit different
address decoder energy consumption. However, simple analytical
energy models for memories have proved to be quite
reliable [13]. This is the approach used in SimplePower to
estimate the energy consumed in the memories.
The energy consumption of the buses depends on the switching
activity on the bus lines and the interconnect capacitance
of the bus lines (with off-chip buses having much larger
capacitive loads than on-chip buses). When the switching
activity is captured by the energy model, we refer to the
technique as a transition-sensitive approach (in contrast to,
for example, the analytical model used for the memory sub-
system). The energy model used by SimplePower for system
buses is transition-sensitive. A wide variety of techniques
have been proposed to reduce system level interconnect energy
ranging from circuit level optimization such as using
low-swing or charge recovery buses, to architectural level
optimizations such as using segmented buses, to algorithmic
level optimizations such as using signal encoding (en-
coding the data in such a way as to reduce the switching
activity on the buses) [11]. As technology scales into the
deep sub-micron, chip sizes grow, and multiprocessor chip
architectures become the norm, system level interconnect
structures will account for a larger and larger portion of the
chip energy and delay. In this paper, we include the energy
consumed in the buses in the memory system energy, unless
specified otherwise.
The final system module to be considered is the processor
core. To support the architecture and compiler optimization
research posed in Section 1, the energy estimation of the
core must be transition-sensitive. At this point in the design
process, in order to support "what-if" experimentation,
the processor core is specified only at the architectural-level
(RTL level). However, without the structural capacitance
information that is part of a gate-level design description
(obtained via time consuming logic synthesis) and the inter-connect
capacitance information that is part of a physical-level
design description (obtained via very time consuming
VLSI design), it is difficult obtain the capacitance values
needed to estimate energy consumption. SimplePower solves
this dilemma by using predefined, transition-sensitive models
for each functional unit to estimate the energy consumption
of the datapath. This approach was first proposed by
Mehta, Irwin and Owens [20]. These transition-sensitive
models contain switch capacitances for a functional unit for
each input transition obtained from VLSI layouts and extensive
simulation. Once the functional unit models
have been built, they can be reused for many different
architectural configurations. SimplePower is, at this time,
only capturing the energy consumed by the core's datapath.
Developing transition-sensitive models for the control path
would be extremely difficult. One way to model control path
power would be analytically. In any case, for the SimplePower
processor core, the energy consumed by the datapath
is much larger than the energy consumed by the control logic
due to the relatively simple control logic. The architecture
simulated by SimplePower in this paper is the integer ISA
of SimpleScalar, a five stage RISC pipeline. Functional unit
energy models (for 2:0-; 0:8-, and 0:35- technology) have
been developed for various units including flip-flops, adders,
register files, multipliers, ALUs, barrel shifters, multiplex-
ors, and decoders.
SimplePower outputs the energy consumed from one execution
cycle to the next. It mines the transition sensitive
energy models provided for each functional unit and sums
them to estimate the energy consumed by each instruction
cycle. The size of these energy tables could, however, become
very large as the number of inputs to the bit-dependent
functional units increase (for units like registers, each bit positions
switching activity is independent and thus one small
table characterizing one flip-flop is sufficient). To solve the
table size problem, we partition the functional units into
smaller sub-modules. For example, a register file is partitioned
into five major sub-modules: five 5:32 decoders,
word-line drivers, write data drivers, read sense-amplifiers,
and a 32 \Theta 32 cell array. Energy tables were constructed for
each submodule. For example, a 1,024 entry table indexed
by the pair of five current and five previous register select
address bits was developed for the register file decoder com-
ponent. This table is then shared by all the five decoders
in the register file. Since the write data drivers, read sense
amplifiers, word line dividers and all array cells are all bit-
independent submodules, their energy tables are quite small.
For the 32 \Theta 32 5-port register file, our power estimation
approach took much less than 0.1 seconds for each input
transition as opposed to the 556.42 seconds required for circuit
level simulation using HSPICE. The machine running
the HSPICE simulation and our simulator is a Sun Ultra-10
with 640 MBytes memory. Our transition-sensitive modeling
approach has been validated to be accurate (average
error rate of 8.98%) using actual current measurements of a
commercial DSP architecture [9].
As mentioned earlier, SimplePower currently uses a combination
of analytical and transition-sensitive energy models
for the memory system. The overall energy of the the memory
system is given by
The energy consumed by the instruction cache (Icache),
and by the data cache (Dcache), EDcache , is evaluated
using an analytical model that has been validated to
be accurate (within 2.4% error) for conventional cache systems
[13; 24]. We extended this model to consider the energy
consumed during writes as well and have also parameterized
the cache models to capture different architectural optimiza-
tions. EBuses includes the energy consumed in the address
and data buses between the Icache/Dcache and the datap-
ath. It is evaluated by monitoring the switching activity on
each of the bus lines assuming a capacitive load of 0.5pF
per line. The energy consumed by the I/O pads and the
external buses to the main memory from the caches, EPads ,
is evaluated similarly for a capacitive load of 20pF per line.
The main memory energy, EMM , is based on the model in
[24] and assumes a per main memory access energy (refered
as Em in the rest of the paper) of 4:95\Theta10 \Gamma9 J based on the
data for the Cypress CY7C1326-133 SRAM chip.
While the SimplePower framework models the influence of
the clock on all components of the architecture (i.e., it assumes
clock gating is implemented), it does not capture the
energy consumed by the clock generation and clock distribution
network. Existing clock energy estimation models
[19; 8] require clock loading and physical dimensions of the
design that can be obtained only after physical design and
are difficult to estimate in the absence of structural infor-
mation. However, we realize that this is an important additional
component of the system energy consumption and
we plan to address this in future research.
3. ENERGY DISTRIBUTION
With the emergence of energy consumption as a critical constraint
in system design, it is essential to identify the energy
hotspots of the system early in the design cycle. There has
been significant work on estimating and optimizing the system
power [7]. However, many have focused on estimat-
ing/optimizing only specific components of the system and
most do not capture the integrated impact of circuit, architectural
and software optimizations. Further, most existing
high-level RTL energy estimation techniques provide a
coarse grain of measurement resulting in 20-40% error relative
to that of a transistor level estimator [2]. By contrast,
SimplePower provides an integrated, cycle-accurate energy
estimation mechanism that captures the energy consumed
Program Source # of Arrays Input Size (KB) Instruction Count Dcache Miss Rates
dtdtz (aps) Perfect Club 17 1,605 42,119,337 0.135
bmcm (wss) Perfect Club 11 126 89,539,244 0.105
psmoo (tfs) Perfect
eflux (tfs) Perfect Club 5 297 12,856,306 0.114
amhmtm (wss) Perfect

Table

1: Programs used in the experiments. Dcache miss rates are for 1K direct mapped caches with
line sizes. Instruction count is dynamic instruction count.1030507090%
Energy
Consumed
in
Components
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Register File
Pipeline Registers
Arithmetic Units
Energy
Consumed
in
Pipeline
Stages
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Fetch
Decode
Execute
Memory
WriteBack

Figure

2: Energy distribution (%) of (a) the major energy consuming data path components and (b) the
pipeline stages. The memory pipeline stage energy consumption does not include that of the ICache and
DCache.2060100%
Energy
Consumed
in
Memory
System
Components
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Buses
Icache
Dcache
I/O Pads
Imemory
Dmemory2060100%
Energy
Consumed
in
Memory
System
Components
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Buses
Icache
Dcache
I/O Pads
Imemory
Dmemory

Figure

3: Energy distribution (%) in memory system: (a) 1K 4way Dcache and (b) 8K 4way Dcache.
Imemory and Dmemory are the energies consumed in accessing the main memory for instructions and data,
respectively.
Original (Unoptimized) Optimized
Memory System Energy Datapath Memory System Energy
Energy (mJ) Energy (mJ)
1-way 2-way 4-way 8-way (mJ) # ! 1-way 2-way 4-way 8-way
tomcatv 3.9 4K 75.8 171.1 172.7 175.4 4.2 4K 52.3 34.6 34.9 35.4
btrix 30.2 4K 1,023.2 513.6 432.6 371.5 28.8 4K 1,093.0 718.8 641.1 593.2
mxm 34.3 4K 1,123.9 522.7 405.3 267.5 83.7 4K 342.0 173.7 159.5 174.6
8K 1,059.3 377.8 240.6 245.0 8K 300.5 192.6 196.4 199.6
vpenta 1.6 4K 109.6 112.9 113.6 113.8 1.9 4K 77.2 60.6 58.9 59.0
8K 78.4 80.9 82.7 87.4 8K 66.2 57.8 57.4 57.6
adi 4.3 4K 166.9 136.7 136.4 136.9 5.2 4K 90.5 77.3 83.1 77.0
1K 2,149.3 1,402.8 1,146.1 1,064.8 1K 1,927.4 823.1 516.2 431.6
dtdtz 27.5 4K 880.5 857.7 815.1 861.2 31.2 4K 428.1 180.2 180.1 136.8
bmcm 59.2 4K 1,007.6 654.2 536.1 385.9 90.0 4K 724.4 416.8 289.8 227.5
psmoo 11.6 4K 341.9 340.7 328.9 343.9 16.1 4K 125.7 102.4 88.2 89.6
341.3 267.5 267.7 269.2 8K 91.8 81.1 81.5 84.1
eflux 8.6 4K 383.0 364.9 368.6 379.6 10.1 4K 226.1 192.9 192.7 193.5
amhmtm 59.8 4K 623.7 271.1 259.9 265.1 66.5 4K 748.9 303.3 287.0 300.0
8K 578.3 308.4 301.9 309.8 8K 551.3 217.5 232.7 265.3
447.2 403.7 403.2 411.8 16K 368.2 290.5 287.6 297.6

Table

2: Energy consumption for various Dcache configurations. For all the cases, an 8K direct-mapped
Icache, line sizes, writeback policy and a core based on 0:8-, 3:3V technology are used.
in the different components of the system.
In this section, we present the energy characteristics of ten
benchmark codes written in the C language 2 (shown in Table
1) from the multidimensional array domain. An important
characteristic of these codes is that they access large
arrays using nested loops. The applications run on energy-constrained
signal and video embedded processing systems
exhibit similar characteristics. Since SimplePower currently
works only with integer data types, floating point data accessed
by these codes were converted to operate on integer
data. In particular, memory access patterns (in terms of
temporal and spatial locality) do not change. In order to
limit the simulation times we scaled down the input sizes;
however, all the benchmarks were run to completion. The
experimental cache sizes (1K-16K) used in our study are
relatively small as our focus is on resource-constrained embedded
systems.
The energy consumed by the system is divided into two
parts: datapath energy and memory system energy. The ma-
Original codes are in Fortran and were converted into C
by paying particular attention to the original data access
patterns.
jor energy consuming components of the datapath are the
register file, pipelined registers, the functional units (e.g.
ALU, multiplier, divider), and datapath multiplexers. The
memory system energy includes the energy consumed by the
Icache and Dcache, the address and data buses, the address
and data pads and the off-chip main memory. Table 2 provides
the energy consumption (in mJ) of our benchmarks for
the datapath and memory system for various Dcache con-
figurations. For all the cases in this paper, an 8K direct
mapped Icache, line sizes of 32 bytes (for both Dcache and
Icache), writeback cache policy, and a core based on 0:8-,
3.3V technology were used. We also present only a single
datapath energy value for the different configurations due
to the efficient stall power reduction techniques (e.g., clock
gating on the pipeline registers) employed in the datapath.
With the aggressive clock gating assumed by SimplePower,
the energy consumed during stall cycles was observed to be
insignificant for our simulations. For example, tomcatv expends
a maximum of 1% of the total datapath energy on
stalls for all cache configurations studied.
We observe that the datapath energy consumption ranges
from 1.577mJ to 59.776mJ for the various codes determined
by the dynamic instruction length and the switching ac-
Energy
Consumed
in
Components
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Register File
Pipeline Registers
Arithmetic Units
Energy
Consumed
in
Pipeline
Stages
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Fetch
Decode
Execute
Memory
WriteBack

Figure

4: Energy distribution (%) of (a) the major energy consuming data path components and (b) the
pipeline stages after applying code transformations. The memory pipeline stage energy consumption does
not include that of the ICache and DCache.
tivity in the datapath. Compared to the memory system
energy, the datapath energy is an order or two smaller in
magnitude. This result corroborates the need for extensive
research on optimizing the memory system power [25; 6; 13;
7]. Next, we zoom-in on the major energy consuming components
of the datapath. It is observed from Figure 2(a)
that the pipeline registers and register file form the energy
hotspots in the datapath contributing 58-70% of the overall
datapath energy. The extensive use of pipelining in DSP
data paths to improve performance [1] and facilitate other
circuit optimization such as voltage scaling will exacerbate
the pipeline register energy consumption. Also, larger and
multiple-port register files required to support multiple issue
machines will increase the register file energy consumption
further. The core energy distribution is also found to be
relatively independent of the codes being analyzed. This is
undoubtably impacted by only simulating integer data op-
erations. The energy consumed by each stage of the pipeline
is calculated by SimplePower and is shown in Figure 2(b).
The decode stage energy does not include control logic energy
consumption since it is not modeled by SimplePower.
The pipeline register is the main contributer to the energy
consumed in the memory stage, since ICache and DCache
energy consumption is not included. The execution stage
of the pipeline that contains the arithmetic units is the major
energy consumer in the entire datapath, since the register
file energy consumption is split between the decode and
writeback stages.
The memory system energy consumption generally reduces
with decrease in capacity and conflict misses when the DCache
size or associativity is increased (see Table 2). Yet, in thirty
seven out of the fifty cases, when we move from a 4way to
8way DCache, the memory system energy consumption in-
creases. A similar trend is observed in fifteen out of forty
cases when we move from an 8K to 16K Dcache. Moving
to a larger cache size or higher associtivities increases the
energy consumption per access. However, for many cases,
this per access cost is amortized by the energy reduction
due to a fewer number of accesses to the main memory.
Of course, if the numbers of misses/hits are equal, using
a less sophisticated cache leads to lower energy consumption

Figure

3(a) shows the energy distribution in the memory
system components for a 1K 4way Dcache configuration
where the main memory energy consumption dominates
due to the large number of Dcache misses. For btrix and
amhmtm, the data accesses per instruction are the smallest.
In amhmtm, the majority of instruction accesses are satisfied
from the Icache resulting in a more significant Icache energy
consumption, whereas btrix exhibits a relatively poor instruction
cache locality (the number of Icache misses is 100
times more than the next significant benchmark) resulting
in increased energy consumption in main memory. When we
increase the data cache size, the majority of data accesses
are satified from the data cache. Hence, the overall contribution
of the Icache and Dcache becomes more significant
as observed from Figure 3(b).
SimplePower provides a comprehensive framework for identifying
the energy hotspots in the system and helps the hardware
and software designers focus on addressing these bot-
tlenecks. The rest of this paper evaluates software and architectural
optimizations targeted at addressing the energy
hotspot of the system, namely, the energy consumed in data
accesses.
4. IMPACTOFCOMPILEROPTIMIZATIONS
To evaluate the impact of compiler optimizations on the
overall energy consumption, we used a high-level compilation
framework based on loop (iteration space) and data (ar-
ray layout) transformations. For this study, the framework
proposed in [14] was enhanced with iteration space tiling,
loop fusion, loop distribution, loop unrolling, and scalar re-
placement. Thus, our compiler is able to apply a suitable
combination of loop and data transformations for a given
input code, with an optimization selection criteria similar
to that presented in [14]. Our enhanced framework takes as
input a code written in C and applies these optimizations
(primarily) to improve temporal and spatial data locality.
The tiling technique employed is similar to one explained in
[27] and selects a suitable tile size for a given code, input
size, and cache configuration. The loop unrolling algorithm
carefully weighs the advantages of increasing register reuse
and the disadvantages of larger loop nests in selecting an
optimal degree of unrolling and is similar in spirit to the
technique discussed in [5].
Energy
Consumed
in
Memory
System
Components
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Buses
Icache
Dcache
I/O Pads
Imemory
Dmemory2060100%
Energy
Consumed
in
Memory
System
Components
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Buses
Icache
Dcache
I/O Pads
Imemory
Dmemory

Figure

5: Energy distribution in memory system after applying code transformations: (a) 1K 4way Dcache
and (b) 8K 4way Dcache. Imemory and Dmemory are the energies consumed in accessing the main memory
for instructions and data, respectively.
There have been numerous studies showing the effectiveness
of these optimizations on performance (e.g., [21; 28]); their
impact on energy consumption of different parts of a computing
system, however, remains largely unstudied. This
study is important because these optimizations are becoming
popular in embedded systems, keeping pace with the
increased use of high-level languages and compilation techniques
on these systems [18]. Through a detailed analysis of
the energy variations brought about by these techniques, architects
can see which components are energy hotspots and
develop suitable architectural solutions to account for the
influence of these optimizations.
Our expectation is that most compiler optimizations (in particular
when they are targeted at improving data locality)
will reduce the overall energy consumed in memory subsys-
tem. This is a side effect of reducing the number of off-chip
data accesses and satisfying the majority of the references
from the cache. Their impact on the energy consumed in the
datapath, on the other hand, is not as clear. As observed in
Section 3, the energy consumed in the memory subsystem
is much higher than that consumed in the datapath. While
this might be true for unoptimized codes (due to the large
number of off-chip accesses), it would be interesting to see
whether this still holds after the locality-enhancing compiler
optimizations.

Table

also shows the resulting datapath and memory system
energy consumption as a result of applying our compiler
transformations. The most interesting observation is
that the optimizations increase the datapath power for all
codes except btrix. This increase is due to more complex
loop structures and array subscript expressions as a result of
the optimizations. Since, in optimizing btrix, the compiler
used only linear loop transformations (i.e., the transformations
that contain only loop permutation, loop reversal, and
loop skewing [28]), the datapath energy did not increase.
Next, we observe that the reduction in the memory system
energy makes the datapath power more significant. For ex-
ample, after the optimizations, in the mxm benchmark, the
datapath power constitutes 29% of the overall system energy
for a 8K 8way cache configuration (as compared to 12.3%
before the optimizations). In fact, the datapath power becomes
larger than that consumed in the memory system if
we do not consider the energy expended in instruction ac-
cesses. This is significant as our optimizations were targeted
only at improving the data cache performance. Thus, it is
important for architects to continue to look at optimizing
the datapath energy consumption rather than focus only on
memory system optimizations.
The compiler optimizations had little effect on the energy
distribution on the datapath components and pipeline stages
as shown in Figures 4(a) and (b). However, the energy distribution
(shown in Figure 5) in the memory system shows
distinct differences from the unoptimized (original) versions
(see

Figure

3). In the optimized case, the relative contribution
of the main memory is significantly reduced due to
more data cache hits. Hence, we observe that the contribution
of the Icache and Dcache energy consumption becomes
more significant for all optimized codes that we used.
Thus, energy-efficient Icache and Dcache architectures become
more important when executing the compiler optimized
codes. The effectiveness of architectural and circuit
techniques to design energy-efficient caches is discussed in
Section 5.
As mentioned earlier, normally, our compiler automatically
selects a suitable set of optimizations for a given code and
cache topology. Since, in doing so, it uses heuristics, there is
no guarantee that it will arrive at an optimal solution. In addition
to this automatic optimization selection, we have also
implemented a directive-based optimization scheme which
relies on user-provided directives and, depending on them,
applies the necessary loop and data transformations. Next,
we forced the compiler using these compiler directives to
apply all eight combinations of three mainstream loop optimizations
[28], namely, loop unrolling, tiling, and linear
loop transformations to the mxm benchmark. The results
presented in Figure 6 reveal that the best compiler transformation
from the energy perspective varies based on the
cache configuration. This observation presents a new challenge
for the compiler writers of embedded systems, as the
most aggressive optimizations (although they may lead to
minimum execution times) do not necessarily result in the
best code from the energy point of view.
1-way 2-way 4-way 8-way
1-way 2-way 4-way 8-way
Memory
Energy
(Joules)
original
loop opt
unrolled
tiled
loop opt+unrolled
loop opt+tiled
tiled+unrolled
tiled+loop opt+unrolled

Figure

Energy distribution in the memory system
(with different DCache configurations) as a result of
different code transformations. original is the un-optimized
program, loop opt denotes the code optimized
using linear loop transformations, unrolled
denotes the version where loop unrolling is used and
tiled is the version when tiling is applied.
5. ENERGY EFFICIENT CACHE ARCHITECTURE

The study of cache energy consumption is relatively new
and the optimization techniques can be broadly classified
as circuit and architectural. The main circuit optimizations
include activating only a portion of the cells on the
bit (DBL) and word lines, reducing the bit line swings using
pulsed word lines (PWL) and isolated sense amplifiers
(IBL), and charge recycling in the I/O buffer [12]. The application
of these optimizations is independent of the code
sequences themselves. Many architectural techniques have
been proposed as optimizations for the memory system [25;
13; 16]. Many of these techniques introduce a new level of
memory hierarchy between the cache and the processor dat-
apath. For instance, the work by Kin et. al. [16] proposed
accessing a small filter cache before accessing the first level
cache. The idea is to reduce the energy consumption by
avoiding access to a larger cache. While such a technique
can have a negative impact on performance, it can result in
significant energy savings. The block-buffering (BB) mechanism
[13] uses a similar idea by accessing the last accessed,
buffered cache line before accessing the cache. Unlike circuit
optimizations, the effectiveness of these architectural
techniques is influenced by the application characteristics
and the compiler optimizations used. For instance, software
techniques can be used to improve the locality in a cache
line by grouping successively accessed data. Then, a cache
buffering scheme can exploit this improved locality. Thus,
increasing spatial locality within a cache line through software
techniques can save more energy. A detailed study
of such interactions between software optimizations and the
effectiveness of energy-efficient cache architectures will be
useful to both compiler writers and hardware designers.
To capture the impact of circuit optimization in the energy
estimation framework, we measured the influence of applying
different combinations of circuit optimizations using four
different layouts of a 0.5Kbits SRAM using HSPICE simu-
lations. It was observed that the energy consumed can be
reduced on an average by 29% and 52% as compared to an
unoptimized SRAM when applying the (PWL+IBL) and
(PWL+IBL+DBL) optimizations. We conservatively utilize
the 29% reduction achieved by the (PWL+IBL) scheme
to capture the efficiency of the circuit optimizations in our
analytical model for memory system energy. We refer to
the (PWL+IBL) scheme as IBL in the rest of this paper for
convenience.
First, we studied the interaction between the compiler optimizations
and the effectiveness of the BB mechanism. In
order to study this interaction, the Dcache was enhanced
to include a buffer for the last accessed set of cache blocks
(one block buffer for each way). A code that exhibits increased
spatial and temporal locality can effectively exploit
the buffer. We define the relative energy savings ratio of an
optimized code (opt) over an unoptimized code (orig) for a
given hardware optimization hopt as:
Relative energy savings ratio
are the energy consumed due to
the execution of optimized and unoptimized code respectively
without hopt, and E optcodehopt , E orighopt are the
corresponding values with hopt. This measure enables us
to evaluate the effectiveness of compiler optimizations in
exploiting the hardware optimization technique. Figure 7
shows the relative energy savings ratio for BB. It can be
observed that the block buffer mechanism was more effective
in reducing energy for the optimized codes (except for
eflux). This is due to the better spatial and temporal locality
exhibited by the compiler optimized codes. This improved
locality results in more hits in the block buffer. On
an average, the optimized codes achieve 19% (18%) more
energy savings relative to the original codes using a direct-mapped
(4way) cache with BB. The reason that optimized
eflux code does not take better advantage of BB than un-optimized
code is that the accesses with temporal locality
in the unoptimized code were better clustered, leading to
increased data reuse in the block buffer. Next, we applied a
combination of the IBL and BB and executed the optimized
codes to find the combined effect of circuit, architectural
and software optimizations on the overall memory system
energy. It can be observed from Figure 8 that the Dcache
energy consumption can be reduced by 58.8% (58.7%) for
the direct-mapped (4way) cache configuration. Thus, architectural
and circuit techniques working together can reduce
the energy consumption of even highly optimized codes sig-
nificantly. While the BB and IBL optimizations are very
effective for reducing the energy consumed in the Dcache, it
is important to investigate their impact on the overall memory
energy reduction. It was found that the memory system
energy reduces by 6.7% (11%) using the direct-mapped
(4way) cache configuration (see Figure 9).
We also investigated the influence of the BB+IBL optimization
for the Dcache due to the reduction in the energy per
main memory access (Em) as a result of emerging technologies
such as the embedded DRAM (eDRAM) [22]. Figure 10
shows that the combined BB and IBL technique reduces
memory system energy by 27.7% with new (future) tech-
7Relative
Energy
Savings
of
Optimized
over
Unoptimized
Codes
(a)
btrix
mxm
vpenta
adi
dtdtz
bmcm
psmoo
eflux
amhmtm
-0.3
-0.2
-0.10.10.30.5Relative
Energy
Savings
of
Optimized
over
Unoptimized
Codes
(b)
btrix
mxm
vpenta
adi
dtdtz
bmcm
psmoo
eflux
amhmtm

Figure

7: Relative energy savings ratio of Dcache for optimized code over unoptimized code using BB on (a)
1way Dcaches and (b) 4way Dcaches.
nologies that have a potential to reduce the per access energy
by an order of magnitude (We use a Em=4.95e-10J)
as compared to the 16.3% reduction in current technology
(Em=4.95e-9J). SimplePower can similarly be used to evaluate
the influence of other new technologies and energy-efficient
techniques such as BB on the energy consumed by
the system as a whole and an individual component in particular

Next, we evaluated the combination of a most recently used
way-prediction cache and BB mechanism. The way-prediction
caches have been used to address the longer cycle time in
associative caches as compared to direct mapped caches
[4]. While most prior effort has focussed on way-prediction
caches for addressing the performance problem, the energy
efficiency of these cache architectures was evaluated recently
by Inoue et. al. [10]. In their work, an MRU (Most Recently
Used) algorithm that predicts and probes only a single way
first was used. If the prediction turns out to fail, all remaining
ways are accessed at the same time in the next
cycle. We refer to this technique as the MRU scheme and
the caches that use them as MRU caches. It must be noted
that MRU caches could increase the cache access cycle time
[4; 15]. However, our work focus is on energy estimation and
optimization rather than investigating energy-performance
tradeoffs. Here, we study the effectiveness of combining two
different architectural techniques to optimize system energy
and also evaluate the impact of software optimizations enabled
by the SimplePower optimizing compiler on the MRU
prediction.
We studied the energy savings that can be obtained using
MRU caches for 4way associative cache configurations. It
can be observed from Figure 11 that the optimized codes
benefit more from the MRU scheme and can obtain 21%
more savings than the original code on an average. The
increased locality in the optimized codes increases the number
of successful probes in the predicted way of the MRU
cache. We also find that using the MRU scheme reduces
Dcache energy by 70.2% on an average for optimized codes
as compared to using a conventional 8K, 4way associative
caches (see Figure 12(a)). The incremental addition of BB
and IBL provided additional 10.5% and 5.5% energy reduction
respectively. Figure 12(b) shows the energy savings in
the entire memory system are 23%, 24.2% and 26.4% when
MRU, BB and IBL are applied incrementally in that order.
-0.10.10.30.5Relative
Energy
Savings
of
Optimized
over
Unoptimized
Codes
btrix
mxm
vpenta
adi
dtdtz
bmcm
psmoo
eflux
amhmtm

Figure

Relative energy savings ratio of Dcache
for optimized code over unoptimized code using
MRU for 4way Dcaches.
From the study in this section, we find that the optimized
codes are not only efficient in reducing the number of costly
(in terms of energy) accesses to main memory but they are
also more effective in exploiting the energy efficient architectural
mechanisms such as MRU caches and BB. We also
find that the incremental benefits of applying the BB scheme
over a MRU cache is significantly smaller as compared to using
these techniques individually. A designer can use similar
early energy estimates provided by SimplePower to perform
energy-cost-performance tradeoffs for new energy efficient
techniques.
6. IMPLICATIONSOFENERGY-EFFICIENT
Emerging new technologies combined with the energy-efficient
circuit, architectural and compiler techniques for reducing
memory system energy can potentially create a paradigm
shift in the importance of energy optimizations from the
memory system to the datapath and other units. Here, we
consider the influence of changes in the energy consumed per
main memory access, Em . Such changes are eminent due to
new process technologies [22] and reduction in physical distance
between the main memory and the datapath. Table 3
shows the memory system energy for different values of Em
for four different cache organizations using two optimized
codes. Note that is the value that we
have used so far in this paper. The lowest Em value that we
experiment with in this section (4:95 \Theta 10 \Gamma11 ) corresponds to
Dcache
Energy
Consumption
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Base
Dcache
Energy
Consumption
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Base

Figure

8: Dcache energy consumption of optimized codes using (BB + IBL) for (a) 1way 8K Dcaches and
(b) 4way 8K Dcaches.0.10.30.50.7Memory
System
Energy
Consumption(J)
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Base
Memory
System
Energy
Consumption
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Base

Figure

9: Memory system energy for optimized codes using (BB using (a) 1way 8K Dcaches and (b)
4way 8K Dcaches.0.10.30.50.7
Memory
System
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Base
Memory
System
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Base

Figure

10: Memory system energy for optimized codes using (BB using 4way 16K Dcaches with (a)
Data
Cache
Energy
Consumption
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(a)
Base
MRU
Memory
System
Energy
Consumption
tomcatv btrix mxm vpenta adi dtdtz bmcm psmoo eflux amhmtm
(b)
Base
MRU
MRU+BB+IBL

Figure

12: Energy consumption when a combination of MRU, BB and IBL techniques are applied to an 8K,
4way associative cache configuration (Base) in (a) Dcache (b) Memory System.
the magnitude of energy per first-level on-chip cache access
with current technology.
Recall that the datapath energy consumption for the optimized
mxm and psmoo codes were 83.7mJ and 16.1mJ, respectively
(see Table 2). Considering the fact that large
amounts of main memory storage capacity are coming closer
to the CPU [22], we expect to see Em values lower than
in the future. Such a change could make
the energy consumed in the datapath larger than the energy
consumed in memory. For example, with
and a 1K, 4-way cache, the energy values of datapath becomes
larger than that of the memory system for mxm.
7. CONCLUSIONS
The need for energy efficient architectures has become more
critical than ever with the proliferation of embedded devices.
Also, the increasing complexity of the emerging systems on
a chip paradigm makes it essential to make good energy-conscious
decisions early in the design cycle to help define
design parameters and eliminate incorrect design paths.
This study has introduced a comprehensive framework that
can provide such early energy estimates at the architectural
level. The uniqueness of this framework is that it captures
the integrated impact of both hardware and software optimizations
and provides the ability to study the system as
a whole and each individual component in isolation. This
work has tried to answer some of the questions raised in
Section 1 using this framework. The major findings of our
research are the following:
ffl A transition-sensitive, cycle-accurate, architectural-level
approach can be used to provide a fast (as compared to
circuit-level simulators) and relatively accurate estimate of
the energy consumption of the datapath. For example, the
register file energy estimates from our simulator are within
2% of circuit level simulation.
ffl The energy hotspots in the datapath were identified to be
the pipeline registers and the register file. They consume 58-
70% of the overall datapath energy for executing (original)
unoptimized codes. However, the datapath energy is found
to be an order or two magnitude less the memory system
energy for these multidimensional array codes.
ffl The main memory energy consumption accounts for almost
all the system energy for small cache configurations
when executing unoptimized codes. The application of high-level
compiler optimizations significantly reduces the main
memory energy causing the Dcache, Icache and datapath
energy contributions to become more significant. For exam-
ple, the contribution of datapath energy to overall system
energy, with an 8K, 8way Dcache, increases from 12.3% to
29.5% when benchmark mxm is optimized.
ffl The improved spatial and temporal locality of the optimized
codes is useful in not only reducing the accesses to the
main memory but also in exploiting energy-efficient cache architectures
better than with unoptimized codes. Optimized
codes saved 21% times more energy using the most recently
used way-predicting cache scheme as compared to executing
unoptimized codes. They also save 19% more energy when
using block buffering.
Emerging technologies coupled with a combination of
energy-efficient circuit, architectural and compiler optimizations
can shift the energy hotspot. We found that with an
order of magnitude reduction in main memory energy access
made possible with eDRAM technology, the datapath
energy consumption becomes larger than the memory system
energy when executing an optimized mxm code with a
4way Dcache.
In this work, we observed that the compiler optimizations
provided the most significant energy savings over the entire
system. The SimplePower framework can also be used
for evaluating the effect of high-level algorithmic, architec-
tural, and compilation trade-offs on energy. Also, we observed
that energy-efficient architectures can reduce the energy
consumed by even highly optimized code significantly
and, in fact, much better than with unoptimized codes. An
understanding of the interaction of hardware and software
optimizations on system energy gained from this work can
help both architects and compiler writers to develop more
energy-efficient systems.
This paper has looked at only a small subset of issues with
respect to studying the integrated impact of hardware-software
optimizations on energy. There are a lot of issues that are
ripe for future research. The interaction of algorithmic selec-
mxm
Confi- Memory Energy (mJ)
guration
1K, 1way 41.3 81.9 132.6 538.2 1,045.2 5,101.1 10,171.2 50,731.1
1K, 4way 38.1 45.9 55.8 134.3 232.6 1,018.4 2,000.9 9,860.0
4K, 1way 80.8 91.3 104.5 210.1 342.0 1,397.9 2,717.6 13,275.3
4K, 4way 86.2 89.2 92.9 122.5 159.6 455.9 826.2 3,788.9
psmoo
Confi- Memory Energy (mJ)
guration
1K, 1way 13.1 35.0 62.5 282.2 556.8 2,753.4 5,499.3 27,466.1
1K, 4way 9.4 15.6 23.4 85.8 163.7 787.3 1,566.8 7,802.6
4K, 1way 17.3 21.7 27.2 70.9 125.8 563.9 1,111.7 5,493.6
4K, 4way 18.4 21.3 24.8 52.9 88.2 370.2 723.0 3,542.1

Table

3: Impact of different Em values on total memory system energy consumption for optimized mxm and
psmoo.
tion, low-level compiler optimizations and other low-power
memory structures will be addressed in our future work.
8.

ACKNOWLEDGEMENTS

The authors would like to thank the anonymous reviewers
whose commments helped to improve this paper. This work
was sponsored in part by grants from NSF (MIP-9705128),
Sun Microsystems, and Intel.
9.



--R

High performance DSPs - what's hot and what's not? <Proceedings>In Proceedings of International Symposium on Low Power Electronics and Design</Proceedings>
Emerging power management tools for processor design.
The simplescalar tool set
Predictive sequential associative cache.

Custom memory management methodology - exploration of memory organization for embedded multimedia system design
Low Power Digital CMOS Design.
Clock power issues in system-on-chip designs
Validation of an architectural level power analysis technique.

Energy issues in multimedia systems.
Trends in low-power ram circuit technologies
Analytical energy dissipation models for low power caches.
Improving locality using loop and data transformations in an integrated framework.
Inexpensive implementations of self-associativity
The filter cache
A framework for estimating and minimizing energy dissipation of embedded hw/sw systems.
Code Generation and Optimization for Embedded Digital Signal Processors.
Power consumption estimation in cmos vlsi chips.
Energy characterization based on clustering.
Advanced Compiler Design Implementation.

Software design for low power.
Memory exploration for low power
Cache designs for energy efficiency.
Instruction level power analysis and optimization of software.
Combining loop transformations considering caches and scheduling.
High Performance Compilers for Parallel Computing.
--TR
Inexpensive implementations of set-associativity
Instruction level power analysis and optimization of software
Energy characterization based on clustering
Combining loop transformations considering caches and scheduling
Analytical energy dissipation models for low-power caches
Software design for low power
The filter cache
Unroll-and-jam using uniformly generated sets
A framework for estimation and minimizing energy dissipation of embedded HW/SW systems
Validation of an architectural level power analysis technique
High performance DSPs - what''s hot and what''s not?
Emerging power management tools for processor design
Advanced compiler design and implementation
Improving locality using loop and data transformations in an integrated framework
Way-predicting set-associative cache for high performance and low energy consumption
Low Power Digital CMOS Design
M32R/D-Integrating DRAM and Microprocessor
Cache designs for energy efficiency
Predictive sequential associative cache
Clock Power Issues in System-on-a-Chip Designs
Code generation and optimization for embedded digital signal processors

--CTR
G. Palermo , C. Silvano , S. Valsecchi , V. Zaccaria, A system-level methodology for fast multi-objective design space exploration, Proceedings of the 13th ACM Great Lakes symposium on VLSI, April 28-29, 2003, Washington, D. C., USA
L. Salvemini , M. Sami , D. Sciuto , C. Silvano , V. Zaccaria , R. Zafalon, A methodology for the efficient architectural exploration of energy-delay trade-offs for embedded systems, Proceedings of the ACM symposium on Applied computing, March 09-12, 2003, Melbourne, Florida
N. Vijaykrishnan , Mahmut Kandemir , Mary Jane Irwin , Hyun Suk Kim , Wu Ye , David Duarte, Evaluating Integrated Hardware-Software Optimizations Using a Unified Energy Estimation Framework, IEEE Transactions on Computers, v.52 n.1, p.59-76, January
Eui-Young Chung , Luca Benini , Giovanni De Micheli, Automatic source code specialization for energy reduction, Proceedings of the 2001 international symposium on Low power electronics and design, p.80-83, August 2001, Huntington Beach, California, United States
Gianluca Palermo , Cristina Silvano , Vittorio Zaccaria, Power-Performance System-Level Exploration of a MicroSPARC2-Based Embedded Architecture, Proceedings of the conference on Design, Automation and Test in Europe: Designers' Forum, p.20182, March 03-07,
Nam Sung Kim , Taeho Kgil , Valeria Bertacco , Todd Austin , Trevor Mudge, Microarchitectural power modeling techniques for deep sub-micron microprocessors, Proceedings of the 2004 international symposium on Low power electronics and design, August 09-11, 2004, Newport Beach, California, USA
Nam Sung Kim , Todd Austin , Trevor Mudge , Dirk Grunwald, Challenges for architectural level power modeling, Power aware computing, Kluwer Academic Publishers, Norwell, MA, 2002
Jun Yang , Rajiv Gupta, Energy-efficient load and store reuse, Proceedings of the 2001 international symposium on Low power electronics and design, p.72-75, August 2001, Huntington Beach, California, United States
David M. Brooks , Pradip Bose , Stanley E. Schuster , Hans Jacobson , Prabhakar N. Kudva , Alper Buyuktosunoglu , John-David Wellman , Victor Zyuban , Manish Gupta , Peter W. Cook, Power-Aware Microarchitecture: Design and Modeling Challenges for Next-Generation Microprocessors, IEEE Micro, v.20 n.6, p.26-44, November 2000
Peter Petrov , Alex Orailoglu, Data cache energy minimizations through programmable tag size matching to the applications, Proceedings of the 14th international symposium on Systems synthesis, September 30-October 03, 2001, Montral, P.Q., Canada
David Brooks , Pradip Bose , Margaret Martonosi, Power-performance simulation: design and validation strategies, ACM SIGMETRICS Performance Evaluation Review, v.31 n.4, p.13-18, March 2004
G. Esakkimuthu , N. Vijaykrishnan , M. Kandemir , M. J. Irwin, Memory system energy (poster session): influence of hardware-software optimizations, Proceedings of the 2000 international symposium on Low power electronics and design, p.244-246, July 25-27, 2000, Rapallo, Italy
Todd Austin , Eric Larson , Dan Ernst, SimpleScalar: An Infrastructure for Computer System Modeling, Computer, v.35 n.2, p.59-67, February 2002
Diana Marculescu , Anoop Iyer, Application-driven processor design exploration for power-performance trade-off analysis, Proceedings of the 2001 IEEE/ACM international conference on Computer-aided design, November 04-08, 2001, San Jose, California
Kang , Mahmut Kandemir , Narayanan Vijaykrishnan , Mary Jane Irwin , Rajarathnam Chandramouli, Studying Energy Trade Offs in Offloading Computation/Compilation in Java-Enabled Mobile Devices, IEEE Transactions on Parallel and Distributed Systems, v.15 n.9, p.795-809, September 2004
Lee , Shidhartha Das , Valeria Bertacco , Todd Austin , David Blaauw , Trevor Mudge, Circuit-aware architectural simulation, Proceedings of the 41st annual conference on Design automation, June 07-11, 2004, San Diego, CA, USA
Weiping Liao , Lei He, Power modeling and reduction of VLIW processors, Compilers and operating systems for low power, Kluwer Academic Publishers, Norwell, MA,
Victor Zyuban, Unified architecture level energy-efficiency metric, Proceedings of the 12th ACM Great Lakes symposium on VLSI, April 18-19, 2002, New York, New York, USA
Luis Villa , Michael Zhang , Krste Asanovi, Dynamic zero compression for cache energy reduction, Proceedings of the 33rd annual ACM/IEEE international symposium on Microarchitecture, p.214-220, December 2000, Monterey, California, United States
V. Delaluz , M. Kandemir , N. Vijaykrishnan , M. J. Irwin , A. Sivasubramaniam , I. Kolcu, Compiler-Directed Array Interleaving for Reducing Energy in Multi-Bank Memories, Proceedings of the 2002 conference on Asia South Pacific design automation/VLSI Design, p.288, January 07-11, 2002
Gianluca Palermo , Cristina Silvano , Vittorio Zaccaria, Multi-objective design space exploration of embedded systems, Journal of Embedded Computing, v.1 n.3, p.305-316, August 2005
Ozgur Celebican , Tajana Simunic Rosing , Vincent J. Mooney, III, Energy estimation of peripheral devices in embedded systems, Proceedings of the 14th ACM Great Lakes symposium on VLSI, April 26-28, 2004, Boston, MA, USA
Trevor Mudge, Power: A First-Class Architectural Design Constraint, Computer, v.34 n.4, p.52-58, April 2001
K. Ananda Vardhan , Y. N. Srikant, Transition aware scheduling: increasing continuous idle-periods in resource units, Proceedings of the 2nd conference on Computing frontiers, May 04-06, 2005, Ischia, Italy
Yongxin Zhu , Weng-Fai Wong , tefan Andrei, An integrated performance and power model for superscalar processor designs, Proceedings of the 2005 conference on Asia South Pacific design automation, January 18-21, 2005, Shanghai, China
G. Chen , M. Kandemir , N. Vijaykrishnan , M. J. Irwin , W. Wolf, Energy savings through compression in embedded Java environments, Proceedings of the tenth international symposium on Hardware/software codesign, May 06-08, 2002, Estes Park, Colorado
Jung-Hi Min , Hojung Cha , Vason P. Srini, Dynamic power management of DRAM using accessed physical addresses, Microprocessors & Microsystems, v.31 n.1, p.15-24, February, 2007
Todd L. Cignetti , Kirill Komarov , Carla Schlatter Ellis, Energy estimation tools for the
Palm
G. Chen , Mahmut T. Kandemir , Narayanan Vijaykrishnan , Mary Jane Irwin , Mario Wolczko, Adaptive Garbage Collection for Battery-Operated Environments, Proceedings of the 2nd Java Virtual Machine Research and Technology Symposium, p.1-12, August 01-02, 2002
I. Kadayif , M. Kandemir , M. Karakoy, An energy saving strategy based on adaptive loop parallelization, Proceedings of the 39th conference on Design automation, June 10-14, 2002, New Orleans, Louisiana, USA
S. Kim , N. Vijaykrishnan , M. Kandemir , M. J. Irwin, Energy-efficient instruction cache using page-based placement, Proceedings of the 2001 international conference on Compilers, architecture, and synthesis for embedded systems, November 16-17, 2001, Atlanta, Georgia, USA
Mahmut Kandemir , N. Vijaykrishnan , Mary Jane Irwin, Compiler optimizations for low power systems, Power aware computing, Kluwer Academic Publishers, Norwell, MA, 2002
Giovanni Agosta , Gianluca Palermo , Cristina Silvano, Multi-objective co-exploration of source code transformations and design space architectures for low-power embedded systems, Proceedings of the 2004 ACM symposium on Applied computing, March 14-17, 2004, Nicosia, Cyprus
I. Kadayif , M. Kandemir , U. Sezer, An integer linear programming based approach for parallelizing applications in On-chip multiprocessors, Proceedings of the 39th conference on Design automation, June 10-14, 2002, New Orleans, Louisiana, USA
V. Delaluz , A. Sivasubramaniam , M. Kandemir , N. Vijaykrishnan , M. J. Irwin, Scheduler-based DRAM energy management, Proceedings of the 39th conference on Design automation, June 10-14, 2002, New Orleans, Louisiana, USA
Ramon Canal , Antonio Gonzlez , James E. Smith, Very low power pipelines using significance compression, Proceedings of the 33rd annual ACM/IEEE international symposium on Microarchitecture, p.181-190, December 2000, Monterey, California, United States
I. Kadayif , M. Kandemir, Tuning In-Sensor Data Filtering to Reduce Energy Consumption in Wireless Sensor Networks, Proceedings of the conference on Design, automation and test in Europe, p.20852, February 16-20, 2004
Russ Joseph , Margaret Martonosi, Run-time power estimation in high performance microprocessors, Proceedings of the 2001 international symposium on Low power electronics and design, p.135-140, August 2001, Huntington Beach, California, United States
O. Ozturk , G. Chen , M. Kandemir , M. Karakoy, Cache miss clustering for banked memory systems, Proceedings of the 2006 IEEE/ACM international conference on Computer-aided design, November 05-09, 2006, San Jose, California
Gilberto Contreras , Margaret Martonosi , Jinzhan Peng , Roy Ju , Guei-Yuan Lueh, XTREM: a power simulator for the Intel XScale core, ACM SIGPLAN Notices, v.39 n.7, July 2004
Mahmut Kandemir , J. Ramanujam , A. Choudhary, Exploiting shared scratch pad memory space in embedded multiprocessor systems, Proceedings of the 39th conference on Design automation, June 10-14, 2002, New Orleans, Louisiana, USA
Min Zhao , Bruce Childers , Mary Lou Soffa, Predicting the impact of optimizations for embedded systems, ACM SIGPLAN Notices, v.38 n.7, July
Mats Brorsson , Mikael Collin, Adaptive and flexible dictionary code compression for embedded applications, Proceedings of the 2006 international conference on Compilers, architecture and synthesis for embedded systems, October 22-25, 2006, Seoul, Korea
Peter Grun , Nikil Dutt , Alex Nicolau, APEX: access pattern based memory architecture exploration, Proceedings of the 14th international symposium on Systems synthesis, September 30-October 03, 2001, Montral, P.Q., Canada
John S. Seng , Eric S. Tune , Dean M. Tullsen, Reducing power with dynamic critical path information, Proceedings of the 34th annual ACM/IEEE international symposium on Microarchitecture, December 01-05, 2001, Austin, Texas
Huiyang Zhou , Mark C. Toburen , Eric Rotenberg , Thomas M. Conte, Adaptive mode control: A static-power-efficient cache design, ACM Transactions on Embedded Computing Systems (TECS), v.2 n.3, p.347-372, August
D. Brooks , P. Bose , V. Srinivasan , M. K. Gschwind , P. G. Emma , M. G. Rosenfield, New methodology for early-stage, microarchitecture-level power-performance analysis of microprocessors, IBM Journal of Research and Development, v.47 n.5-6, p.653-670, September
Viji Srinivasan , David Brooks , Michael Gschwind , Pradip Bose , Victor Zyuban , Philip N. Strenski , Philip G. Emma, Optimizing pipelines for power and performance, Proceedings of the 35th annual ACM/IEEE international symposium on Microarchitecture, November 18-22, 2002, Istanbul, Turkey
Gilberto Contreras , Margaret Martonosi , Jinzhang Peng , Guei-Yuan Lueh , Roy Ju, The XTREM power and performance simulator for the Intel XScale core: Design and experiences, ACM Transactions on Embedded Computing Systems (TECS), v.6 n.1, February 2007
Lode Nachtergaele , Vivek Tiwari , Nikil Dutt, System and architecture-level power reduction of microprocessor-based communication and multi-media applications, Proceedings of the 2000 IEEE/ACM international conference on Computer-aided design, November 05-09, 2000, San Jose, California
I. Kadayif , M. Kandemir , N. Vijaykrishnan , M. J. Irwin , J. Ramanujam, Morphable Cache Architectures: Potential Benefits, ACM SIGPLAN Notices, v.36 n.8, p.128-137, Aug. 2001
Yang , Wayne Wolf , N. Vijaykrishnan , D. N. Serpanos , Yuan Xie, Power Attack Resistant Cryptosystem Design: A Dynamic Voltage and Frequency Switching Approach, Proceedings of the conference on Design, Automation and Test in Europe, p.64-69, March 07-11, 2005
Gilles Pokam , Olivier Rochecouste , Andr Seznec , Franois Bodin, Speculative software management of datapath-width for energy optimization, ACM SIGPLAN Notices, v.39 n.7, July 2004
I. Kadayif , A. Sivasubramaniam , M. Kandemir , G. Kandiraju , G. Chen, Generating physical addresses directly for saving instruction TLB energy, Proceedings of the 35th annual ACM/IEEE international symposium on Microarchitecture, November 18-22, 2002, Istanbul, Turkey
G. Chen , R. Shetty , M. Kandemir , N. Vijaykrishnan , M. J. Irwin , M. Wolczko, Tuning garbage collection for reducing memory system energy in an embedded java environment, ACM Transactions on Embedded Computing Systems (TECS), v.1 n.1, p.27-55, November 2002
Eduardo Pinheiro , Ricardo Bianchini , Enrique V. Carrera , Taliver Heath, Dynamic cluster reconfiguration for power and performance, Compilers and operating systems for low power, Kluwer Academic Publishers, Norwell, MA,
Daniele Folegnani , Antonio Gonzlez, Energy-effective issue logic, ACM SIGARCH Computer Architecture News, v.29 n.2, p.230-239, May 2001
Michael Huang , Jose Renau , Seung-Moon Yoo , Josep Torrellas, A framework for dynamic energy efficiency and temperature management, Proceedings of the 33rd annual ACM/IEEE international symposium on Microarchitecture, p.202-213, December 2000, Monterey, California, United States
I. Kadayif , A. Sivasubramaniam , M. Kandemir , G. Kandiraju , G. Chen, Optimizing instruction TLB energy using software and hardware techniques, ACM Transactions on Design Automation of Electronic Systems (TODAES), v.10 n.2, p.229-257, April 2005
J. Adam Butts , Gurindar S. Sohi, A static power model for architects, Proceedings of the 33rd annual ACM/IEEE international symposium on Microarchitecture, p.191-201, December 2000, Monterey, California, United States
Peter Grun , Nikil Dutt , Alex Nicolau, Access pattern-based memory and connectivity architecture exploration, ACM Transactions on Embedded Computing Systems (TECS), v.2 n.1, p.33-73, February
Daniele Folegnani , Antonio Gonzlez, Energy-effective issue logic, ACM SIGARCH Computer Architecture News, v.29 n.2, p.230-239, May 2001
Kathleen Baynes , Chris Collins , Eric Fiterman , Brinda Ganesh , Paul Kohout , Christine Smit , Tiebing Zhang , Bruce Jacob, The performance and energy consumption of three embedded real-time operating systems, Proceedings of the 2001 international conference on Compilers, architecture, and synthesis for embedded systems, November 16-17, 2001, Atlanta, Georgia, USA
Jason Flinn , M. Satyanarayanan, Managing battery lifetime with energy-aware adaptation, ACM Transactions on Computer Systems (TOCS), v.22 n.2, p.137-179, May 2004
N. Vijaykrishnan , M. Kandemir , S. Kim , S. Tomar , A. Sivasubramaniam , M. J. Irwin, Energy behavior of java applications from the memory perspective, Proceedings of the JavaTM Virtual Machine Research and Technology Symposium on JavaTM Virtual Machine Research and Technology Symposium, p.23-23, April 23-24, 2001, Monterey, California
Soontae Kim , N. Vijaykrishnan , Mahmut Kandemir , Anand Sivasubramaniam , Mary Jane Irwin, Partitioned instruction cache architecture for energy efficiency, ACM Transactions on Embedded Computing Systems (TECS), v.2 n.2, p.163-185, May
H. Saputra , M. Kandemir , N. Vijaykrishnan , M. J. Irwin , J. S. Hu , C-H. Hsu , U. Kremer, Energy-conscious compilation based on voltage scaling, ACM SIGPLAN Notices, v.37 n.7, July 2002
Nikil Dutt , Alex Nicolau , Hiroyuki Tomiyama , Ashok Halambi, New directions in compiler technology for embedded systems (embedded tutorial), Proceedings of the 2001 conference on Asia South Pacific design automation, p.409-414, January 2001, Yokohama, Japan
Kathleen Baynes , Chris Collins , Eric Fiterman , Brinda Ganesh , Paul Kohout , Christine Smit , Tiebing Zhang , Bruce Jacob, The Performance and Energy Consumption of Embedded Real-Time Operating Systems, IEEE Transactions on Computers, v.52 n.11, p.1454-1469, November
Victor Delaluz , Mahmut Kandemir , N. Vijaykrishnan , Anand Sivasubramaniam , Mary Jane Irwin, Hardware and Software Techniques for Controlling DRAM Power Modes, IEEE Transactions on Computers, v.50 n.11, p.1154-1173, November 2001
Victor De La Luz , Ismail Kadayif , Mahmut Kandemir , Uger Sezer, Access Pattern Restructuring for Memory Energy, IEEE Transactions on Parallel and Distributed Systems, v.15 n.4, p.289-303, April 2004
A. Parikh , Soontae Kim , M. Kandemir , N. Vijaykrishnan , M. J. Irwin, Instruction Scheduling for Low Power, Journal of VLSI Signal Processing Systems, v.37 n.1, p.129-149, May 2004
Victor De La Luz , Mahmut Kandemir, Array Regrouping and Its Use in Compiling Data-Intensive Embedded Applications, IEEE Transactions on Computers, v.53 n.1, p.1-19, January 2004
Ismail Kadayif , Mahmut Kandemir , Guilin Chen , Ozcan Ozturk , Mustafa Karakoy , Ugur Sezer, Optimizing Array-Intensive Applications for On-Chip Multiprocessors, IEEE Transactions on Parallel and Distributed Systems, v.16 n.5, p.396-411, May 2005
Pin Zhou , Vivek Pandey , Jagadeesan Sundaresan , Anand Raghuraman , Yuanyuan Zhou , Sanjeev Kumar, Dynamic tracking of page miss ratio curve for memory management, ACM SIGOPS Operating Systems Review, v.38 n.5, December 2004
I. Kadayif , M. Kandemir , G. Chen , N. Vijaykrishnan , M. J. Irwin , A. Sivasubramaniam, Compiler-directed high-level energy estimation and optimization, ACM Transactions on Embedded Computing Systems (TECS), v.4 n.4, p.819-850, November 2005
Ning An , Sudhanva Gurumurthi , Anand Sivasubramaniam , Narayanan Vijaykrishnan , Mahmut Kandemir , Mary Jane Irwin, Energy-performance trade-offs for spatial access methods on memory-resident data, The VLDB Journal  The International Journal on Very Large Data Bases, v.11 n.3, p.179-197, November 2002
