--T
Animals with Anatomy.
--A
Applying anatomical and physiological principles to model and animate animals achieves greater realism. Underlying components represent bones, muscles, and soft tissue; for speed and simplicity, we can model these from ellipsoids. Muscles stretch across joints, and their orientations, sizes, and shapes change during joint motion. A polygonal skin is automatically generated from the underlying structures. The skin mesh adjusts itself to changes in position under the influence of neighboring skin points and connections to the underlying anatomy. Much of the process is automated but under the control of user-defined parameters. Manipulation and animation of these models occur at comfortable interactive speeds on graphics workstations.
--B
Introduction
Animals are beautiful, varied, and common, and we would like to see more, and more realistic, ones in
computer-generated images and animations. In general, computer graphics achieves greater realism by developing
methods that simulate the real world, rather than using adhoc methods that just appear somewhat
realistic. To this end, we are developing modeling and animation approaches based on anatomical and physiological
principles.
Our method models any animals that have a jointed endoskeleton ("inside" skeleton) moved by muscles
and covered by a flexible skin. This includes, basically, all the higher vertebrates, and some of the inverte-
brates. While we admit to a partiality toward other animals, our approach can be used to model humans
as well. There is actually a remarkable similarity in the structure of most vertebrates, so a well-designed
model of one animal can be used as a basis for various individuals of the same species, or even very different
species. We can also design entirely new and fantastic animals.
Creating a truly realistic model of any animal is a daunting task. This research provides a fundamental
paradigm that can be extended gradually to include whatever level of physical realism is desirable. At present,
all underlying parts (bones, muscles, and soft tissue) are represented as ellipsoids, which are actually quite
a natural shape for many body parts and allow us to interact with our models at comfortable interactive
speeds. The polygonal skin is automatically created based on underlying components and moves with them
when joints move.
We feel our contributions so far are: (1) partially automated or interactive creation of underlying parts
from the basic structure; (2) sharable model descriptions for expediting creation of different individuals and
species; (3) an underlying structure of individual bones and individual muscles that extend across joints and
reshape as joints move; and (4) an automatically extracted skin that moves naturally during motion.
This paper presents an overview of our new method. Color images and animations illustrating the method
can be viewed on the Internet at http://www.cse.ucsc.edu/~wilhelms/fauna.html.
Background
Many research areas have contributed results useful for modeling and animating animals, and only a small
subset can be referenced here. Much of the work has concentrated on modeling humans, especially their
faces [BPW93, LTW93, TW90]. Some of the best animals have been created for commercial advertising and
movies, and details of the methods used are not published. Two excellent recent examples are the polar
bears of Rhythm and Hues [Car94] and the dinosaurs of Jurassic Park [SD93]. Both were initially digitized
from real physical models.
2.1 Model Construction
Chadwick, Haumann, and Parent presented a method for layered construction of flexible animated characters
[CHP89]. A polygonal skin model was associated either with a freeform deformation abstractly representing
muscle and fatty tissue or with the skeletal hierarchy itself. The deformation was affected by kinematics
based on joint angles, dynamics based on mass-spring model of control points, or interactive sculpting by
the user. Unlike our own model, they did not simulate individual muscles that cross joints, and the skin was
embedded in the deformations, not flexibly attached to underlying structures.
Mark Henne also used a layered approach [Hen90]. A bicubic surface skin was pushed outward by
localized "velocity" fields. These implicit fields represented bones, fat, and muscles, and were connected to
a hierarchical body structure. Each skin control point was affected by neighboring skin points and by an
anchor which was the point's original position in the rest state. Anchor points were displaced when joint
angles changed. Simulated muscles were only attached to a single segment in the hierarchy, and individual
muscles were not modeled.
Creating natural-looking skin and deformations across joints is a particularly difficult problem and this
is where many animal models fail [BZ91]. Gourret, Magnenat-Thalmann, and Thalmann used finite-element
theory to model the hand during grasping [GMTT89]. Their method simulated shape changes during motion,
including effects of contact between flesh and objects, using solid elements such as cubes, prisms, and
tetrahedra and a spring-like model. Magnenat-Thalmann and Thalmann also presented an approach using
joint-local deformations (JLD's) to create realistic body deformations at joints [MTT91]. JLD's are geometric
operators which cause deformations based on the angular values of the joint, and parameters such as flexion
axis of the joint and amount of inflation that should occur during motion. Here the main interest was visual
realism and speed; no attempt is made to accurately model the internal hand anatomy.
Chen and Zeltzer presented a biomechanically based muscle model using a finite element method to
realistically simulate a few individual muscles [CZ92]. The muscles were modeled using polyhedral meshes,
and a biomechanical contaction model used to calculate non-linear forces at mesh points. The simulated
muscles showed good correspondence to actual measured muscle behavior. This research concentrated on
accurately simulating individual muscle behavior. Overlying skin was not modeled. The cost of the simulation
was not discussed, but may be prohibitive for purposes of whole body muscle simulation. At some point,
hopefully, computational resources will make it possible for animation and biomechanical simulation to
converge.
2.2 Implicit Surfaces and Isosurfaces
An implicit surface and an isosurface are really equivalent, each being a two-dimensional surface of
constant value within a three-dimensional scalar field, i.e., the set of points x where F Those
in computer graphical modeling tend to use the term "implicit surface" and the three-dimensional field is
usually a simulated density field around geometric objects. Those in scientific visualization tend to use the
term "isosurface" and the field is usually provided as discrete scalar values on a grid; data values represent
samples from an underlying field function that is usually not given. The isosurface for a given threshold
value in the field can be extracted by a wide variety of approaches [NH93]. Blinn wrote a seminal paper on
implicit surface modeling which created a "blobby man" by extracting a surface from around an articulated
skeleton, but underlying anatomy wasn't modeled [Bli82].
Our method uses a "marching-cubes" approach [LC87], which is simple, fast, and sufficient for present
purposes. A cell of the grid is defined by eight corner points. An isosurface crosses the cell if some of the
data values at these corners are above the threshold and others are below. Linear interpolation along cell
edges provides points on the isosurface. These are connected together using a table to produce a polygonal
mesh surface.
Modeling Approach
An animal, for the purposes of this model, is a structure of individual bones, muscles, and generic other
tissue ("stuffing") covered by a flexible skin. Our sample model will be the zuni cat, which has 27 segments,
bones, 128 muscles, and 13 stuffings. The skin mesh has 5518 vertices. Figure 5 shows the bones of
the cat. Figure 7 shows the underlying components on the left and the polygonal skin mesh with texture
mapping on the right.
3.1 The Model Hierarchy and Geometry
Our animal models are represented, as is common, by a hierarchy or tree. The root segment is attached
via a six degree-of-freedom joint to the world, and other joints allow three rotational degrees of freedom. A
body segment is a part of the body with a rigid underlying skeleton (such as the upper arm, the lower leg,
the head, etc.) that is attached to other segments via joints. Each segment (except the root segment which
is free to move in the world) has one parent segment and zero or more child segments. A well-designed
hierarchy can represent most of the vertebrates with few changes, because most vertebrates have a similar
number of arms, legs, fingers, toes, etc. and differ in minor points like the number of vertebrae.
The segments, bones, muscles, stuffing, and the animal as a whole are each described in terms of local
coordinate systems. The geometric relation between these coordinate frames is known and used for adjusting
body parts during motion and drawing the model. Of course, all body parts must be converted to the world
coordinate system for drawing. As a convention, when body parts have a distinct longitudinal axis, this is
the Z-axis in the local system. Figure 1 shows a hierarchy and underlying components for a simple structure.
Each body segment is described in a local segment coordinate system. The origin of this coordinate
system is the proximal joint of the segment, connecting it to its parent segment. The coordinate system
of the root body segment is also the whole animal coordinate system. The skin is described in the animal
coordinate system, but, because it maintains connections to other body parts as well, it is also described in
local coordinate systems (see Section 3.5).
Bones, muscles, and stuffing each have their own local bone, muscle, or stuffing coordinate systems. These
components are all modeled as ellipsoids, and each ellipsoid has its own local ellipsoid coordinate system. A
geometrical transformation places ellipsoids in the body, muscle, or stuffing coordinate system of which they
are a part. Other geometrical transformations place bones, muscles, and stuffing in the segment coordinate
frame to which they are attached.
The relationship between body segments is stored both in a rest geometry and a state geometry. The
rest geometry specifies the rest origin and orientation of each segment's coordinate frame on its parent
segment. The state geometry represents rotations of segments relative to their parents and the position and
orientation of the whole animal in the world. These changes are represented by the state geometry. Bones
and stuffing just move with their segments during state changes. Muscles and skin, however, have more
complex responses (Sections 3.4 and 3.5).
3.2 Ellipsoids
The basic primitive is the ellipsoid, specified by the equation:
a 2
The (x; lengths of the ellipsoid are (a; b; c). Ellipsoids can be succinctly stored, and solving the
equation for a particular 3D point (x; indicates if the point is in (f(x;
or outside (f(x;
Ellipsoids used in modeling are centered at the origin of their own local coordinate frame. Matrices
representing the relationship between the local ellipsoid coordinate frame and the world coordinate frame
are stored with each ellipsoid for rapid display and for adjustment of skin points (see Section 3.5). Muscle
ellipsoids may change shape, so their volume (v) and the ratio (r) of their X and Y axis lengths are also
stored (see Section 3.4). (The (x; lengths of the ellipsoid are (a; b; c).) The longitudinal ((Z) axis
length of the muscle ellipsoids change during joint motion because the relative positions of the muscle end
points change. Because the muscle volume should remain relatively constant, the X and Z axis lengths
needed to be scaled accordingly, maintaining the ratio of X=Y from the rest position.
4-abc
3 (2)
3.3 Bones and Stuffing
A typical bone is modeled as a thin center ellipsoid with two bulbous spheres at each end, but the three
ellipsoids can be rescaled and moved relative to each other for other shapes (see Figure 5). Notice, for
example, the three ellipsoids that form a rib and the three flat ellipsoids that form the scapula (the shoulder
blade). Default bones lie along the longitudinal axes of segments.
"Stuffing" refers to ellipsoids used to simulate general soft tissue important for shaping the body, such
as in the abdomen and thorax, and is also used to add features such as ears, nose and eyes. Stuffing consists
of a single ellipsoid, and appears purple in the color images (see Figure 7). We avoid the term "soft tissue"
because it doesn't deform.
3.4 Muscles
The animal body is covered by model muscles that are simplified versions of the muscles found in a real
animal. Muscles are anchored to body parts at an origin (the proximal attachment, closest to the center
of the body) and an insertion (the distal attachment, farther from the body center). Origin and insertion
remain at fixed positions in their local segment frames, and muscles reshape themselves to lie between these
attachments when joints move. The muscle coordinate frame has its origin at the origin point of the muscle,
and its Z-axis extends toward the insertion point of the muscle. Three ellipsoids representing two tendons
and a muscle body between are lined up along this Z-axis (Figure 2.)
The muscles are created by the user interactively. The process is simplified by the use of standard defaults.
When the user requests a new muscle, she specified only the segments with which the origin point and the
insertion point are associated. The origin and insertion points are assumed to lie along the longitudinal axis
of the segment, 10% along the distance of the bounding box of the segment in this direction. The tendons
and muscle body are created to just span the distance between origin and insertion. This distance represents
the rest length of the muscle.
muscles for the whole body can also be requested, and, in that case, four muscles are created
around each joint. These muscles are similar to a muscle requested singly, but in this case the four muscles
are arranged symmetrically around the segments that they attach to by placing their origin and insertion
points slightly away from the longitudinal axes of the proximal and distal segments in the +X, \GammaX , +Y ,
and \GammaY directions. This simulates abductor, adductor, flexor, and extensor muscles.
The user can interactively move the origin and insertion, change the insertion segment, and reshape the
muscle as desired. Muscle creation and modification are done in the rest state, and define the relaxed, muscle
rest state.
The system also stores the muscle present state, which takes in account the present state geometry. The
origin and insertion points of the muscle in their local segment frames remain constant, but the relation of
these frames may have changed. The present state modifies the muscle so that it lines up between origin
and insertion points in their new positions, and reshapes the muscle ellipsoids so that volume and the X=Y
axis ratios are maintained.
First, the muscle origin and insertion points are transformed into the origin segment coordinate frame
and a vector between them is found. The length of this vector is the new muscle length (l new ), which may
be longer or shorter than the rest length (l rest ). The Z-axis rest lengths (c) of the ellipsoids making up the
muscle must be scaled to fit this new length, and their other (a; b) rest axes lengths adjusted to maintain a
constant ratio
volume (v). These changes are figuratively represented in Figure 2. They are
accomplished as follows:
new
l rest
c (4)
r 3v
4c new r-
new r (6)
This rescaling is applied independently to each of the three muscle ellipsoids. If the new length is shorter
than the rest length, this causes the muscle to bulge; and if larger, to become thinner.
Next, a transformation defining the relation of the new longitudinal muscle axis to the origin segment
coordinate frame must found. This can be done using techniques described in standard graphics texts for
rotating a given vector into another arbitrary vector. First, find a local coordinate system for which the
muscle axis vector is the Z-axis by taking a cross-product of the axis vector with a non-parallel vector, and
take the cross-product of the axis vector with the new vector. Then, normalize axes and use them as rows
in a rotation matrix.
Finally, muscle ellipsoids are placed along this longitudinal axis at appropriate distances from the muscle
origin point to line up the tendons with the muscle body between them.
These adjustments are quite fast and muscles can be animated and shown changing shape in close to
realtime. Figure 4 show a structure created almost totally automatically (stuffing was added interactively)
from default parameters, showing the muscles (red), tendons and bones (white), stuffing (purple), and a skin
mesh covering them.
User-defined parameters control the automatic generation and movement of the skin. A polygon mesh
rest skin is generated (Section 3.6), and each skin vertex is associated with its nearest anchor ellipsoid
(Section 3.7). During motion, the positions of skin vertices are adjusted under the influence of neighboring
skin vertices and their attachment to the anchor ellipsoid (Section 3.8). Various skin characteristics can be
changed under user control (Section 3.9).
3.6 Skin Generation
The rest skin is generated in three steps: (1) sample the region around the body in its rest position to create
a scalar 3D data volume (voxelization); (2) filter the volume; and (3) extract a polygonal isosurface of a
designated threshold from it. Notice that the skin need only be generated once, in the body rest position.
The polygon vertices extracted are attached to underlying components and are automatically repositioned
when the body moves.
First, a volume of data points on a rectilinear grid of a user-specified resolution is created over the animal
model in its rest configuration. Each grid point is tested to see if it lies within any ellipsoid by converting it
to the coordinate frame of the ellipsoid and testing its location with the ellipsoid equation (Equation 1). If
the grid point is in any ellipsoid, it is given a positive scalar value; otherwise, it is given a value of zero.
To produce a smooth skin at a reasonable distance from the underlying parts, this volume is then filtered
some number of times (five is often good). A Gaussian filter with a default decay of 2 (which can be changed
by the user) is used.
We calculate the filter using the equation below. The one center point ((i; j; k)) is scaled by w 3
, the six
1-adjacent points (e.g., (i , the twelve 2-adjacent points by w 1 (e.g., (i and the
eight 3-adjacent points (e.g., (i
. (In other words, n-adjacent means one away from
the center point in each of n coordinate dimensions.)
(decay
The filtered value finally used is the maximum of the filtered value from the algorithm and the original
grid value. This ensures that internal grid points never lose value and positive values spread outward from
the original points included in the model.
In the third step, an isosurface of a user-defined threshold is extracted from the filtered volume to produce
a polygonal skin model [LC87]. This is represented as a list of vertices representing points on the skin surface
together with outward-pointing normal vectors at those points; a list of polygons each specified as a list of
pointers into the vertex list; and a list of edges describing connectivity between vertices. The edges act like
springs and adjust the positions of vertices when the body moves. The edge length when extracted is the
rest length for these "springs."
Our approach is quite a bit simpler than some other voxelization and filtering approaches described in
the literature (e.g., [WK94]). However, unlike most voxelization approaches, we are not interested in an
exact representation of the objects sampled (the component ellipsoids in this case), but rather a sense of
where they are. The ellipsoids are not a perfect representation of a real body with the skin removed, but
only an approximation. The filtering step is essential to "blur" this approximation, making it possible to
create a smooth isosurface at some distance from the underlying components. The user has control over the
amount of filtering, and the process is fast enough to allow interactive experimentation.
3.7 Anchoring
Once the default skin has been found, it must be anchored to appropriate body parts, so that when the
body moves, the skin automatically moves as well. Each skin vertex is anchored to the ellipsoid to which it
is closed, at the near point on that ellipsoid. To find this anchor, skin points which are originally in world
space are converted to the frame of the ellipsoids with to which they might be anchored, and the closest
point on any of them found. Figure 3 shows important components in anchoring and moving skin.
The solution of the ellipsoid equation for a given point unfortunately doesn't give the distance to the
nearest point on the ellipsoid, so we use an iterative Newton-Raphson approach. The derivative of the
ellipsoid equation at the nearest point on the ellipsoid to the skin point represents a vector between the skin
point and its nearest point. We find a parametric line equation representing that vector such that when the
parameter we are at the skin point, and taking small steps along the line dt brings us toward the
near point. The ellipsoid equation is also parameterized by t; we refer to it as g(t). Let be the
skin point in the ellipsoid coordinate frame and (a; b; c) be the ellipsoid axis lengths. The parameter t is
initialized to zero and dt is initialized to a small fraction of the value of f(0). The following iteration occurs
until the absolute value of dt is acceptably small or ten iterations have occurred.
s
s
s
s
s
s
The final point (x; is the nearest point on the ellipsoid to the skin point and is called the anchor
point. The distance to the ellipsoid is found from these two points. The ellipsoid nearest the skin point
becomes the anchor ellipsoid for that point. The position of the skin point itself in its initial rest state is
the virtual anchor.
The virtual anchor and the skin point are stored both as world space positions and as parameterized
positions in the local ellipsoid frame. A parameterized local position is found by dividing the actual local
position by the ellipsoid axis lengths to yield values between \Gamma1 and 1. As the axis lengths for muscles may
change due to joint changes, points that are rescaled back to the local space correctly take into account these
changes.
3.8 Skin Adjustment During Motion
Much of an animal's skin is rather loosely attached to underlying parts. Rigid attachment of the skin to body
segments, particularly near joints, is a major reason why many animal models do not appear realistic. Our
modeled skin moves under the influence of neighbor skin regions and variably stiff attachments to underlying
parts. Often these parts are muscles, which themselves move relative to the skeleton when the body moves.
After a joint movement has occurred, the initial positions of each skin point in world space are found by
transforming the last position of the skin point in its ellipsoid local coordinate frame to world space using
the new relationship of local space to world space. This produces a good approximation of a stable position
for the point.
Next, each skin point is iteratively adjusted in world space taking into account the influence of neighboring
skin points which are connected to it by edges and its virtual anchor. The number of iterations can be set
by the user, and it is possible to iterate continuously in the background when not actively interacting with
the program. In practice, however, movement of skin points due to iteration is not visible, even for large
motions, after about five iterations, and for small motions, after two or three.
We use the virtual anchor (the rest position of a skin point) rather than the anchor on the ellipsoid because
it gives better visual results. Henne also used the rest position as the anchor [Hen90]. If the ellipsoid anchor
is used, the point can rotate around the anchor and find a stable position very close to or even inside the
ellipsoid. While collision detection can take care of this, it is expensive.
The change in position for each skin point is the sum of changes in position caused by each of the edges
to which it is attached. Let P s be the 3D position in world space of the skin point being adjusted and Pn
be the position in world space of the neighbor point connected to it by an edge. Let l r be the rest length
for that particular edge; and let l p be the present length of that edge. Let k be the "spring constant" for
the edge, which controls how strongly it is drawn back to its rest position. Then, the change in position due
to this edge is dp. In the very unusual case where l when the edge is between skin points (two points
coincide), the displacement is set to be a small amount in a set direction.
l p
The new position for the point P merely the old position nudged by the displacements caused
by its i edges, each of which has displacement dp i . This worldspace position is also converted back to a
parameterized local position for future use.
Collisions between skin points and ellipsoids can be checked for, and points displaced to avoid them
when they occur, but they slow the skin adjustment. Because virtual anchors tend to keep points from
colliding with their own ellipsoids, and the underlying tissues are not normally displayed under an opaque
skin, small interpenetrations have little visual effect. We don't do ellipsoid-ellipsoid collision detection or
collision detection with external objects at this time.
3.9 Skin Modification
The skin automatically generated as explained above may not be quite what is desired. For example, one
might like it to be at a greater distance from and more loosely attached to the abdomen, but close and
tightly attached to the skull. Therefore, the user can interactively adjust various parameters to get the
proper regional skin properties. Adjustment may occur to skin over the entire body, over an active segment,
or to an interactively chosen set of skin points. Two of the most useful adjustment parameters are the rest
distances of skin points from their anchor ellipsoids and the "spring constant" (k) controlling the strength of
the pull between skin points or between skin points and their virtual anchors. The actual resting positions of
skin points can be interactively adjusted, but in most cases it is more effective and easier to alter relationships
between skin and underlying structure than to tweak points.
In the figures, we demonstrate our method using a few "animals." A simple two-armed structure illustrates
what can be done using default parameters and automatic component generation (Figure 4). The "zuni cat"
is closer to a model that might be used for real animation (Figures 5-9). The toad was created from cat
description files in about an hour (Figure 11). being developed.) The final model shows a
human hand (Figure 12).
The models are defined by several ascii files describing the hierarchy structure, rest geometry, state
geometry, bones, muscles, stuffing, and skin parameters, as well as a binary file for the skin polygon mesh.
This makes it possible to share descriptions easily. For example, the main difference between the toad and
the cat is the rest geometry, the shape of the head, and the lack of the tail segments.
Images and animations were done on an SGI Reality Engine with a 150 MHz processor. Calculating new
skin positions is "interactive" in that it is fast enough to give a feel for the motion, but not really realtime.
A facility exists to save skin positions for realtime playback.
The zuni cat is our most interesting model so far (Figures 5-9). It consists of 27 segments, 39 bones,
123 muscles, and 13 stuffings. The sample volume was of resolution 83x83x83 and it produced a skin mesh
of 5518 vertices and 6787 polygons using five filter iterations. The skin mesh was used as automatically
generated, except that two points at the tips of the ears were displaced upwards to produce pointed ears,
and the points around the head were drawn closer to the skull ellipsoid by reducing their anchor lengths.
Also, points on the trunk of the body and upper limbs were given very loose anchor connections (small values
of k to virtual anchors) to simulate the extremely baggy nature of cat skin in those regions.
Generation of the volume, filtering, and skin extraction took about a minute of elapsed time for the cat.
Adjustment and animation of the skin can be done at 3.3 frames per second using 1 adjustment iteration,
frames per second using 5 adjustment iterations, or about 0.75 frames per second using 1 adjustment
iteration with collision detection and response. However, visual differences between images using these
different parameter settings are subtle.
The figures show the cat and its underlying components in various positions. Figure 6, in particular,
shows the bent left leg of the cat. At left are shown bones, muscles, stuffing and skin mesh, with blue vectors
showing connections from skin points to anchor points on ellipsoids, and red vectors showing displacements
of skin points from virtual anchor points. At right is shown the texture-mapped polygonal skin in this
position.
5 Discussion and Future Work
As a first pass on this new modeling approach, we feel the results were very satisfactory. The simplicity
of our model and the rather ad hoc nature of the muscles is the main problem at this point. We need a
more flexible animal model that includes most of the bones and joints of the typical vertebrate. A human
has 206 bones, though many are fused or have little motion (such as the skull, wrist, and foot). Our next
model will include most or all the vertebrae, including all the tail vertebrae of the cat. We also need more
realistic muscles. The origins and insertions of actual muscles are well documented, so the process of muscle
creation should be automated from this information. Though a more complex model would slow down the
program some, work on our present models suggests having two or three times more components would still
be interactively pleasant to work with. Adjustment of the skin is the major bottleneck, not that of the
underlying anatomy.
We would also like to use more complex primitives than ellipsoids. For bones, and possibly muscles and
stuffing, meshes can be extracted using isosurface programs from CT scan data or created using modeling
programs. Because of the remarkable similarity between many animals, we believe the work invested in
creating good polygonal models will allow us to convert these descriptions between different individuals and
species fairly easily.
Other methods of skin extraction should be pursued; for example, shrink wrapping a surface onto the
underlying components, or creating an isosurface at a given distance from underlying component using
tracking. The present method works satisfactorily for animals with relatively loose skin, such as the cat, but
less well where the skin is more tightly attached to the body, as in humans. The latter would more easily
accommodate different levels of detail. Decimation methods to reduce the number of skin points in large flat
regions would also expedite adjustment.
At present, the model is kinematic, and joint position changes cause the muscle changes, while, in reality,
it is muscle changes that move joints. It would be interesting to explore a physical simulation model based on
muscle contraction using this model. muscle models could store information concerning comfortable lengths
and amount of force that they can apply. This could be used to implement joint limits and to help determine
natural and acceptable movements.
Our texture mapping program for coloring skin is quite rudimentary. We will explore methods to better
control mapping and to generate more realistic texture maps, including 3D textures for fur and hair.
Overall, we think this research provides a new and successful basic paradigm for animal modeling using
an approximation to real animal anatomy. We believe this work can be gradually extended in a number of
directions, such as those mentioned above, to create animal models of great realism.

Acknowledgments

List processing software by Yumi Tsuji and Allen Van Gelder was used in this software package. Allen Van
Gelder contributed many helpful suggestions concerning filtering, skin motion, and texture-mapping. Mark
Henne of Lucasfilm and Pauline Tso of Rhythm & Hues provided helpful pointers to related literature. Brad
Smith went beyond the call of duty to keep the machine running. aexture maps were taken from modeling
software provided as a donation from Alias Incorporated. This research was supported in part by an NSF
grant CCR-8958590.



--R

A generalization of algebraic surface drawing.
Simulating humans
Making Them Move.
Commercial spot cola bears.
Layered construction for deformable animated characters.
Pump it up: Computer animation based model of muscle using the finite element method.
Simulation of object and human skin deformations in a grasping task.
A constraint-based skin model for human figure animation
Marching cubes: A high resolution 3D surface construction algorithm.
Constructing physics-based facial models of individuals
Human body deformations using joint- dependent local operators and finite element theory
Vector quantization for Volume
The Making of Jurassic Park.


--TR

--CTR
Caroline Larboulette , Marie-Paule Cani , Bruno Arnaldi, Dynamic skinning: adding real-time dynamic effects to an existing character animation, Proceedings of the 21st spring conference on Computer graphics, May 12-14, 2005, Budmerice, Slovakia
Y. M. Tang , K. C. Hui, The effect of tendons on foot skin deformation, Computer-Aided Design, v.39 n.7, p.583-597, July, 2007
J. Peter C. Markush , Gary J. Grimes , Jonathan R. Merril, Investigations toward Using VRML for Distributed Medical Collaboration, Presence: Teleoperators and Virtual Environments, v.9 n.4, p.383-393, August 2000
Jane Wilhelms , Allen Van Gelder, Anatomically based modeling, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, p.173-180, August 1997
Michael Pratscher , Patrick Coleman , Joe Laszlo , Karan Singh, Outside-in anatomy based character rigging, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, July 29-31, 2005, Los Angeles, California
