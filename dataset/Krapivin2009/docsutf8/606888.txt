--T
On an Augmented Lagrangian SQP Method for a Class of Optimal Control Problems in Banach Spaces.
--A
An augmented Lagrangian SQP method is discussed for a class of nonlinear optimal control problems in Banach spaces with constraints on the control. The convergence of the method is investigated by its equivalence with the generalized Newton method for the optimality system of the augmented optimal control problem. The method is shown to be quadratically convergent, if the optimality system of the standard non-augmented SQP method is strongly regular in the sense of Robinson. This result is applied to a test problem for the heat equation with Stefan-Boltzmann boundary condition. The numerical tests confirm the theoretical results.
--B
Introduction
We consider an Augmented Lagrangian SQP method (ALSQP method) for the following
class of optimal control problems, which includes some meaningful applications to control
problems for semilinear partial dierential equations:
Minimize
subject to y
In this setting Y and U are real Banach spaces, are
dierentiable mappings, and U ad is a nonempty, closed, convex and bounded subset of U .
The operator  is a continuous linear operator from Y to U . In general, (P) is a non-convex
problem. We will refer to u as the control, and to y as the state.
In the past years, the application of ALSQP methods to optimal control or identication
problems for partial dierential equations has made considerable progress. The list of
contributions to this eld has already become rather extensive so that we shall mention
only the papers by Bergounioux and Kunish [6], Ito and Kunisch [13], [14], Kaumann
[15], Kunisch and Volkwein [16], and Volkwein [25], [26].
Supported by SFB 393 "Numerical Simulation on Massive Parallel Computers".
2 Parts of this work were done when the third author was visiting professor at the Universite Paul
Sabatier in Toulouse.
In this paper, we extend the analysis of the ALSQP method to a Banach space setting.
This generalization is needed, if, for instance, the nonlinearities of the problem cannot be
well dened in Hilbert spaces. In our application, this will concern the nonlinear mapping
. A natural consequence of this extension is that, in contrast to the literature about the
ALSQP method, we have to deal with the well known two-norm discrepancy. Another
novelty in our approach is the presence of the control constraints u 2 U ad in (P) , which
complicates the discussion of the method. To resolve the associated diculties, we rely
on known results on the convergence of the generalized Newton method for generalized
equations.
One of the main goals of this paper is to reduce the convergence analysis to one main
assumption, which has to be checked for the particular applications { the strong regularity
of the optimality system. In this way, we hope to have shown a general way to perform
the convergence analysis of the ALSQP method.
For (P) we concentrate on a particular type of augmentation, applied only to the
nonlinearity of the state equation. Splitting up the state equation into y
and z augment only the second equation. This type of augmentation
is useful for our application to parabolic boundary control problems. The convergence
analysis is conrmed by numerical tests, which are compared with those performed for the
(non-augmented) SQP method.
We obtain the following main results: If the optimality system of rst order necessary
optimality conditions for (P) is strongly regular in the sense of Robinson, then the ALSQP
method will be locally quadratic convergent under natural assumptions. This result is
applied to a boundary control problem for a semilinear parabolic equation. In [23], the
convergence of the (non-augmented) SQP method was shown for this particular problem
by verifying this strong regularity assumption. In this way, our result is immediately
applicable to obtain the convergence of the augmented method in our application.
The paper is organized as follows: In Section 2 we x the general assumptions and
formulate rst order necessary and second order sucient optimality conditions. Section
3 contains our example, a semilinear parabolic control problem. The ALSQP method is
presented in Section 4, where we show that its iterates are well dened in the associated
Banach spaces. The convergence analysis is developed in Section 5 on the basis of the
Newton method for generalized equations. The last part of our paper reports on our
numerical tests with the ALSQP method.
General assumptions and optimality conditions
We rst x the assumptions on the spaces and mappings. The Banach spaces Y and U
mentioned in the introduction stand for the ones where the following holds:
f is a mapping of class C 2 from Y  U into R,
is a mapping of class C 2 from Y into U .
For several reasons, among them, the formulation of the SQP method and the sucient
second order optimality conditions, we have to introduce real Hilbert spaces Y 2 and U 2
such that Y (respectively U) is continuously and densely imbedded in Y 2 (respectively U 2 ).
Moreover, we identify U 2 with its dual U
. Therefore, denoting by U  the dual space of U ,
we have the continuous imbeddings
Let us introduce the product space endowed with the norm jjvjj
jjujj U , and the space endowed with the norm jjvjj
Notations: We shall denote the rst and second order derivatives of f and  by
Partial derivatives are indicated by associated
subscripts such as f y (v), f yu (v), etc. Notice that, by their very denition, f 0 (v) 2 V  ,
U)). The open ball in V centered
at v, with radius r is denoted by B V (v; r). The same notation is used in other
Banach spaces. We will denote the duality pairing between U  and U (resp. Y  and Y )
by reserved in this paper for the scalar product
of U 2 .
Below we list our main assumptions:
(A1)  is a linear, continuous, and bijective operator from Y 2 to U 2 . Moreover, its
restriction to Y , still denoted by , is continuous and bijective from Y to U . In
addition, we assume that U ad is closed in U 2 .
(Extension properties) For all r > 0 there is a constant c(r) > 0 such that, for
all
for all v 2 V; (2.1)
for all From (2.1) it follows that f 0 (v) can be considered as a continuous
linear operator from V 2 to R, and  0 (y) can be considered as a continuous linear
operator from Y 2 to U 2 .
Since  00 (y belongs to U , and U  U  , the term k 00 (y
ful. Moreover, f 00 (v) (respectively  00 (y)) can be considered as a continuous bilinear
operator from V 2  (respectively U  ). In the second
order derivatives we shall write [v;
there is a c(r) > 0 such
that
for all z 2:
(Remainder terms) Let r F
denote the i-th order remainder term for the
Taylor expansion of a mapping F at the point x in the direction h. Following Ioe
[11] and Maurer [18] we assume
kr
For all y 2 Y , the operator is bijective from Y 2 to U 2 . Its restriction to
Y , still denoted by  is bijective from Y to U .
For all belongs to b
Y , where b
Y is a Banach space continuously imbedded
in Y  . For all belongs to U .
The restriction of (
Y is continuous from b
Y to U .
The rst assumption concerns the linearized state equation. The second and third
assumptions are needed to get optimal regularity for the adjoint equation. Indeed, the
adjoint state corresponding to
dened by
To study the convergence of the SQP method we need that
p belongs to U . Since by
denition f u (v) belongs to U  , the condition f u (v) 2 U is a regularity condition on
f u (v).
In the analysis of the Generalized Newton Method, we need the following additional regularity
conditions.
(A6) For every y 2 Y ,  0 (y)  belongs to L(U; ^
Y ). The mapping y 7!  0 (y)  is locally of
class C 1;1 from Y into L(U; b
Y ). For every y belongs to L(U; b
The mapping (y is locally of class C 1;1 from Y Y into L(U; b
(A7) The mapping v 7! f 0 (v) is locally of class C 1;1 from V into ^
Y U .
3 Example - Control of a semilinear parabolic equa-
tion
Let us consider the following particular case of (P) :
Z
a u u
Z
a y y
subject to
in
Here,
n is a bounded domain with boundary of class C 2 , T > 0;  > 0, y T 2
2 and u a < u b are
given xed. The function ' : R ! R is nondecreasing, and locally of class C 2;1 . (The choice
ts into this setting.)
Let us verify that problem (E) satises all our assumptions. This problem is related to (P)
as follows:
fy
fy
where W (0; T ) is the Hilbert space dened by
dt
The space Y (respectively Y 2 ) is endowed with the norm kyk
us check the assumptions.
The operator  is obviously continuous from Y 2 to U 2 , and is bijective from Y 2 to U 2
(see [17]). It is also a bijection from Y to U . (see [8], [20].) Thus (A1) is satised.
continuous imbedding ([8], [20]), we can verify that  is a mapping
of class C 2 from Y into U , and that f is a mapping of class C 2 from Y  U into R.
Moreover, for all v
f y (y
Z
(y
Z
a y (x; t)y(x; t) dSdt
f u (y
Z
Thus, the derivative f y (v can be identied with the triplet (0; y
()). The assumptions (2.1) and (2.3) can be easily satised.
To verify assumption (A5), let us introduce the space b
This space can be identied with the subspace of Y  of all elements having the form
y 7!
Z
Z
y
Z
where (^y
y
Y . >From the above calculations, it is clear that f y (v
belongs to b
Y . Let y (d;a;u) be the solution to the equation
The operator (d; a; u) 7! y (d;a;u) is continuous and bijective from U 2 into Y 2 ([17]), and from
U into Y ([8], [20]). The rst part of (A5) is satised. To prove the second part, let us
consider the adjoint equation
y
For all (d; a; u) 2 U , and all ^
y
Y , by using a Green formula, we obtain
Z
Z
Z
Z
Z
y
Z
Therefore nothing else than (; (0); j  ). With this identity, we
can easily verify the second part of assumption (A5).
Let us nally discuss properties of some second order derivatives. The second derivative
For
We can interprete  00 (y as an element of L 1 ()  L 1 ()  , and (2.2) can be checked.
The other assumptions on the second order derivatives, precisely (2.4) and (A4), are also
4 Optimality conditions
This section is devoted to the discussion of the rst and second order optimality conditions.
Let
u) be a local solution of (P) . This means that
holds for all v, which belong to a suciently small ball B V (v; ") and satisfy all constraints
of (P) .
Theorem 1 Let
u) be a local solution of (P ) and suppose that the assumptions
(A1), (A2), and (A5) are satised. Then there exists a unique Lagrange multiplier
such that
hf u (y;
Proof. Since f is Frechet-dierentiable at
u),  is of class C 1 from Y to U , and
is surjective from Y to U , there exists a unique
such that (4.4) and (4.5)
be satised (see [12], and also Theorem 2.1 in [1]). The variational equation (4.4) admits a
unique solution
dened by
(v). Due to assumptions (A5), it follows
that
p belongs to U . 2
We next introduce the Lagrange function
The system (4.4)-(4.5) is equivalent to
For shortening, we shall write the adjoint equation (4.4) in the form f y (v)+p(+ 0
Thus the rst order optimality system for (P) is
hf
In what follows, the derivatives in L 0 and L 00 refer only to the variable v, but not to the
Lagrange multiplier p. Let us assume that
also satises the following:
(SSC) Second order sucient optimality condition
There is  > 0 such that
holds for all that satisfy the linearized equation
Remark 1 The condition (SSC) is a quite strong assumption, and does not consider
active control constraints, which might occur in U ad . For instance, this can be useful
for constraints of the type U In
concrete applications, the use of an associated second order assumption is possible (see for
example [23]). However, we intend to shed light on the main steps, which are needed for
a convergence analysis of the augmented Lagrangian SQP method, rather than to present
the dicult technical details connected with weakening (SSC) . We shall adress this issue
again in section 6.
Let us complete this section by some simple results, which follow from the second order
sucient condition.
Lemma 1 Suppose that the assumptions (A1)-(A5) are satised. Suppose in addition
that  v satises the second order sucient condition (SSC). Then there exists  > 0 such
that, for every
p) given in B V U ((y;  u;
for all that satisfy the perturbed linearized equation
Proof. We brie
y explain the main ideas of this quite standard result, to show where
the dierent assumptions are needed. If
p) is suciently close to (y;
p), then the
quadratic form L 00
p) is arbitrarily close to L 00 (y;  u;
p). By (SSC), (A2), and (A3)
we derive that
provided that y+ 0 (^y) y analogous estimate has to be shown for the solutions
of the perturbed equation (4.11), where  0 is taken at ^
y. Write for short B := L 00
and dene z as the unique solution of z use the rst part of (A5)).
Then
The assumptions (A1), (A3), and (A5) ensure the estimate
ck^y
(4.
(here and below c stands for a generic constant). Therefore,
7=8  k(z; u)k 2
follows by (4.12), (4.14) and Young inequality, where " > 0 can be taken arbitrarily small.
Now we re-substitute z by y arrive by similar estimates at
provided that  is suciently small. Thus (4.10) is proven. 2
Although we shall not directly apply the next result, we state it to show why the dierent
assumptions are needed. Some of them have been assumed to deal with the well known
two-norm discrepancy.
the optimality system (4:7) of (P ) and the second
order sucient condition (SSC). Suppose that the assumptions (A1)-(A5) are fullled.
Then there are constants " > 0 and  > 0 such that the quadratic growth condition
holds for all admissible
Proof. The rst order optimality system implies
Subtracting the state equations for y and
y, analogously to (4.13) we nd that
1 . Then v h := (y
solves the linearized equation
(4:9), and the coercivity estimate of (SSC) can be applied to v h . Moreover, (A5) yields
khk Y2  c kr
We insert v h in (4.16), write for short B := L 00 (v;
p) and proceed similarly to the estimation
of Bv 2 in the last proof:
ckv
jr L
g:
In these estimates, the assumptions (A2) and (A3) were used. We have kv  v v h k V 2
, and the estimate of h by the rst order remainder term r
1 can be inserted. Let
the
quadratic growth estimate follows from classical arguments. 2
This Lemma shows that the second order condition (SSC) is sucient for local optimality
of (y;  u) in the sense of V , whenever (y;  u) solves the rst order optimality system. Notice
that we cannot show local optimality in the sense of V 2 .
5 Augmented Lagrangian method
5.1 Augmented Lagrangian SQP method
In this section we introduce the Augmented Lagrangian SQP method (ALSQP) with some
special type of augmentation. For this, we rst represent (P) in the equivalent form
Minimize
subject to z
The augmentation takes into account only the nonlinear equation z
ALSQP method is obtained by applying the classical SQP method to the problem
Minimize f  (y;
subject to z
where  > 0 is given. We dene the Lagrange functional L for ( ~
P ), and the corresponding
augmented functional L  on Y  U 4 as follows:
Once again, the derivatives L 0 and L 00 will stand for derivatives with respect to (y; u; z)
and do not refer to the Lagrange multipliers (p; ). The same remark concerns L  . Let
the current iterate of the ALSQP method, and consider the linear-quadratic
problem
(QP
Minimize f 0
subject to z (y n
The new iterate (y obtained by taking the solution (y
of (QP
exists), and the multipliers (p n+1 ;  n+1 ) associated with the constraints
respectively. For we recover the
classical SQP method.
Let us also introduce the following problem:
QP
subject to y
The problems (QP
QP
are equivalent in the sense precised below.
Theorem 2 Let (y a solution of (QP
associated Lagrange multipliers
must solve the problem ( d
QP
n+1 ), and the
multiplier p n+1 is the solution to the equation
Moreover, z n+1 and  n+1 must satisfy
z
Conversely, if (y n+1 ; u n+1 ) is a solution of ( d
QP
are dened by
{ (5:3), then (y n+1 ; u n+1 ; z n+1 ) is a solution to (QP
associated Lagrange
multipliers (p n+1 ;  n+1 ).
Proof. Let us rst assume that (y n+1 ; u
To show that (y n+1 ; u n+1 )
solves ( d
QP
n+1 ) and that the relations (5.1){(5.3) are satised, we investigate the following:
Explicit form of (QP
We expand all derivatives occuring in the problem (QP
. Write for short k  and introduce for convenience the functional g(y;
Having this, the objective to minimize in (QP
n+1 ) is given by
The minimization is subject to the constraints
z (y n
Reduction to ( d
QP
To reduce the dimension of the problem, we exploit the second
one of the equations (5.4): We insert the expression z z n  0 (y n )(y y
in the functional J . Then the second and fourth items in the denition of J are constant
with respect to (y; z; u). They depend only on the current iterate and can be neglected
during the minimization of J . The associated functional to be minimized is
~
Moreover, we can delete the second equation of (5.4) by inserting the expression for z in
the rst one. This explains why (y n+1 ; u n+1 ) is a solution of ( d
QP
Necessary optimality conditions. To derive the necessary conditions for the triplet
with the Lagrange functional
~
The conditions are ~
L u (u u n+1 )  0, for all u 2 U ad . An evaluation yields
for We mention for later use, that the equations (5.4) belong to the optimality
system of (QP
too. The update formulas for p n+1 and  n+1 follow from (5.5), (5.6).
We have shown one direction of the statement. The converse direction can be proved in
a completely analogous manner. If (y
QP
n+1 ), then we substitute z for
in the corresponding positions. Then it is easy to
verify that (y n+1 ; u subject to (5.4), and that  n+1 is the multiplier
associated to the equation z (y n
Remark 2 The update rules (5:2) { (5:3) imply that the Lagrange multiplier  coincides
with p during the iteration, while this is not necessarily true for the initial values of  n
and p n . Therefore, with possible exception of the rst step, up to a constant, the objective
functional of ( d
QP
n+1 ) is
~
This easily follows by calculating L 00 (y from the formula (4:6). Moreover, we are
justifed to replace  n by p n in the variational equation (5:1).
Theorem 2 shows that the iterates of the ALSQP method can be obtained by solving
the reduced problem ( d
QP
solutions of (QP
exist. This question of
existence, can be answered by considering ( d
QP
Theorem 3 Let (y;
p) satisfy the assumptions of Lemma 1 and let
suciently small, then ( d
QP
n+1 ) has a unique solution (y
Moreover, (y being dened by (5:3)) is the unique solution of
(QP
Proof. Assume that k(y;
us prove the existence
for ( d
QP
In view of the remark above, the functional ~
J can be taken instead of J for
the minimization in ( d
QP
Its quadratic part is
where ~
tends to
in U , since z n (y
z yields that the objective functional of ( d
QP
n+1 ) is coercive on the
set ~
hence it is strictly convex there. The set
U ad is non-empty, bounded, convex, and closed in U , and in U 2 as well. We have assumed
in (A5) that ( is continuous from U 2 to Y 2 at all y 2 Y , in particular at
Therefore, ~
C is non-empty, convex, closed, and bounded in Y 2 U 2 . Now existence
and uniqueness of a solution (y
QP
n+1 ) are standard conclusions.
Moreover, U ad  U , hence u n+1 2 U , and the regularity properties of (
guarantee that y n+1 2 Y . Further, z n+1 2 U follows from (5.3). Existence and uniqueness
for (QP
are obtained from Theorem 2. 2
The update rules of Theorem 2 show that (p n+1 ;  n+1 ) is uniquely determined in U 2  U 2 .
We get even better regularity:
Corollary 1 If the initial element (y is taken from Y U 4 , then the iterates
generated by the ALSQP method are uniquely determined and belong
to Y  U 4 .
Proof. Existence and uniqueness follows from the last theorem and the update rules (5.2){
(5.3). We also know that (y n+1 ; u . The only new result we have to
derive is that (p n+1 ;  n+1 ) remains in U  U as well. Since  we have to
verify p n+1 2 U . This, however, follows instantly from the equation (5.1): We know that
belong to b
Y (assumptions (A5), (A6),
(A7)). Moreover, the same holds for ( 00 (y n )(y n+1 y n
Therefore, (A5) ensures the solution p n+1 of (5.1) to be in U . 2
5.2 Newton method for the optimality system of (P  )
The augmented SQP method can be considered as a computational algorithm to solve the
rst order optimality system of (P  ) by the generalized Newton method. This equivalence
will be our tool in the convergence analysis. The optimality system for (P  ) consists of the
equations (L  (w))
z
for the unknown variable The optimality system (5.8) of (P  ) is equivalent
to a generalized equation. To see this, let us rst introduce the following set-valued
mappings:
Y
f0 U g N(u)  f0 U g  f0 U
and consider F
Y  U 4 dened by
f u (y; u) p
z (y)C C C C C C C C C C A
Notice that N(u) has a closed graph in U U . It is the restriction to U of the normal cone
at U ad in the point u. (For the denition of the normal cone, we refer to [5].) In the rst
component of F , due to (A6), we identify with the element
which belongs to ^
Y . With (A5) and (A6), we can
easily verify that F takes values in ^
Y  U 4 .
Lemma 3 The optimality system (5:8) of (P  ) is equivalent to the generalized equation
Proof. By calculating the derivatives of L  in (5.8), we easily verify that:
(L  (w)) y
(L  (w)) z
(L  (w)) u
z (y)C C C C C C A
Therefore, by the denition of F , (5.10) is equivalent to
The third relation can be rewritten as:
This is just the variational inequality of (5.8), and the equivalence of (5.8) and (5.10) is
veried. 2
Next we recall some facts about generalized equations and related convergence results
for the Generalized Newton Method (GNM). Let W and E be Banach spaces, and let O
be an open subset of W. Let F be a dierentiable mapping from O into E , and T be a
set-valued mapping from O into P(E) with closed graph. Consider the generalized equation
The generalized Newton method for (5.11) consists in the following algorithm:
Choose a starting point
For the solution to the generalized equation:
The generalized Newton method is locally convergent under some assumptions stated below

Equation (5.11) admits at least one solution
!.
There exist constants ~ r(!) and ~ c(!) such that BW (!; ~
r(!)).
Denition 1 The generalized equation is said to be strongly regular at !  2 O, if there
exist constants r(!  ) and c(!  ), such that, for all  )), the perturbed generalized
equation
has a unique solution S(!
for all
The theorem below is a variant of Robinson's implicit function theorem ([21], Theorem
2.1).
Theorem 4 ([4], Theorem 2:5) Assume that (5.11) is strongly regular at some  ! 2 O, and
that (C1) and (C2) are fullled. Then there exist (!) > 0, k(!) > 0, and a mapping S 0
from BW (!; (!))  O into BW (!; (!)) such that, for every !  2 BW (!; (!)), S 0 (!  ) is
the unique solution to (5:13), and
The following theorem is an extension to the generalized equation (5.11) of the well known
Newton-Kantorovitch theorem. It is a direct consequence of Theorem 4.
Theorem 5 ([4], Theorem 2:6) Assume that the hypotheses of Theorem 4 are fullled.
Then there exists ~
(!) > 0 such that, for any starting point
(!)), the generalized
Newton method generates a unique sequence (! k ) k convergent to
!, and satisfying
W for all k  1:
We apply these results to set up the generalized Newton method for the generalized equation
(5.10), which is the abstract formulation of the optimality system of (P  ).
Lemma 4 The generalized Newton method for solving the optimality system of (P  ), dened
by (5:12), proceeds as follows: Let w be the current
iterate. Then the next iterate w is the solution
of the following generalized equation for
Proof. This iteration scheme is a conclusion of the iteration rule (5.12) applied to the
concrete choice of (5.9) for F . The computations are straightforward. We should only
mention the following equivalent transformation, which nally leads to (5.14), (5.15): Due
to the concrete expression for F given in (5.12), the rst two relations in
are
Inserting (5.18) in (5.19), (5.20) we obtain (5.14), (5.15). 2
To apply Theorem 5 to the concrete generalized equation (5.10), we need that (5.10) be
strongly regular at
and that conditions (C1) and (C2) be satised. The assumption
of strong regularity at
w must be assumed here. It has to be checked for each particular
application. In general, the verication of strong regularity requires a detailed analysis. In
the case of the optimal control of parabolic partial dierential equations, we refer to the
discussion of the SQP method in Troltzsch [23]. The strong regularity of an associated
generalized equation was proved there by means of a result on L 1 -Lipschitz stability from
[22]. The associated semilinear elliptic case was studied by Unger [24].
The conditions (C1) and (C2) can be veried with assumptions (A6) and (A7).
Lemma 5 The mapping w 7! F (w) is of class C 1;1 from Y  U 4 into b
Y  U 4 .
Proof. This statement is an immediate consequence of (A6) and (A7). 2
Theorem 6 Let (y;
u) be a local solution of (P ), and let
p be the associated adjoint state.
Assume that the generalized equation: Find (y; u; p) 2 Y  U 2 such that
be strongly regular at (y;
p). Then the generalized equation
Find
is strongly regular at
p.
Proof. Let z ) be a perturbation in b
Y  U 4 . The linearized generalized
equation for (5.22) at the point
associated with the perturbation e, is
f yy (y
(z
e
f uy (y
where
f yy stands for f yy (y;
u), and the same notations is used for the other mappings. To
obtain the two rst equations of (5.23), we refer to the system (5.19), (5.20), where we
insert
w and replace the left hand side by the perturbation.
Since
z
by straightforward calculations, we can easily prove that the
system (5.23) is equivalent to
f yy (y
e
f uy (y
Now we observe that the rst, third, and fourth relation of (5.24) form a subsystem for
which does not depend on (z; ). Once (y; u; p) is given from this subsystem,
(z; ) is uniquely determined by the remaining two equations. Let us set ~
e
with
~
The subsystem of (5.24) can be rewritten in the form of the generalized equation
f uy (y
The generalized equation (5.26) is the linearization of the generalized equation (5.21) at
p), associated with the perturbation ~ e. Since (5.21) was assumed to be strongly
regular at (y;
p), there exist ~ r  r(y;
p) > 0, and a mapping S from
U , such that S(~e) is the unique solution to (5.26) for all ~ e
r),
and
U . Now, we show that (5.22) is strongly regular at
w. For any e, let ~
e be given by (5.25). Then
and there exists
r > 0 such that ~ e belongs to
(0;
r). Dene a
mapping
S from B b
(0;
r) into b
where
ce z S 3 (~e):
Then
S(e) is clearly the unique solution to (5.23). We can easily nd  c > 0 such that
. The proof is complete. 2
Theorem 6 shows that once the convergence analysis for the standard non augmented
Lagrange-Newton-SQP method has been done by proving strong regularity of the associated
generalized equation, this analysis does not have to be repeated for analyzing convergence
of the augmented method.
Up to now, we have discussed the Augmented SQP method and the Generalized Newton
method separately. Now we shall show that both methods are equivalent. This equivalence
is used to obtain a convergence theorem for the augmented SQP method.
Theorem 7 Let (y;  u) a local solution of (P ), which satises together with the associated
Lagrange multiplier
p the second order sucient optimality condition (SSC). Dene
suppose that the generalized equation (5:21) is
strongly regular at
w. Then there exists
w) > 0 such that, for any starting point
in the neighbourhood BW (
w; r), the ALSQP method dened according to
Theorem 2 and the generalized Newton method dened in Lemma 4 generate the same sequence
of iterates (w n . Moreover, there is a constant c q (
w) such
that the estimate
is satised for all
Proof. First we should mention the simple but decisive fact that
w satises the optimality
system of (P  ), since (y;
p) has to satisfy the optimality system for (P). There-
fore, it makes sense to determine
w by the generalized Newton method. Let w
be an arbitrary current iterate, which is identical for the ALSQP method
and the generalized Newton method.
In the GNM, w n+1 2 W is found as the unique solution of (5.14){(5.18). As concerns the
ALSQP method, (y obtained as the unique solution of ( d
QP
are determined by (5.2). Therefore, (y
satises the associated optimality system (5.4), (5.5)-(5.7) which is obviously identical with
(5.14)-(5.18). It is clear that both the methods deliver the same new iterate w n+1 2 W .
All remaining statements of the theorem follow from the convergence Theorem 5. 2
6 Numerical results
6.1 Test example
We apply the augmented SQP method to the following one-dimensional nonlinear parabolic
control problem with Stefan-Boltzmann boundary condition:
Z( a y (t)
subject to
u a  u(t)
This example is a particular case of problem (E) considered in Section 3, where we
take
(0; ') and make an associated modication of the boundary condition. In an early phase of
this work, we studied the numerical behaviour of the SQP method without augmentation.
Here, we compare both methods. We performed our numerical tests for the following
particular data:
a y
Lemma 6 The pair (y;  u) dened by
e 2=3 e 1=3
is a locally optimal solution for (6:27) in C([0; '][0; T ])L 1 (0; T ). The associated adjoint
state (Lagrange multiplier) is given by
cos(x). The triplet (y;
the second order sucient optimality condition (SSC).
Proof. The proof is split into four steps.
Step 1. State equation. It is easy to see that
Now regard the boundary condition at ': The left hand side is
The same holds for the right hand side, since
Step 2. Adjoint equation. Again, the equations
are easy to check. It remains to verify the boundary condition at
It is obvious that
'. The right hand side of the boundary condition has
the same value, since
a y (t)
Step 3. Variational inequality. We must verify that
{ which is trivial { and that
a
It is well known that this holds if and only if
(a
e 2=3 e 1=3
where P [0;1] denotes projection onto [0; 1]. This is obviously veried.
Step 4. Second order sucient condition. The Lagrange function is given by
R
R l
R Ty x (0; t)p(0;
R T(y x (';
R T
Therefore,
Since
p is negative, L 00 (y;
p) is coercive on the whole space Y  U , hence (SSC) is
Theorem 8 The pair (y;
u) is a global solution of (E).
Proof. Let (y; u) be any other admissible pair for (E). Due to the rst order necessary
condition, we have
p)(y
u)2
Z
Z
>From the positivity of
p and of ' 00 (y (independently of s and y), it follows
that f(y; u)  f(y;
u). 2
Next we discuss the strong regularity of the optimality system at (y;
p).
Theorem 9 The optimality system of (E) is strongly regular at (y;
p).
Proof. The triplet (y;
p) satises (SSC). Moreover, (E) ts into a more general class
of optimal control problems for semilinear parabolic equations, which was considered in
[23]. It follows from Theorem 5.2 in [22], and Theorem 5.3 in [23] that (SSC) ensures
the strong regularity of the generalized equation being the abstract formulation of the
associated optimality system. We only have to apply this result to problem (6.27). 2
Remark 3 A study of [23] reveals that convergence of the standard SQP method can be
proved for arbitrary dimension
of
assuming a weaker form of (SSC). It requires coercivity
of L 00 only on a smaller subspace that considers strongly active control constraints.
This weaker assumption should be helpful for proving the convergence of the augmented
SQP method as well. We shall not discuss this, since the technical eort will increase
considerably.
Now we obtain from Theorem 7 the following result:
Corollary 2 The Augmented Lagrangian SQP method for (E) is locally quadratically convergent
towards (y;
p).
6.2 Algorithm
For the convenience of the reader, let us consider the problem ( d
QP
corresponding to
our test example. After simplifying we get
Minimize2
subject to
(6.
with
One specic diculty for solving problem (6:27)-(6:29) is partially related to the control
constraints. But the main diculty appears also in the unconstrained case where a (large)
linear system has to be solved. Let us consider for a moment the unconstrained case. If
solution of problem (6:27)-(6:28), then the optimal triplet
satises (6:28), the adjoint equation
and
(a
In practice, we solve ( d
QP
discretization of its optimality system. The result is taken to
solve ( d
QP
). The discretized version of equation (6.31) corresponds to a large-scale linear
system. To solve this system, we need the solutions corresponding to the discretization
of two coupled parabolic equations (the state and the adjoint equations). It is clear that
the accuracy of the Augmented Lagrangian SQP-method depends on the one for solving
the linear system, and consequently on the numerical methods for the partial dierential
equations. In our example, the state and adjoint equations are solved by using a second-order
nite dierence scheme (Cranck-Nicholson scheme) appropriately modied at the
boundary to maintain second order approximation. The linear system is solved by using
the CGM (conjugate gradient method), with a step length given by the Polak-Ribiere
formula.
Let us now take into account the constraints (6.29). The optimality condition (6.31) is
replaced by
(a
(a
The management of these restrictions is based on (6.32) and on an projection method
by Bertsekas [7]. (See also [9] and [10] where this method is successfully applied.) More
precisely, we have the following algorithm:
be the vector representing the iterate corresponding to
xed grid. Let " and  be xed positive numbers, and let I = f1;    ; mg
be the index set associated to w n . (m is the dimension of the vector w n and depends
on the discretization of u n )
and denote by d
the vector representing
the iterate corresponding to the solution of (6.30).
the sets of strongly active inequalities
I
I
where A
is the vector representing a u .
n for all j 2 I
a [ I
b .
Solve the unconstrained problem (6.27)-(6.28) for w j
a [ I
remaining components are xed due to 4.) Denote by v n the vector representation of
the solution.
denotes the projection onto [u a ;
and go to 2. Otherwise stop
the iteration.
6.3 Numerical tests
In the numerical tests, we focused our interest on the aspects concerning the convergence
for dierent values of initial data and penalty parameters , and on the rate of convergence.
The programs were written in MATLAB.
Let us rst summarize some general observations.
In our example, the augmented Lagrangian algorithm performed well. In particular, the
graphs of the exact solution and that of the numerical solution are (almost) identical.
When compared with the SQP method (corresponding to  = 0), the augmented Lagrangian
SQP has the advantage of a more global behavior. Moreover, it is less sensitive
to the start-up values, and is signicantly faster than the SQP method for some points.
Graphical correction of the computed controls and precisionof optimal value (up to ve
digits) are obtained by taking the discretization parameters with respect to the time and
the space equal to 200.
For xed data, the number of iterations for the CGM and the Augmented SQP turned
out to be independent of the mesh size.
In all the sequel, we set
ku
ku
where (u;
z) and are the vectors respectiveely corresponding
to the exact solution of (E), the numerical solution of (E), and the solution of ( d
QP
Moreover, we denote by n t and n x the discretization parameters with respect to the time
and the space. Optimal controls were determined for the following pairs (n x
(200,200), (400,400).
Run 1. (SQP method.) The rst test corresponds to
The rates for e n , n u , n p , and n z are given in Table 1.

Table

1:
100 1.7782e-06 2.5347e-06 1.6610e-06 0.2372 0.3653 1.0575 1.3886
200 1.3725e-06 2.9337e-06 1.0724e-06 0.2472 0.3663 1.0585 0.9980
The SQP method shows a good convergence for this initial point. 4 iterations were needed
to get the result.
Run 2. (ALSQP method.) The second test corresponds to the point
(0:5; 0:5; 0:5), with z

Table

2:
100 1.5391e-06 2.6824e-06 1.5013e-06 1.4459e-06 0.0150 1.0004 2.2378
200 1.2318e-06 3.8783e-07 5.2251e-07 5.5521e-07 0.0149 0.9256 1.0015
The ALSQP method has a very good convergence for this choice. Convergence could always
be achieved by xing using other values of z 0 and . However, the number
of iterations and the speed of the method depend on these choices. As shown in Table 3,
three iterations for the ALSQP method were needed, instead of four for the SQP method.
The number of iterations for the CGM, the SQP and the ALSQP methods is independent
of the mesh-size. The exact value for the cost functional is
In

Table

3, we give
the values of the cost functional corresponding to the dierent steps for

Table

3:
SQP method
Iter f n CGM iter
ALSQP method
Iter f n CGM iter
u2 u1
u3, u4
u2, u3

Figure

1: Controls for Run 1 and Run 2

Figure

2: States y('; t) for Run 1 and Run 2
p3, p4
p2, p3

Figure

3: Adjoint states p('; t) for Run 1 and Run 2
In

Figures

1, 2, and 3, we compare the behavior of the control, the state, and the adjoint
state obtained by taking 1. It is clear that in the case of the
ALSQP method, the second iteration gives a good approximation to the optimal control,
the optimal state, and the optimal adjoint state.
Run 3. The last test corresponds to the initial point given by

Table

4:
100 9.9421e-06 2.7989e-06 4.0979e-06 3.0853e-06
200 1.1864e-05 4.7523e-06 5.0999e-06 2.3842e-06
400 1.2167e-05 5.2817e-06 5.3307e-06 2.2146e-06
200 0.0404 0.3975 1.3537 1.1471
For this initial point, the SQP method (corresponding to does not converge, while
the ALSQP method converges for many choices of z 0 . In our tests, the point which gives
the best result is given by z 1. For this choice, 4 iterations are needed
with 2, 5, 6 and 9 CG steps. The dierents rates are given in Table 4, and the behavior of
the solution is shown is Figure 4.
Remark 4 The numerical results stated in Table 1, 2, and reft3 were obtained for a xed
mesh-size (xed grid). However, we also implemented the ALSQP method with adaptative
mesh size, i.e. we started with a coarse grid and used the obtained results as startup values
u2
u3, u4
p3,

Figure

4: Controls, states, and adjoint states for Run 3
for the next ner grid. This method is signicantly faster, and delivers essentially the same
results.



--R

A Lagrange multiplier theorem for control problems with state constraints
The Lagrange-Newton method for in nite-dimensional optimization prob- lems
The Lagrange Newton method for in
Discretization and mesh independence of Newton's method for generalized equations.
Analysis and Control of Nonlinear In
Augmented Lagrangian techniques for elliptic state constrained optimal control problems
Projected Newton methods for optimization problems with simple constraints
Pontryagin's principle for state-constrained boundary control problems of semilinear parabolic equations

Numerical solution of a constrained control problem for a phase


Augmented Lagrangian-SQP methods for nonlinear optimal control problems of tracking type
Augmented Lagrangian-SQP methods in Hilbert spaces and application to control in the coecients problems

Augmented Lagrangian-SQP techniques and their approxi- mations
"Linear and quasilinear equations of parabolic type"
First and second order su

Hamiltonian Pontryagin's principles for control problems governed by semilinear parabolic equations
Strongly regular generalized equations.


Hinreichende Optimalit

Distributed control problems for the Burgers equation.
--TR
Multiplier methods for nonlinear optimal control
Second-order sufficient optimality conditions for a class of nonlinear parabolic boundary control problems
Augmented Lagrangian--SQP Methods for Nonlinear OptimalControl Problems of Tracking Type
Augemented Lagrangian Techniques for Elliptic State Constrained Optimal Control Problems
Pontryagin''s Principle for State-Constrained Boundary Control Problems of Semilinear Parabolic Equations
On the Lagrange--Newton--SQP Method for the Optimal Control of Semilinear Parabolic Equations
Mesh-Independence for an Augmented Lagrangian-SQP Method in Hilbert Spaces
Distributed Control Problems for the Burgers Equation

--CTR
Hans D. Mittelmann, Verification of Second-Order Sufficient Optimality Conditions for Semilinear Elliptic and Parabolic Control Problems, Computational Optimization and Applications, v.20 n.1, p.93-110, October 2001
