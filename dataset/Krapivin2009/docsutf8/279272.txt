--T
A Volumetric/Iconic Frequency Domain Representation for Objects With Application for Pose Invariant Face Recognition.
--A
AbstractA novel method for representing 3D objects that unifies viewer and model centered object representations is presented. A unified 3D frequency-domain representation (called Volumetric Frequency RepresentationVFR) encapsulates both the spatial structure of the object and a continuum of its views in the same data structure. The frequency-domain image of an object viewed from any direction can be directly extracted employing an extension of the Projection Slice Theorem, where each Fourier-transformed view is a planar slice of the volumetric frequency representation. The VFR is employed for pose-invariant recognition of complex objects, such as faces. The recognition and pose estimation is based on an efficient matching algorithm in a four-dimensional Fourier space. Experimental examples of pose estimation and recognition of faces in various poses are also presented.
--B
Introduction
A major problem in 3-D object recognition is the method of representation, which actually
determines to a large extent, the recognition methodology and approach. The large variety
of representation methods presented in the literature do not provide a direct link between the
3-D object representation and its 2-D views. These representation methods can be divided
into two major categories: object centered and viewer centered (iconic). Detailed discussions
are included in [15] and [12]. An object centered representation describes objects in a coordinate
system attached to objects. Examples of object centered methods of representation are
spatial occupancy by voxels [15], constructive solid geometry (CSG) [15], superquadrics [21]
[2], algebraic surfaces [8], etc. However, object views are not explicitly stored in such representations
and therefore such datasets do not facilitate the recognition process since the
images cannot be directly indexed into such a dataset and need to be matched to views generated
by perspective/orthographic projections. Since the viewpoint of the given image is
a priori unknown, the recognition process becomes computationally expensive. The second
category i.e. viewer centered (iconic) representations, is more suitable for matching a given
image, since the model dataset also is comprised of various views of the objects. Examples
of viewer centered methods of representation are aspect graphs [16], quadtrees [12], Fourier
descriptors [30], moments [13], etc. However, in a direct viewer centered approach, the
huge number of views needed to be stored renders this approach impractical for large object
datasets. Moreover, such an approach does not automatically provide a 3-D description of
the object. For example, in representations by aspect graphs [16], qualitative 2-D model
views are stored in a compressed graph form, but the view retrieval requires additional 3-D
information in order to generate the actual images from different viewpoints. For recognition
purposes, viewer centered representations do not offer a significant advantage over
object centered representations. In summation, viewer centered and object centered representations
have complementary merits that could be augmented in a merged representation
- as proposed in this paper.
A first step in unifying object and viewer centered approaches was provided by our
recently developed iconic recognition method by Affine Invariant Spectral Signatures (AISS)
[6] [5] [4], which was based on an iconic 2-D representation in the frequency domain. However,
the AISS is fundamentally different from other viewer centered representations since each
2-D shape representation encapsulates all the appearances of that shape from any spatial
pose. It also implies that the AISS enables to recognize surfaces which are approximately
planar, invariant to their pose in space. Although this approach is basically viewer centered,
it has the advantage of directly linking 3-D model information with image information, thus
merging object and viewer centered approaches. Hence, to generalize the AISS it is necessary
to extend it from 2-D or flat shapes to general 3-D shapes. Towards this end, we describe in
Section 2, a novel representation of 3-D objects by their 3-D spectral signatures which also
captures all the 2-D views of the object and therefore facilitates direct indexing of a given
image into such a dataset.
As a demonstration of the VFR, it is applied for estimating pose of faces and face recognition
in Section 3. Range image data of a human head is used to construct the VFR model
of a face. We demonstrate that reconstruction from slices of the VFR results are accurate
enough to recognize faces from different spatial poses and scales. In Section 3, we describe
the matching technique by means of which a gray scale image of a face is directly indexed
into the 3-D VFR model based on fast matching by correlation in a 4 dimensional Fourier
space. In our experiments (described in Section 5), we demonstrate how the range data
generated from a model is used to estimate the pose of a person's face in various images.
We also demonstrate the robustness of our 2-D slice matching process by recognizing faces
with different poses from a dataset of 40 subjects, and present statistics of the matching
experiments.
Frequency Representation (VFR)
In this section, we describe a novel formulation that merges the 3-D object centered representation
in the frequency domain to a continuum of its views. The views are also expressed
in the frequency domain. The following formulation describes the basic idea.
Given an object O, which is defined by its spatial occupancy on a discrete 3-D grid as a
set of voxels fV (x; z)g, we assume without loss of generality, that the object is of equal
density. Thus, V (x; otherwise. The 3-D
Discrete Fourier Transform (DFT) of the object is given by V(u; v; z)g. The
surface of the object is derived from the gradient vector field
@
@x
@
@y
@
@z
where k x , k y and k z are the unit vectors along the x; y and z axes. The 3-D Discrete Fourier
Transform (DFT) of the surface gradient is given by the frequency domain vector field:
F frV (x;
Let the object be illuminated by a distant light source 1 with uniform intensity \Upsilon and direction
z . We assume that the object O is a regular set [1] and has a constant
gradient magnitude K on the object surface, i.e. j rV K. The surface normal is given by
. We also assume that O has a Lambertian surface with constant albedo A. Thus points
on its surface have a brightness proportional to
@
@x
@
@y
@
@z
i are the positive and negative parts. The function
z) is not a
physically realizable brightness and is introduced only for completeness of Eq. (3). The separation
of the brightness function into positive and negative components is used to consider
Additional light sources can be handled using superposition.
only positive illuminations. The negative components are disregarded in further processing,
as this function is separable only in the spatial domain. As elaborated in Section 2.2,
can be eliminated using a local Gabor transform. In another approach, the side of the object
away from the illumination can be considered as planar and
becomes a plane with a
negative constant value which does not alter the resulting image.
It is also necessary to consider the viewing direction when generating views from the
VFR. The brightness function B i (x; y; z) is decomposed as a 3-D vector field by projecting
onto the surface normal at each point of the surface. This enables the correct projection of
the surface from a given viewpoint. As noted earlier, the surface normal is given by rV
Thus, the new vectorial brightness function B i is given by
\UpsilonA
The 3-D Fourier transform of this model is a complex 3-D vector field V i (u; v; w)=FfB i (x; z)g.
The transform is evaluated as:
(i x
where   denotes convolution. Variation in illumination only emphasizes the amplitude of V i
in the (i x but does not change its basic structure. The absolute value of
defined as the VFR signature.
2.1 Projection Slice Theorem and 2-D Views
The function V i (u; v; w) is easily obtained, given the object O. To generate views of the
object, we resort to 3-D extensions of the Projection-Slice Theorem [14] [24] that projects
the 3-D vector field V i (u; v; w) onto the central slice plane normal to the viewpoint direction.
Fig. 1 illustrates the principle by showing the slice derived from the 3-D DFT of a rectangular
block. Orthographically viewing the object from a direction results
in an image I c which has a 2-D DFT given by Ic To find I c its
necessary to project the vector brightness function
along the
Figure

1: The Projection-Slice Theorem: A slice of the 3-D Fourier Transform of a rectangular
block (on the right) is equivalent to the 2-D Fourier Transform of the projection of the image of
that block (on the left).
viewing direction c after removing all the occluded parts from that viewpoint. The vectorial
decomposition of the brightness function along the surface normals as given by Eq. (4)
compensates for the integration effects of projections of slanted surfaces. This explains the
necessity of using a vectorial frequency domain representation.
Removing the occluded surfaces is not a simple task if the object O is not convex or if the
scene includes other objects that may partially occlude O. For now, we shall assume that O
is convex and is entirely visible. This assumption is quite valid for local image analysis where
a local patch can always be regarded as either entirely occluded or visible. Also, for local
z) is not a major problem. The visible part of B i (x; y; z) from direction c,
denoted by B ic (x; y; z), is given by
\UpsilonA
where hwr[ff] is the "half wave rectified" value of ff, i.e.
Now V ic (u; v; w) can be obtained from B ic (x; simply by calculating the DFT,
The image DFT Ic obtained using the Projection-Slice Theorem [14] [24] by
slicing V ic (u; v; w) through the origin with a plane normal to c, i.e.
derived by sampling V ic (u; v; w) on this plane. An example
of such a slicing operation is illustrated in Fig. 1. Note that V ic actually encapsulates both
the objects 3-D representation and the continuum of its view-signatures, which are stored as
planar sections of j V ic j. As we see from Eq. (5), variations in illumination only emphasizes
the amplitude of V i in (i x direction, but do not change its basic structure. Thus, it is
feasible to recognize objects that are illuminated from various directions by local signature
matching methods as described in Section 2.3, while employing the same signature.
2.2 Local Signature Analysis in 3-D
Local signature analysis is implemented by windowing B i with a 3-D Gaussian centered at
location proceeding as in Eq. (4) on the windowed object gradient. Such
local frequency analysis is implemented by using the Gabor Transform (GT) instead of the
DFT. The transition required from the DFT to the GT is quite straightforward. The object
O is windowed with a 3-D Gaussian to give
oe x
oe y
oe z
The equivalent local VFR is given by
The important outcome from this are: 1) The Projection-Slice Theorem [14], [24] can be still
employed for local space-frequency signatures of object parts. 2) In local space-frequency
almost always does not contain the problematic
i part, which can be eliminated
by the windowing function. We note that for most local surfaces, [B i \Delta
as the local analysis approximates the hwr[\Delta] function with respect to viewing direction c.
Hence, the VFR of B ic is a general representation of a local surface patch of V (x;
uc +vc
x y z
e
a
u'
w'
slice plane

Figure

2: The frequency domain coordinate system in which the slice plane is defined.
are the direction cosines of the slice plane normal, which has an azimuth ff and an elevation ffl.
Image swing is equivalent to in-plane rotation ', and viewing distance results is variation in the
radial frequency r f of the VFR function.
2.3 Indexing using the VFR signature
As explained in Section 2.1, the VFR is a continuum of the 2-D DFT of views of the model.
To facilitate indexing into the VFR signature data structure, we consider the VFR signature
slice plane uc x are the direction cosines of the slice plane
normal. We define a 4-D pose space in the frequency domain which consists of the azimuth ff
and elevation ffl, defining the slice plane normal with respect to the original axes, the in-plane
rotation ' of the slice plane and the scale ae which changes with the distance to the viewed
object. Fig. 2 illustrates the coordinate system used. [c x are related to the azimuth
ff and elevation ffl as follows6c x
c y
c z7
sin ff cos ffl
sin ffl7\Gamma-=2 - ff -=2
We note again that slices of the VFR signature are planes which are parallel to the imaging
plane. Thus the image plane normal and the slice plane normal coincide. By using 3-D
coordinate transformations (see Fig. 2) we can transform the frequency domain VFR model
to the 4-D pose space (ff; ffl; '; ae). Let (u; v; w) represent the original VFR coordinate system
and (-u; - v; -
w) be the coordinate system defined by the slice plane. The slice plane is within
the 2-D coordinate system (-u; - v), where -
w is the normal to the slice plane and corresponds
to the viewing direction. The relation between these two systems is given by6u
sin ff sin ffl cos ff sin ff cos ffl
VFR signature slices, being 2-D DFT's of model views are further transformed to polar
coordinates by considering the in-plane rotation ' (equivalent to the image swing or rotation
about the optical axis), and the radial frequency r f .
- u
sin '
\Gamma-=2 -=2
The radial frequency r f is transformed logarithmically to attain exponential variation of r f
given by ae = log a
. The full transformation of the coordinate system to the 4-D pose space
is given by 24
cos ' sin ff sin ffl \Gamma sin ' cos ff
sin ' cos ffl7
Thus, the 4-tuple (ff; ffl; '; ae) defines all the points in the 3-D VFR signature frequency space
We observe that the space defined by the 4-tuple (ff; ffl; '; ae) is redundant in the
sense that infinite number of 4-tuples (ff; ffl; '; ae) may represent the same (u; v; w) point.
However, this representation has the important advantage that every (ff; ffl) pair defines a
planar slice in V ic (u; v; w). Moreover, every ' defines an image swing and every ae defines
another scale. Thus the (ff; ffl; '; ae) representation significantly simplifies the indexing search
for the viewing poses and scales. Now, the indexing can be simply implemented by correlation
in the frequency domain to immediately determine all pose parameters by linear shifts in
space. The significance of this transformation to the 4-D pose space is in using
the following properties. The polar coordinate transformation within the slice allows rotated
image views to have 2-D frequency domain signatures which shift along the ' axis. Similarly
the exponential sampling of the radial frequency r f results is scale changes causing linear
shifts along the ae axis. Thus the new coordinate system given by (ff; ffl; '; ae) results in a 2-D
frequency domain signature which is invariant to view point and scale and results only in
linear shifts in the 4-D pose space so defined. A particular slice corresponding to a particular
viewpoint is easily indexed into the transformed VFR signature by using correlation.
3 Pose Estimation and Recognition of Human Faces
Recognition of human faces is a hard problem for machine vision, primarily due to the
complexity of the shape of a human face. The change in the observed view caused by
variation in facial pose is a continuum which needs large numbers of stored models for every
face. Since the representation of such a continuum of 3-D views is well addressed by our
VFR, we present here, the application of our VFR model for pose-invariant recognition of
human faces. First we discuss some of the existing work in face recognition in Section 3.1
followed by our approach to the problem in Section 3.2. We present our results in face
pose estimation (Section 4) and face recognition (Section 3) and compare our results in face
recognition to some other recent works using the same database [20].
azimuth a
elevation
e

Figure

3: Reconstructions of a model face from slices of the VFR are shown for various azimuths
and elevations. Note that all facial features are accurately reconstructed indicating the robustness
of the VFR model.
3.1 Face Recognition: A Literature Survey
Recent works in face recognition have used a variety of representations including parameterized
models like deformable templates of individual facial features [29] [26] [10], 2-D
pictorial or iconic models using multiple views [9] [7], matching in eigenspaces of faces or
facial features [22] and using intensity based low level interest operators in pictures. Other
recent significant approaches have used convolutional neural networks [18] as well as other
neural network approaches like [11] and [28]. Hidden Markov Models [25], modeling faces as
deformable intensity surfaces [19], and elastic graph matching [17] have also been developed
for face recognition.
Parameterized models approaches like that of Yuille et al. [29], use deformable template
models which are fit to preprocessed images by minimizing an energy functional, while
Terzopoulos and Waters [26] used active contour models of facial features. Craw et al. [10]
and others have used global head models from various smaller features. Usually deformable
models are constructed from parameterized curves that outline subfeatures such as the iris or
a lip. An energy functional is defined that attracts portions of the models to pre-processed
versions of the image and model fitting is performed by minimizing the functional. These
models are used to track faces or facial features in image sequences. A variation is the
deformable intensity surface model proposed by Nastar and Pentland [19]. The intensity
is defined as a deformable thin plate with a strain energy which is allowed to deform and
match varying poses for face recognition. A 97% recognition rate is reported for a database
with 200 test images.
Template based models have been used by Brunelli and Poggio [9]. Usually they operate
by direct correlation of image segments and and are effective only under invariant conditions
of scale orientations and illumination. Brunelli and Poggio computed a set of geometrical
features such as nose width and length, mouth position and chin shape. They report 90%
recognition rate on a database of 47 people. Similar geometrical considerations like symmetry
[23] have also been used. A more recent approach by Beymer [7] uses multiple views and a
face feature finder for recognition under varying pose. An affine transformation and image
warping is used to remove distortion and bring correspondence between test images and
model views. Beymer reports a recognition rate of 98% of a database of 62 people, while
using 15 modeling views for each face.
Among the more well known approaches has been the eigenfaces approach [22]. The
principal components of a database of normalized face images is used for recognition. The
results report a 95% recognition rate from a database of 3000 face images of about 200
people. However, it must be noted that the database has several face images of each person
with very little variation in face pose. More recent reports on a fully automated approach
with extensive preprocessing on the FERET database indicate only 1 mistake on a database
of 150 frontal views.
Elastic graph matching using the dynamic link architecture [17] was used quite successfully
for distortion invariant recognition. Objects are represented as sparse graphs. Graph
vertices labeled with multi-resolution spectral descriptions and graph edges associated with
geometrical distances form the database. A recognition rate of 97.3% is reported for a
database of 300 people.
Neural network approaches have also been popular. Principal components generated
using an autoassociative network have been used [11] and classified using a multilayered
perceptron. The database consists of 20 people with no variation in face pose or illumination.
Weng and Huang used a hierarchical neural network [28] on a database of 10 subjects. A
more recent approach uses a hybrid approach using self organizing map for dimensionality
reduction and a convolutional neural networks for hierarchical extraction of successively
larger features for classification [18]. The reported results show a 3.8% error rate on the
ORL database using 5 training images per person.
In [25], a HMM-based approach is used on the ORL database. Error rates of 13%
were reported using a top-down HMM. An extension using a pseudo two-dimensional HMM
reduces the error to 5% on the ORL database. 5 training and 5 test images were used for
each of 40 people under various pose and illumination conditions.
3.2 VFR model of faces
In our VFR model, we present a novel representation using dense 3-D data to represent
a continuum of views of the face. As indicated by Eq. (7) in Section 2, the VFR model
encapsulates the information in the 3-D Fourier domain. This has the advantage of 3-D
translation invariance with respect to location in the image coupled with faster indexing
to a view/pose of the face using frequency domain scale and rotation invariant techniques.
Hence, complete 3-D pose invariant recognition can be implemented on the VFR.
Range data of the head is acquired using a Cyberware range scanner. The data consists
of 256 \Theta 512 range information from the central axis of the scanned volume. 360 ffi of azimuth
is sampled in 512 columns and heights in the range of 25 to 35 cm is sampled in 256
rows. The data is of the heads of subjects looking straight ahead at 0 ffi azimuth and 0 ffi
latitude corresponding to the x-axis. This model is then illuminated with numerous sources
of uniform illumination thus approximating diffuse illumination. The resulting intensity data
in converted from the cylindrical coordinates of the scanner to Cartesian coordinates and
inserted in a 3-D surface representation of the head surface as given by Eq. (3).
The facial region of interest to us is primarily the frontal region consisting of the eyes,
lips and nose. A region corresponding to this area is extracted by windowing the volumetric
surface model with a 3-D ellipsoid centered at the nose with a Gaussian fall-off. The parameters
of the 3-D volumetric mask are adjusted to ensure that the eyes, nose and lips are
contained within it, with the fall off beyond the facial region. The model thus formed is a
complex surface which consists of visible parts of the face from an continuous range of view
centered around the x-axis or the (0 direction. The resulting model then corresponds
to Eq. (6) in our VFR model. Applying Eq. (7), the VFR of the face is obtained. The VFR
model is then resampled into the 4-D pose space using Eq. (13) as described in Section 2.3.
Reconstructions of a range of viewpoints from a model head, from the VFR slices are shown
in Fig. 3. We see from the reconstructions, that all relevant facial characteristics are retained
thus justifying our use of the vectorial VFR model. This model is used in the face
pose estimation experiments.
3.3 Indexing images into the VFR signature
Images of human faces are masked with an ellipse with Gaussian fall-off to eliminate background
textures. The resulting image shows the face with the eyes nose and lips. The
magnitudes of Fourier transform of the windowed 2-D face images are calculated. The windowing
has the effect of focusing on local frequency components (or foveating) on the face.
while retaining the frequency components due to facial features. The Fourier magnitude
spectrum make the spectral signature translation invariant in the 2-D imaging plane. The
spectrum is then sampled in the log-polar scheme similar to the slices of the VFR signa-
ture. As most illumination effects are typically lower frequency, band pass filtering is used
to compensate for illumination.
The spectral signatures from the gray scale images are localized (windowed) log-polar
sampled Fourier magnitude spectra. The continuum of slices of the VFR provide all facial
poses, and band-passed Fourier magnitude spectrum provides 2-D translation invariant (in
the imaging plane) signatures. Log-polar sampling of the 2-D Fourier spectrum allows for
scale invariance (translation normal to the imaging plane) and rotation invariance (within
the imaging plane). This is because a scaled image manifests itself in Fourier spectrum
inversely proportional to the scale and a rotated image has a rotated spectrum. Thus scaled
and rotated images have signatures which are only linearly shifted in the log-polar sampled
frequency domain.
The pose of a given image is determined by correlating the intensity image signature
with the VFR in the 4-D pose space. The matching process is based on indexing through
the sampled VFR signature slices and maximizing the correlation coefficient for all the 4
pose parameters. The correlation is performed on the signature gradient which reduces
dependence of actual spectral magnitudes and as it considers only the shape of the spectral
envelope. The results take the form of scale and rotation estimate along with a matching
score from 0 to 1. Similar matching methods have been very sucessfully used to match Affine
Invariant Spectral Signatures (AISS) [27] [3] [6] [5] [4]. References [27] and [3] already include
detailed noise analysis with white and colored noise which shows robustness to noise levels
of up to 0 dB SNR for these matching methods.
Table

1: Pose estimation errors for faces with known pose. These are the averaged absolute
errors for angles and standard deviation of the ratio of estimated size to true size for scale.
Azimuth Error Elevation Error Rotation Error Scale Std. Dev.
4 Face Pose Estimation
To verify the accuracy of the pose estimation procedure, the method is first tested on images
generated from the 3-D face model. 20 images of the face in Fig. 3 are generated using
random viewpoints and scales from uniform distributions. The azimuth and elevation are in
the range the rotation angle is in the range [\Gamma45 and the scale in the range
[0:5; 1:5]. These are indexed in the VFR signature pose space. The results are summarized in

Table

1. An example of the correlation peak for the estimated pose in azimuth and elevation
is shown in Fig. 4(b) for the test image in Fig. 4(a). The corresponding reconstructed face
from the VFR signature slice is shown in Fig. 4(c).
a b c

Figure

4: (a) A test image with pose parameters
The correlation maximum in the azimuth-elevation dimensions of the pose space. The peak is
quite discriminative as seen by relative brightness. (c) The reconstructed image from the slice
which maximizes the correlation. Pose parameters
In addition, we also show the results of pose estimation of face images of the subject with
unknown pose and illumination in Fig. 5.

Figure

5: Using the VFR model, the pose of the face in the above images is estimated
and the faces are recognized. The estimated poses are given in terms of the 4-tuple azimuth
ff, the elevation ffl, the relative swing (rotation) ', and the relative scale r 0   a ae . The
results are A:(+15

Table

2: Face recognition using the ORL database. Recognition rates are given for 5, 6, 7 and
8 images as VFR signature slices.
Number of Slices 5 6 7 8
Recognition Rate 92.5% 95.6% 96.6% 100%
5 Face Recognition Results
In this section, we describe experiments on face recognition based on the VFR model. The
ORL database [20] is used. The ORL database consists of 10 images of each of 40 people
taken in varying pose and illumination. Thus, there are a total of 400 images in the database.
Figure

Shown are images of a few faces from the set of test images which are used for the
face recognition task using our matching scheme.
We select a number of these images varying from 5 to 8 as model images and the remaining
images form the test set. The model images are windowed with an ellipse with a Gaussian
fall-off. The recognition is robust to the window parameters selected, provided the value of
oe for the Gaussian fall-off is relatively large. The images are 112 \Theta 92 pixels. The window
parameters chosen were for the longer elliptical axis aligned vertically and 22 pixels
for the shorter axis aligned horizontally and pixels. Each window is centered at
(60,46). This allows for faster processing rather than manually fitting windows to each face
image. Thus, the same elliptical Gaussian window was used on all model and test images
even though its axes does not align accurately with the axes of all the faces. The windowed
images are transformed to the Fourier domain and then sampled in a log-polar format, now
correspond to slices in a 4-D VFR signature pose space. The test images are then indexed
into the dataset of slices for each person. The recognition rates using 5, 6, 7 and 8 model
images are summarized in Table 2. As can be seen, a recognition rate of 92.5% is achieved
when using 5 slices. This increases to 100% when using 8 slices in the model. A few of the
test images that are recognized are shown in Fig. 6. Computationally each face indexing
takes about 320 seconds when using 5 slices and up to about 512 seconds when using 8 slices.
The experiments are performed on a 200 MHz Pentium Pro running Linux.
6 Summary and Conclusions
We present a novel representation technique for 3-D objects unifying both the viewer and
model centered object representation approaches. The unified 3-D frequency-domain representation
(called Volumetric Frequency Representation - VFR) encapsulates both the spatial
structure of the object and a continuum of its views in the same data structure. We show that
the frequency-domain representation of an object viewed from any direction can be directly
extracted employing an extension of the Projection Slice theorem. Each view is a planar
slice of the complete 3-D VFR. Indexing into the VFR signature is shown to be efficiently
done using a transformation to a 4-D pose space of azimuth, elevation, swing (in-plane image
rotation) and scale. The actual matching is done by correlation techniques.
The application of the VFR signature is demonstrated for pose-invariant face recognition.
Pose estimation and recognition experiments is carried out using a VFR model constructed
from range data of a person and using gray level images to index into the model. The
pose estimation errors are quite low at about 4:05 ffi in azimuth, 5:63 ffi in elevation, 2:68 ffi in
rotation and 0:0856 standard deviation in scale estimation. The standard deviation in scale
is taken for the ratio of estimated size to true size. Thus it represents the standard deviation
assuming a scale of 1.0. Face recognition experiments are also carried out on a large database
of 40 subjects with face images in varying pose and illumination. Varying number of model
images between 5 and 8 is used. Experimental results indicate recognition rates of 92.5%
using 5 model images and goes up to 100% using 8 model images. This compares well with
[25] who reported recognition rates of 87% and 95% using the same database with 5 training
images. The eigenfaces approach [22] was able to achieve a 90% recognition rate on this
database. It also is comparable to the recognition rates of 96.2% reported in [18] again
using 5 training images per person from the same database. These are highest reported
recognition rates for the ORL database in the literature. The VFR model holds promise
as a robust and reliable representation approach that inherits the merits of both the viewer
and object centered approaches. We plan future investigations in using the VFR model for
robust methods in generic object recognition.



--R

"Computer Vision,"
"Superquadrics and Angle Preserving Transformations,"
"Pictorial Recognition Using Affine Invariant Spectral Sig- natures,"
"Affine Invariant Shape Representation and Recognition using Gaussian Kernels and Multi-dimensional Indexing,"
"Iconic Recognition with Affine-Invariant Spectral Signatures,"
"Iconic Representation and Recognition using Affine-Invariant Spectral Signatures,"
"Face Recognition Under Varying Pose,"
"Describing Surfaces"
"Face Recognition: Features versus Templates,"
"Finding face features,"
"Non-linear dimensionality reduction,"
"Object Models and Matching,"
"Visual Pattern recognition by Moment Invariants,"
"Image Reconstruction from Projections,"
"Object Recognition,"
"The Internal Representation of Solid Shape with respect to Vision,"
"Distortion Invariant Object Recognition in the Dynamic Link Architecture,"
"Face recognition: A Convolutional Neural Network Approach,"
Olivetti and Oracle Research Laboratory
"Perceptual Organization and the Representation of Natural Form,"
"View-based and modular eigenspaces for face recognition,"
"Robust detection of facial features by generalized symme- try,"

"Parameterisation of a Stochastic Model for Human Face
"Analysis of Facial Images using Physical and Anatomical Models,"
"SVD and Log-Log Frequency Sampling with Gabor Kernels for Invariant Pictorial Recognition,"
"Learning Recognition and Segmentation of 3- D Objects from 2-D Images,"
"Feature Extraction from Faces using Deformable Templates,"
"Fourier Descriptors for Plane Closed Curves,"
--TR

--CTR
Ching-Liang Su, Robotic Intelligence for Industrial Automation: Object Flaw Auto Detection and Pattern Recognition by Object Location Searching, Object Alignment, and Geometry Comparison, Journal of Intelligent and Robotic Systems, v.33 n.4, p.437-451, April 2002
Ching-Liang Su, Face Recognition by Using Feature Orientation and Feature Geometry Matching, Journal of Intelligent and Robotic Systems, v.28 n.1-2, p.159-169, June 2000
Yoshihiro Kato , Teruaki Hirano , Osamu Nakamura, Fast template matching algorithm for contour images based on its chain coded description applied for human face identification, Pattern Recognition, v.40 n.6, p.1646-1659, June, 2007
Seong G. Kong , Jingu Heo , Besma R. Abidi , Joonki Paik , Mongi A. Abidi, Recent advances in visual and infrared face recognition: a review, Computer Vision and Image Understanding, v.97 n.1, p.103-135, January 2005
