--T
Affine Structure and Motion from Points, Lines and Conics.
--A
In this paper several new methods for estimating scene
structure and camera motion from an image sequence taken by affine
cameras are presented. All methods can incorporate both point, line
and conic features in a unified manner. The correspondence between
features in different images is assumed to be known.Three new
tensor representations are introduced describing the viewing geometry
for two and three cameras. The centred affine epipoles can be used to
constrain the location of corresponding points and conics in two
images. The third order, or alternatively, the reduced third order
centred affine tensors can be used to constrain the locations of
corresponding points, lines and conics in three images. The reduced
third order tensors contain only 12 components compared to the
components obtained when reducing the trifocal tensor to affine
cameras.A new factorization method is presented. The novelty
lies in the ability to handle not only point features, but also line
and conic features concurrently. Another complementary method based
on the so-called closure constraints is also presented. The advantage
of this method is the ability to handle missing data in a simple and
uniform manner.  Finally, experiments performed on both simulated and
real data are given, including a comparison with other
methods.
--B
Introduction
Reconstruction of a three-dimensional object from
a number of its two-dimensional images is one of
the core problems in computer vision. Both the
structure of the object and the motion of the camera
are assumed to be unknown. Many approaches
have been proposed to this problem and apart
Supported by the ESPRIT Reactive LTR project 21914,
CUMULI
Supported by the Swedish Research Council for Engineering
Sciences (TFR), project 95-64-222
from the reconstructed object also the camera motion
is obtained, cf. (Tomasi and Kanade 1992,
Koenderink and van Doorn 1991, McLauchlan
and Murray 1995, Sturm and Triggs 1996, Sparr
1996, Shashua and Navab 1996, Weng, Huang and
Ahuja 1992, Ma 1993).
There are two major diOEculties that have to
be dealt with. The -rst one is to obtain corresponding
points (or lines, conics, etc.) through-out
the sequence. The second one is to choose an
appropriate camera model, e.g., perspective (cali-
brated or uncalibrated), weak perspective, aOEne,
etc. Moreover, these two problems are not completely
?separated, but in some sense coupled to
each other, which will be explained in more detail
later.
The -rst problem of obtaining feature correspondences
between dioeerent images is simpli-ed
if the viewing positions are close together. How-
ever, most reconstruction algorithms break down
when the viewpoints are close together, especially
in the perspective case. The correspondence problem
is not addressed here. Instead we assume that
the correspondences are known.
The problem of choosing an appropriate camera
model is somewhat complex. If the intrinsic
parameters of the camera are known, it seems
reasonable to choose the calibrated perspective
(pinhole) camera, see (Maybank 1993). If the intrinsic
parameters are unknown, many researchers
have proposed the uncalibrated perspective (pro-
jective) camera, see (Faugeras 1992). This is the
most appealing choice from a theoretical point of
view, but in practice it has a lot of drawbacks.
Firstly, only the projective structure of the scene is
recovered, which is often not suOEcient. Secondly,
the images have to be captured from widespread
locations, with large perspective eoeects, which is
rarely the case if the imaging situation cannot
be completely controlled. If this condition is not
ful-lled, the reconstruction algorithm may give a
very inaccurate result and might even break down
completely. Thirdly, the projective group is in
some sense too large for practical applications.
Theoretically, the projective group is the correct
choice, but only a small part of the group is actually
relevant for most practical situations, leading
to too many degrees of freedom in the model.
Another proposed camera model is the aOEne
one, see (Mundy and Zisserman 1992), which is an
approximation of the perspective camera model.
This is the model that will be used in this paper.
The advantages of using the aOEne camera model,
compared to the perspective one, are many-fold.
Firstly, the aOEne structure of the scene is obtained
instead of the projective in the uncalibrated
perspective case. Secondly, the images may be
captured from nearby locations without the algorithms
breaking down. Again, this facilitates the
correspondence problem. Thirdly, the geometry
and algebra are more simple, leading to more eOE-
cient and robust reconstruction algorithms. Also,
there is a lack of satisfactory algorithms for non-point
features in the perspective case, especially
for conics and curves.
This paper presents an integrated approach to
the structure and motion problem for aOEne cam-
eras. We extend current approaches to aOEne
structure and motion in several directions, cf.
(Tomasi and Kanade 1992, Shapiro, Zisserman
and Brady 1995, Quan and Kanade 1997, Koenderink
and van Doorn 1991). One popular reconstruction
method for aOEne cameras is the Tomasi-
Kanade factorization method for point correspon-
dences, see (Tomasi and Kanade 1992). We will
generalize the factorization idea to be able to incorporate
also corresponding lines and conics. In
(Quan and Kanade 1997) a line-based factorization
method is presented and in (Triggs 1996) a
factorization algorithm for both points and lines
in the projective case is given.
Another approach to reconstruction from images
is to use the so-called matching constraints.
These constraints are polynomial expressions in
the image coordinates and they constrain the locations
of corresponding features in two, three or
four images, see (Triggs 1997, Heyden 1995) for a
thorough treatment in the projective case. The
drawback of using matching constraints is that
only two, three or four images can be used at
the same time. The advantage is that missing
data, e.g. a point that is not visible in all images,
can be handled automatically. In this paper the
corresponding matching constraints for the aOEne
camera in two and three images are derived. Specializing
the projective matching constraints di-
rectly, like in (Torr 1995), will lead to a large over-
parameterization. We will not follow this path,
instead the properties of the aOEne camera will be
taken into account and a more eoeective parameterization
is obtained. It is also shown how to
concatenate these constraints in a uni-ed manner
to be able to cope with sequences of images.
This will be done using the so-called closure con-
straints, constraining the coeOEcients of the matching
constraints and the camera matrices. Similar
constraints have been developed in the projective
case, see (Triggs 1997). Some attempts to deal
with the missing data problem have been made in
(Tomasi and Kanade 1992, Jacobs 1997). We describe
these methods and the relationship to our
approach based on closure constraints, and we also
provide an experimental comparison with Jacobs'
method.
Preliminary results of this work, primarily
based on the matching constraints for image
triplets and the factorization method can be found
in (Kahl and Heyden 1998). Recently, the matching
constraints for two and three aOEne views have
also been derived in a similar manner, but in-
dependently, in two other papers. In (Bretzner
and Lindeberg 1998), the projective trifocal tensor
is -rst specialized to the aOEne case, like in
(Torr 1995), resulting in 16 non-zero coeOEcients
in the trifocal tensor. Then, they introduce the
centred aOEne trifocal tensor by using relative co-
ordinates, reducing the number of coeOEcients to
12. From these representations, they calculate the
three orthographic camera matrices corresponding
to these views in a rather complicated way.
A factorization method for points and lines for
longer sequences is also developed. In (Quan
and Ohta 1998) the two-view and three-view constraints
are derived in a nice and compact way
for centred aOEne cameras. By examining the relationships
between the two- and three-view con-
straints, they are able to reduce the number of co-
eOEcients to only 10 for the three-view case. These
coeOEcients for three aOEne cameras are then
directly related to the parameters of three orthographic
cameras. Our presentation of the matching
constraints is similar to the one in (Quan and
Ohta 1998), but we prefere to use a tensorial no-
tation. While we pursue the path of coping with
longer image sequences, their work is more focused
on obtaining a Euclidean reconstruction limited to
three calibrated cameras.
The paper is organized as follows. In Section 2,
we give a brief review of the aOEne camera, describing
how points, lines and conics project onto
the image plane. In Section 3, the matching constraints
for two and three views are described. For
arbitrary many views, two alternative approaches
are presented. The -rst one, in Section 4, is based
on factorization and the second one, in Section 5,
is based on closure constraints that can handle
missing data. In Section 5, we also describe two
related methods to the missing data problem. A
number of experiments, performed on both simulated
and on real data, is presented in Section 6.
Finally, in Section 7, some conclusions are given.
2. The affine camera model
In this section we give a brief review of the
aOEne camera model and describe how dioeerent
points, lines and quadrics are projected onto the
image plane. For a more thorough treatment,
see (Shapiro 1995) for points and (Quan and
Kanade 1997) for lines.
The projective/perspective camera is modeled
by
x-
where P denotes the standard 3 \Theta 4 camera matrix
and - a scale factor. Here X is a 3-vector and x is
a 2-vector, denoting point coordinates in the 3D
scene and in the image respectively.
The aOEne camera model, -rst introduced by
Mundy and Zisserman in (Mundy and Zisserman
1992), has the same form as (1), but the camera
matrix is restricted to
22
and the homogeneous scale factor - is the same for
all points. It is an approximation of the projective
camera and it generalizes the orthographic, the
perspective and the para-perspective camera
models. These models provide a good approximation
of the projective camera when the distances
between dioeerent points of the object is small compared
to the viewing distance. The aOEne camera
has eight degrees of freedom, since (2) is only de-
-ned up to a scale factor, and it can be seen as
a projective camera with its optical centre on the
plane at in-nity.
Rewriting the camera equation (1) with the
aOEne restriction (2), the equation can be written
where
A =p 34
and b =p 34
A simpli-cation can be obtained by using relative
coordinates with respect to some reference
in the object and the corresponding
point in the image. Introducing
the relative coordinates
, (3) simpli-es to
In the following, the reference point will be chosen
as the centroid of the point con-guration, since
the centroid of the three-dimensional point con-
-guration projects onto the centroid of the two-dimensional
point con-guration. Notice that the
visible point con-guration may dioeer from view to
view and thus the centroid changes from view to
view. This must be considered and we will comment
upon it later.
A line in the scene through a point X with direction
D can be written
With the aOEne camera, this line is projected to
the image line, l, through the point
according to
Thus, it follows that the direction, d, of the image
line is obtained as
This observation was -rst made in (Quan and
Kanade 1997). Notice that the only dioeerence
between the projection of points in (4) and the
projection of directions of lines in (6) is the scale
present in (6), but not in (4). Thus, with
known scale factor -, a direction can be treated
as an ordinary point. This fact will be used later
on in the factorization algorithm.
For conics, the situation is a little more complicated
than for points and lines. A general conic
curve in the plane can be represented by its dual
form, the conic envelope,
where l denotes a 3 \Theta 3 symmetric matrix and
extended dual coordinates
in the image plane. In the same way, a general
quadric surface in the scene can be represented by
its dual form, the quadric envelope,
where L denotes a 4 \Theta 4 symmetric matrix and
extended dual coordinates
in the 3D space. A conic or a quadric, (7)
or (8), is said to be proper if its matrix is non-
singular, otherwise it is said to be degenerate. For
most practical situations, it is suOEcient to know
that a quadric envelope degenerates into a disc
quadric, i.e., a conic lying in a plane in space. For
more details, see (Semple and Kneebone 1952).
The image, under a perspective projection, of a
quadric, L, is a conic, l. This relation is expressed
by
where P is the camera matrix and - a scale factor.
Introducing
l =4
l 2
l 3
l 5
l 4
l 5
l
and specializing (9) to the aOEne camera (3) gives
two set of equations. The -rst set is
l 1
l 2
l 2
l 3
\Theta
\Theta

containing three non-linear equations in A and b.
Normalizing l such that l 6
L such that
1, the second set becomes
l 4
l 5
containing three linear equations in A and b. Observe
that this equation is of the same form as
(3), which implies that conics can be treated in
the same way as points, when the non-linear equations
in (10) are omitted.
The geometrical interpretation of (11) is that
the centre of the quadric projects onto the centre
of the conic in the image, since indeed
corresponds to the centre of the
conic. This can be seen by parameterizing the
conic by its centre point then expressing it in the
form of (7).
3. Affine matching constraints
The matching constraints in the projective case
are well-known and they can directly be specialized
to the aOEne case, cf. (Torr 1995). However,
we will not follow this path. Instead, we start from
the aOEne camera equation in (4) leading to fewer
parameters and thereby a more eoeective way of
parameterizing the matching constraints.
We will from now on assume that relative coordinates
have been chosen and use the notation
I x 2
I
for relative coordinates. The subindex indicates
that the image point belongs to image I .
3.1. Two-view constraints
Denote the two camera matrices corresponding to
views number I and J by A I and A J and an arbitrary
3D-point by X (in relative coordinates).
Then (4) gives for these two images x I = A I X
and x equivalently,
A I x I
A J x J
Thus, it follows that det since M has a
non-trivial nullspace. Expanding the determinant
by the last column gives one linear equation in
the image coordinates x
I x 2
I
. The coeOEcients of this linear equation
depend only on the camera matrices A I and A J .
Therefore, let
A I
A J
De-nition 1. The minors built up by three
dioeerent rows from E IJ in (12) will be called the
centred aOEne epipoles and its 4 components will
be denoted by E
and
I
A J
and JI e
A I
where A i
I denotes the ith row of A I and similarly
for A J .
Remark. The vector IJ is the
well-known epipole or epipolar direction, i.e., the
projection in camera I of the focal point corresponding
to camera J . Here the focal point is a
point on the plane at in-nity, corresponding to the
direction of projection.
Observe that E IJ is built up by two dioeerent
tensors, IJ e i and JI e j , which are contravariant
tensors. This terminology alludes to the transformation
properties of the tensor components. In
fact, consider a change of image coordinates from
x to -
x according to
equivalently x
where S denotes a non-singular 2 \Theta 2 matrix and
denotes i.e., the element with row-index
i and column-index i 0 of S. Then the tensor components
change according to
Observe that Einstein's summation convention
has been used, i.e., when an index appears twice
in a formula it is assumed that a summation is
made over that index.
Using this notation the two-view constraint can
be written in tensor form as
denotes the permutation symbol, i.e.,
Using instead
vector notations the constraint can be written
as
where - denote the 2-component cross product,
i.e., Writing out
explicitly gives
Remark. The tensors could equivalently have
been de-ned as
I
A J
giving a covariant tensor instead. The relations
between these tensors are IJ e
and IJ e i IJ e The two-view constraints
can now simply be written, using the co-variant
epipolar tensors, as
I
The choice of covariant or contravariant indices for
these 2D tensors is merely a matter of taste. The
choice made here to use the contravariant tensors
is done because they have physical interpretations
as epipoles.
The four components of the centred aOEne
epipoles can be estimated linearly from at least
four point or conic correspondences in the two im-
ages. In fact, each corresponding feature gives one
linear constraint on the components and the use of
relative coordinates makes one constraint linearly
dependent on the other ones. Corresponding lines
in only two views do not constrain the camera mo-
tion. From (14) follows that the components can
only be determined up to scale. This means that
are centred aOEne epipoles,
then -E are
also centred aOEne epipoles corresponding to the
same viewing geometry. This undetermined scale
factor corresponds to the possibility to rescale
both the reconstruction and the camera matrices,
keeping (4) valid.
The tensor components parameterize the epipolar
geometry in two views. However, the camera
matrices are only determined up to an unknown
aOEne transformation. One possible choice of camera
matrices is given by the following proposition.
Proposition 1. Given centred aOEne epipoles,
normalized such that JI e
a set of corresponding camera matrices is given by
Proof: The result follows from straightforward
calculations of the minors in (12).
3.2. Three-view constraints
Denote the three camera matrices corresponding
to views number I , J and K by A I , A J and AK
and an arbitrary 3D-point by X. Then, the projection
of X (in relative coordinates) in these images
are given by x I = A I X, x
according to (4), or equivalently
A I x I
A J x J
Thus, it follows that rank M ! 4 since M has a
non-trivial nullspace. This means that all 4 \Theta 4
minors of M vanish. There are in total (
such minors and expanding these minors by the
last column gives linear equations in the image
coordinates x I , x J and xK . The coeOEcients of
these linear equations are minors formed by three
rows from the camera matrices A I , A J and AK .
Let
A I
A J
The minors from (16) are the Grassman coordinates
of the linear subspace of R 6 spanned by
the columns of T IJK . We will use a slightly different
terminology and notation, according to the
following de-nition.
De-nition 2. The ( determinants
of the matrices built up by three rows
from T IJK in (16) will be denoted by T
denotes the previously de-ned centred aOEne
epipoles and t ijk will be called the centred aOEne
tensor de-ned by
I
where A i
I again denotes the ith row of A I and all
indices i, j and k range from 1 to 2.
Observe that T IJK is built up by 7 dioeerent ten-
sors, the 6 centred aOEne epipoles, IJ e i , etc., and
a third order tensor t ijk , which is contravariant
in all indices 1 . This third order tensor transforms
according to
when coordinates in the images are changed according
to (13) in image I and similarly for image
J and K using matrices U and V instead of S.
Given point coordinates in all three images, the
minors obtained from M in (15) yield linear constraints
on the 20 numbers in the centred aOEne
tensors. One example of such a linear equation,
obtained by picking the -rst, second, third and
-fth row of M is
The general form of such a constraint is
or
where the last equation is the previously de-ned
two-view constraint. In (18), j and k can be chosen
in 4 dioeerent ways and the dioeerent images
can be permuted in 3 ways, so there are 12 linear
constraints from this equation. Adding the 3
additional two-view constraints from (19) gives in
total 15 linear constraints on the 20 tensor com-
ponents. All constraints can be written
where R is a 15 \Theta 20 matrix containing relative image
coordinates of the image point and t is a vector
containing the 20 components of the centred aOEne
tensor. From (20), it follows that the overall scale
of the tensor components cannot be determined.
Observe that since relative coordinates are used,
one point alone gives no constraints on the tensor
components, since its relative coordinates are
all zero. The number of linearly independent constraints
for dioeerent number of point correspondences
is given by the following proposition.
Proposition 2. Two corresponding points in 3
images give in general 10 linearly independent
constraints on the components of T IJK Three
points give in general 16 constraints and four or
more points give in general 19 constraints. Thus
the centred aOEne tensor and the centred aOEne
epipoles can in general be linearly recovered from
at least four point correspondences in 3 images.
Proof: See Appendix A.
The next question is how to calculate the camera
matrices A I , A J and AK from the 20 tensor
components of T IJK . Observe -rst that the camera
matrices can never be recovered uniquely, since
a multiplication by an arbitrary non-singular 3 \Theta 3
matrix to the right of T ijk in (16) only changes the
common scale of the tensor components. The following
proposition maps T IJK to one set of compatible
camera matrices.
Proposition 3. Given T IJK normalized such
that t the camera matrices can be calculated
as
and
Proof: Since the camera matrices are only determined
up to an aOEne transformation, the -rst
rows of A I , A J and AK can be set to the 3\Theta3 iden-
tity. The remaining components are determined
by straightforward calculations of the minors in
(16).
We now turn to the use of line correspondences
to constrain the components of the aOEne tensors.
According to (6) the direction of a line projects
similar to the projection of a point except for the
extra scale factor. Consider (6) for three dioeerent
images of a line with direction D in 3D space,
- I d I = A I D;
Since these equations are linear in the scale factors
and in D, they can be written
\Gamma- I
\Gamma- J
A I d I 0 0
A J 0 d J 0
\Gamma- I
\Gamma- J
\Gamma- K
Thus the nullspace of N is non-empty, hence
det Expanding this determinant, we get
I d j 0
i.e., a trilinear expression in d 1
and d 3
with
coeOEcients that are the components of the centred
aOEne tensor included in T IJK . Finally, we
conclude that the direction of each line gives one
constraint on the viewing geometry and that both
points and lines can be used to constrain the tensor
components 2 .
3.3. Reduced three-view constraints
It may seem superAEuous to use 20 numbers to describe
the viewing geometry of three aOEne cam-
eras, since specializing the trifocal tensor (which
has 27 components) for the projective camera, to
the aOEne case, the number of components reduces
to only 16 without using relative coordinates, cf.
(Torr 1995). Since our 20 numbers describe all
trilinear functions between three aOEne views, the
comparison is not fair, even if the specialization
of the trifocal tensor also encodes the information
about the base points. It should be compared with
the 3 \Theta components of
all trifocal tensors between three aOEne views and
three projective views, respectively. Although, it
is possible to use a tensorial representation with
only 12 components to describe the viewing geometry

In order to obtain a smaller number of parame-
ters, start again from (15) and rank M - 3. This
time we will only consider the 4 \Theta 4 minors of M
that contain both of the rows one and two, one
of the rows three and four, and one of the rows
-ve and six. There are in total 4 such minors and
they are linear in the coordinates of x I , x J and
xK . Again, these trilinear expressions have coef-
-cients that are minors of T IJK in (16), but this
time the only minors occurring are the ones containing
either both rows from A I and one from A J
or AK , or one row from each one of A I , A J and
AK .
De-nition 3. The minors built up by rows
and k from T IJK in (16), where either i 2
will be called the reduced centred
aOEne tensors and the 12 components will be denoted
by T r
the previously de-ned centred aOEne epipoles
and t denotes the previously de-ned centred aOEne
tensor in (17).
Observe that T r
IJK is built up by three dioeer-
ent tensors, the tow centred aOEne epipoles, JI e j
and KI e k , which are contravariant tensors and the
third order tensor t ijk , which is contravariant in
all indices.
Given the image coordinates in all three images,
the chosen minors obtained from M give linear
constraints on the 12 components of T r
IJK . There
are in total 4 such linear constraints and they can
be written
which can be written as
R r is a 4 \Theta 12 matrix containing relative
image coordinates of the image point and t r is
a vector containing the 12 components of the reduced
centred aOEne tensors. Observe again that
the overall scale of the tensor components can not
be determined. The number of linearly independent
constraints for dioeerent number of point correspondences
are given in the following proposition

Proposition 4. Two corresponding points in 3
images give 4 linearly independent constraints on
the reduced centred aOEne tensors. Three points
give 8 linearly independent constraints and four
or more points give 11 linearly independent con-
straints. Thus the tensor components can be linearly
recovered from at least four point correspondences
in 3 images.
Proof: See Appendix A.
Again the camera matrices can be calculated
from the 12 tensor components.
Proposition 5. Given T r
IJK normalized such
that t the camera matrices can be calculated
9as
a 21
a 22
a 23
and
A 3
a 31 a 32 a 33
where
a
a
a 23
a
a
a
Proof: The form of the elements a 22
and a 33
follows by direct calculations of the determinants
corresponding to t 212 and t 221 , respectively. The
others follow from taking suitable minors and solving
the linear equations.
Using these combinations of tensors, a number
of minimal cases appear for recovering the viewing
geometry. In order to solve these minimal cases
one has to take also the non-linear constraints on
the tensor components into account. However, in
the present work, we concentrate on developing a
method to use points, lines and conics in a uni-ed
manner, when there is a suOEcient number of corresponding
features available to avoid the minimal
cases.
4. Factorization
Reconstruction using matching constraints is limited
to a few views only. In this section, a factorization
based technique is given that handle
arbitrarily many views for corresponding points,
lines and conics. The idea of factorization is sim-
ple, but still a robust and eoeective way of recovering
structure and motion. Previously with the
matching constraints only the centre of the conic
was used, but there are obviously more constraints
that could be used. After having described the
general factorization method, we show one possible
way of incorporating this extra information.
Now consider m points or conics, and n lines in
images. (4) and (6) can be written as one single
matrix equation (with relative coordinates),
A p7 5
\Theta

The right-hand side of (26) is the product of a
2p \Theta 3 matrix and a 3 \Theta (m + n) matrix, which
gives the following theorem.
Theorem 1. The matrix S in (26) obeys
Observe that the matrix S contains entries obtained
from measurements in the images, as well
as the unknown scale factors - ij , which have to be
estimated. The matrix is known as the measurement
matrix. Assuming that these are known, the
camera matrices, the 3D points and the 3D directions
can be obtained by factorizing S. This can
be done from the singular value decomposition of
are orthogonal matrices
and \Sigma is a diagonal matrix containing the
singular values, oe i , of S. Let ~
and let ~
U and ~
V denote the -rst three columns of
U and V , respectively. Then6 4
A p7
U
~
\Sigma and
\Theta

~
ful-l (26). Observe that the whole singular value
decomposition of S is not needed. It is suOEcient to
calculate the three largest eigenvalues and the corresponding
eigenvectors of SS T . The only missing
component is the scale factors - ij for the lines.
These can be obtained in the following way.
Assume that T IJK or T r
IJK has been calcu-
lated. Then the camera matrices can be calculated
from Proposition 3 or Proposition 5. It follows
from (22) that once the camera matrices for three
images are known, the scale factors for each direction
can be calculated up to an unknown scale
factor. It remains to estimate the scale factors
for all images with a consistent scale. We have
chosen the following method. Consider the -rst
three views with camera matrices A 1
and A 3
Rewriting (22) as
A 3
d
shows that M in (28) has rank less than 4 which
implies that all 4 \Theta 4 minors are equal to zero.
These minors give linear constraints on the scale
factors. However, only 3 of them are independent.
So a system with the following appearance is obtained
54
where   indicates a matrix entry that can be calculated
from A i and d i . It is evident from (29)
that the scale factors - i only can be calculated up
to an unknown common scale factor. By considering
another triplet, with two images in common
with the -rst triplet, say the last two, we can obtain
consistent scale factors for both triplets by
solving a system with the following appearance,6 6 6 6 6 6 400
In practice, all minors of M in (28) should be used.
This procedure is easy to systematize such that
all scale factors from the direction of one line can
be computed as the nullspace of a single matrix.
The drawback is of course that we -rst need to
compute all camera matrices of the sequence. An
alternative would be to reconstruct the 3D direction
D from one triplet of images according to (22)
and then use this direction to solve for the scale
factors in the other images.
In summary, the following algorithm is proposed

1. Calculate the scale factors - ij using T IJK or
IJK .
2. Calculate S in (26) from - ij and the image
measurements.
3. Calculate the singular value decomposition of
S.
4. Estimate the camera matrices and the reconstruction
of points and line directions according
to (27).
5. Reconstruct 3D lines and 3D quadrics.
The last step needs a further comment. From
the factorization, the 3D directions of the lines and
the centres of the quadrics are obtained. The remaining
unknowns can be recovered linearly from
(5) for lines and (10) for quadrics.
Now to the question of how to incorporate all
available constraints for the conics. Given that the
quadrics in space are disk quadrics, the following
modi-cation of the above algorithm can be done.
Consider a triplet of images, with known matching
constraints. Choose a point on a conic curve in
the -rst image, and then use the epipolar lines in
the other two images to get the point-point correspondences
on the other curves. In general, there
is a two-fold ambiguity since an epipolar line intersects
a conic at two points. The ambiguity is
solved by examining the epipolar lines between the
second and third image in the triplet. Repeating
this procedure, point correspondences on the conic
curves can be obtained throughout the sequence,
and used in the factorization method as ordinary
points.
5. Closure constraints
The drawback of all factorization methods is the
diOEculty in handling missing data, i.e., when all
features are not visible in all images. In this sec-
tion, an alternative method based on closure con-
straints, is presented that can handle missing data
in a uni-ed manner. Two related methods are also
discussed.
Given the centred aOEne tensor and the centred
aOEne epipoles, it is possible to calculate a representative
for the three camera matrices. Since the
reconstruction and the camera matrices are determined
up to an unknown aOEne transformation,
only a representative can be calculated that dioeers
from the true camera matrices by an aOEne trans-
formation. When an image sequence with more
than three images is treated, it is possible to -rst
calculate a representative for the camera matrices
and A 3
, and a representative for A 2
, A 3
and A 4
and then merge these together. This is not
a good solution since errors may propagate uncontrollably
from one triplet to another. It would be
better to use all available combinations of aOEne
tensors and calculate all camera matrices at the
same time. The solution to this problem is to use
the closure constraints.
There are two dioeerent types of closure constraints
in the aOEne case springing from the two-view
and three-view constraints. To obtain the
second order constraint, start by stacking camera
matrices A I and A J like in (12), which results in
a 4 \Theta 3 matrix. Duplicate one of the columns to
obtain a 4 \Theta 4 matrix
A I A n
I
A J A n
where A n
I denotes the n:th column of A I . Since
B IJ is a singular matrix (a repeated column), we
have det B by the last
column, for
\Theta

\Theta

where IJ e 1 etc. denote the centred aOEne epipoles.
Thus (30) gives one linear constraint on the camera
matrices A I and A J .
To obtain the third order type of closure constraints
consider the matrix T IJK de-ned in (16)
for the camera matrices A I , A J and AK and duplicate
one of the columns to obtain a 6 \Theta 4 matrix
A I A n
I
A J A n
where again A n
I denotes the n:th column of A I .
Since C IJK has a repeated column it is rank de-
-cient, i.e., rank C 4. Expanding the 4 \Theta 4
minors of C IJK give three expressions, involving
only two cameras of the same type as (30) and 12
expressions involving all three cameras of the type
\Theta

\Theta

\Theta

Thus we get in total 15 linear constraints on the
camera matrices A I , A J and AK . However, there
are only 3 linearly independent constraints among
these 15, which can easily be checked by using a
computer algebra package, such as MAPLE. Some
of these constraints involve only components of
the reduced aOEne tensors, e.g., the one in (31),
making it possible to use the closure constraints
in the reduced case also.
To sum up, every second order combination of
centred aOEne epipoles gives one linear constraint
on the camera matrices and every third order combination
of aOEne tensors gives 12 additional linear
constraints on the camera matrices. Using all
available combinations, all the linear constraints
on the camera matrices can be stacked together
in a matrix M ,
Given a suOEcient number of constraints on the
camera matrices, they can be calculated linearly
from (32). Observe that the nullspace of M has
dimension 2, which implies that only the linear
space spanned by the columns of A can be de-
termined. This means that the camera matrices
can only be determined up to an unknown aOEne
transformation.
When only the second order combinations are
used, it is not suOEcient to use only the combinations
between every successive pair of images.
However, it is suOEcient to use the combinations
between views every i. This
can easily be seen from the fact that one new image
gives two new independent variables in the linear
system of equations in (32) and the two new
linear constraints balances this. When the third
order combinations are used, it is suOEcient to use
the tensor combinations between views
for every i, which again can be seen be counting
the number of unknowns and the number of linearly
independent constraints. This is also the
case for the reduced third order combinations.
The closure constraints bring the camera ma-
trices, A i , into the same aOEne coordinate
system. However, the last column in the
camera matrices, denoted by b i , cf. (3), needs also
to be calculated. These columns depend on the
chosen centroid for the relative coordinates. But if
the visible feature con-guration changes, as there
may be missing data, the centroid changes as well.
This has to be considered. For example, let x 01 ,
and X 0 denote the centroid of the visible
points in the images and in space for the -rst
three views, respectively, and let x 02
0 denote the centroid in the images and in
space for views two, three and four, respectively.
The centroids are projected as
This is a linear system in the unknowns b 1
0 . It is straightforward to generalize
the above equations for m consecutive images and
the system can be solved by a single SVD.
5.1. Related work
We examine two closely related algorithms for
dealing with missing data.
Tomasi and Kanade propose one method in
(Tomasi and Kanade 1992) to deal with the missing
data problem for point features. In their
method, one -rst locates a rectangular subset of
the measurement matrix S (26) with no missing
elements. Factorization is applied to this matrix.
Then, the initial sub-block is extended row-wise
(or column-wise) by propagating the partial structure
and motion solution. In this way, the missing
elements are -lled in iteratively. The result is -
nally re-ned using steepest descent minimization.
As pointed out by Jacobs (Jacobs 1997), their
solution seems like a reasonable heuristics, but the
method has several potential disadvantages. First,
the problem of -nding the largest full submatrix
of a matrix is NP-hard, so heuristics must be used.
Second, the data is not used in a uni-ed manner.
As only a small subset is used in the -rst fac-
torization, the initial structure and motion may
contain signi-cant inaccuracies. In turn, these errors
may propagate uncontrollably as additional
rows (or columns) are computed. Finally, the re-
-nements with steepest descent is not guaranteed
to converge to the globally optimal solution.
The method proposed in (Jacobs 1997) also
starts with the measurement matrix S using only
points. Since S should be of rank three, the m
columns of S span a 3-dimensional linear sub-
space, denoted L. Consequently, the span of any
three columns of S should intersect the subspace
L. If there are missing elements in any of the three
columns, the span of the triplet will be of higher
dimension. In that case, the constraint that the
subspace L should lie in the span of the triplet will
be a weaker one. In practise, Jacobs calculates the
nullspace of randomly chosen triplets, and -nally,
the solution is found by computing the nullspace
of the span of the previously calculated nullspaces,
using SVD.
Jacobs' method is closely related to the closure
constraints. It can be seen as the 'dual' of the closure
constraints, since it generates constraints by
picking columns in the measurement matrix, while
we generate constraints by using rows. Therefore,
a comparison based on numerical experiments has
been performed, which is presented in the experimental
section.
There are also signi-cant dioeerences. First, by
using matching tensors, lines can also contribute
to constraining the viewing geometry. Second, for
m points, there are
point triplets. In practice,
this is hard to deal with, so Jacobs heuristically
chooses a random subset of the triplets, without
knowing if it is suOEcient. With our method we
know that, e.g., it is suOEcient to use every consecutive
third order closure constraint. Finally,
Jacobs uses the visible point con-guration in adjacent
images to calculate the centroid. Since there
is missing data, this approximation often leads to
signi-cant errors (see experimental comparison).
However, one may modify Jacobs' method, so it
correctly compensates for the centroid. In order
to make a fair experimental comparison, we have
included a modi-ed version which properly handles
this problem. It works in the same manner
as the original one, but it does not use relative
coordinates. In turn, it has to compute a 4-
dimensional linear subspace of the measurement
matrix S. This modi-ed version generates constraints
by picking quadruples of columns in S.
Since there are
quadruples, the complexity is
much worse than the original one.
6. Experiments
The presented methods have been tested and evaluated
on both synthetic and real data.
6.1. Simulated data
All synthetic data was produced in the following
way. First, points, line segments and conics were
randomly distributed in space with coordinates
between \Gamma500 and +500 units. The camera positions
were chosen at a nominal distance around
1000 units from the origin and then all 3D features
were projected to these views and the obtained images
were around 500 \Theta 500 pixels. In order to test
the stability of the proposed methods, dioeerent
levels of noise were added to the data. Points were
perturbated with uniform, independent Gaussian
noise. In order to incorporate the higher accuracy
of the line segments, a number of evenly sampled
points on the line segments were perturbated with
independent Gaussian noise in the normal direction
of the line. Then, the line parameters were estimated
with least-squares. The conics were handled
similarly. The residual error for points was
chosen as the distance between the true point position
and the re-projected reconstructed 3D point.
For lines, the residual errors were chosen as the
smallest distances between the endpoints of the
true line segment and the re-projected 3D line.
For conics, the errors were measured with respect
to the centroid. These settings are close to real
life situations. All experiments were repeated 100
times and the results reAEect the average values.
Before the actual computations, all input data was
rescaled to improve numerical conditioning.
In

Table

1, it can be seen that the 20-parameter
formulation (the centred aOEne tensor and the centred
aOEne epipoles) of three views is in general
superior to the 12-parameter formulation (the reduced
aOEne tensors). For three views, factorization
gives slightly better results. All three methods
handle moderate noise perturbations well. In

Table

2 the number of points and lines is var-
ied. In general, the more number of points and
lines the better results, and the non-reduced representation
is still superior the reduced version.
Finally, in Table 3 the number of views is var-
ied. In this experiment, two variants of the factorization
method are tried and compared to the
method of closure constraints. The -rst one (I)
uses the centroid of the conic as a point feature,
and the second one uses, in addition, one point on
each conic curve, obtained by the epipolar transfer
(see Section 4). The -rst method appears more
robust than the second one, even though the second
method incorporates all the constraints of the
conic. Somewhat surprisingly, the method based
on closure constraints has similar performance as
the best factorization method 3 . The closure constraints
are of third order and only the tensors
between views used.
However, the dioeerences are minor between the
two methods and they both manage to keep the
residuals low.

Table

1. Result of simulations of 10 points and 10 lines in
3 images for dioeerent levels of noise using the third order
combination of aOEne tensors, the reduced third order combination
of aOEne tensors and the factorization approach.
The root mean square (RMS) errors are shown for the reduced
aOEne tensors T r
IJK , the non-reduced T IJK , and
factorization.
STD of noise
Red. aOEne tensors
RMS of points 0.0 3.3 8.4 7.7
RMS of lines 0.0 3.5 7.1 8.6
AOEne tensors
RMS of points 0.0 1.6 2.2 6.2
RMS of lines 0.0 1.7 2.3 8.3
Factorization
RMS of points 0.0 1.0 1.8 4.5
RMS of lines 0.0 1.1 2.1 6.8

Table

2. Results of simulation of 3 views with a dioeerent
number of points and lines and with a standard deviation
of noise equal to 1. The table shows the resulting error
(RMS) after using the reduced aOEne tensors T r
IJK , the
non-reduced T IJK , and factorization.
#points, #lines 3,3 5,5 10,10 20,20
Red. aOEne tensors
RMS of points 1.0 1.5 1.6 2.0
RMS of lines 3.9 1.5 1.2 1.7
AOEne tensors
RMS of points 1.0 1.6 1.0 1.2
RMS of lines 3.9 2.2 0.8 1.1
Factorization
RMS of points 1.0 1.1 0.9 0.9
RMS of lines 3.9 1.1 0.7 0.7
6.2. Real data
Two sets of images have been used in order evaluate
the dioeerent methods. The -rst set is used to
verify the performance on real images, and the second
set is used for a comparison with the method
of Jacobs.
6.2.1. Statue sequence A sequence of 12 images
was taken of an outdoor statue containing both
points, lines and conics. More precisely, the
statue consists of two ellipses lying on two dioeerent
planes in space and the two ellipses are connected
by straight lines, almost like a hyperboloid, see

Figure

1. There are in total 80 lines between the
ellipses. In total, four dioeerent experiments were
performed on these images.
In the -rst three experiments only 5 images were
used. In these images, 17 points, 17 lines and the
ellipses were picked out by hand in all images.
For the ellipses and the lines, the appropriate representations
were calculated by least-squares.
In the -rst experiment, only the second order
closure constraints between images i and i +1 and
between images i and used. The reconstructed
points, lines and conics were obtained by
intersection using the computed camera matrices.
The detected and re-projected features are shown
in

Figure

1.
In the second experiment, only the third order
closure constraints between images
used. The tensors were estimated from
both point, line and conic correspondences. The
camera matrices were calculated from the closure
constraints and the 3D features were obtained by
intersection. The detected and re-projected features
are shown in Figure 2 together with the re-constructed
3D model.
The third experiment was performed on the
same data as the -rst two, but the factorization
method was applied. In Figure 2, a comparison is
given for the three methods. The third order closure
constraints yield better results than the second
order constraints as expected. However, the
factorization method is outperformed by the third
order closure constraints which was unexpected.

Table

3. Table showing simulated results for
lines and 3 conics in a dioeerent number of views, with an
added error of standard deviation 1 for the factorization
approaches and using third order closure constraints. Factorization
I uses only conic centres, while Factorization II
uses an additional point on each conic curve.
Factorization I
RMS of points 0.84 0.73 0.69 0.65
RMS of lines 0.62 0.62 0.70 0.73
RMS of conics 1.00 0.76 0.78 0.76
Factorization II
RMS of points 0.87 1.00 1.25 1.59
RMS of lines 0.67 0.98 1.45 1.90
RMS of conics 1.02 1.07 1.43 1.71
Closure Constr.
RMS of points 0.86 0.75 0.68 0.65
RMS of lines 0.64 0.64 0.70 0.75
RMS of conics 1.20 0.84 0.86 0.85
100 200 300 400 500 600100200300400500100 200 300 400 500 600100200300400500Fig. 1. The second and fourth image of the sequence, with detected points lines and conics together with re-projected
points, lines and conics using the second order closure constraints.
Fig. 2. The second image of the sequence, with detected and re-projected points, lines and conics together with the
reconstructed 3D model using the third order closure constraints.
Fig. 3. Root mean square (RMS) error of second and third
order closure constraints, and factorization for -ve images
in the statue sequence.
The -nal experiment was performed on all 12
images of the statue. In these images, there is a
lot of missing data, i.e., all features are not visible
in all images. The reconstruction then has to
be based on the closure constraints. In the resulting
3D model, the two ellipses and the 80 lines
were reconstructed together with 80 points, see

Figure

4. The resulted structure and motion was
also re-ned using bundle adjustment techniques,
cf. (Atkinson 1996) to get, in a sense, an optimal
reconstruction, and compared to that of the original
one. To get an idea of the errors caused by
the aOEne camera model, the result was also used
as initialization for a bundle adjustment algorithm
based on the projective camera model. The comparison
is given in Figure 5, image per image. The
quality of the output from the method based on
the closure constraints is not optimal, but fairly
accurate. If further accuracy is required, it can
serve as a good initialization to a bundle adjustment
algorithm for the aOEne or the full projec-
tive/perspective model.
6.2.2. Box sequence As a -nal test, we have
compared our method to that of Jacobs, described
in (Jacobs 1997). Naturally, we can only use point
features, since Jacobs method is only valid for
that. As described in Section 5.1, it works by
-nding a rank three approximation of the measurement
matrix. Since this original version incorrectly
compensates for the translational com-
ponent, we have included a modi-ed version which
does this properly by -nding a rank four approx-
imation. We have used Jacobs' own implementation
in Matlab, for both versions.
As a test sequence, we have chosen the box
sequence, which was also used by Jacobs in his
paper. The sequence, which originates from the
Computer Vision Laboratory at the University
of Massachusetts, contains forty points tracked
across eight images. One frame is shown in Figure
6. We generated arti-cial occlusions, by assuming
that each point is occluded for some fraction
of the sequence. The fraction is randomly
chosen for each point from a uniform distribution.
These settings are the same as in (Jacobs 1997).
For Jacobs' algorithm, the maximum number of
triplets (quadruples) has been set to the actual
Fig. 4. The full reconstruction of the statue based on the
third order closure constraints.
Fig. 5. Root mean square (RMS) error of third order closure
constraints, aOEne bundle adjustment and projective
bundle adjustment for each image in the statue sequence.
number of available triplets (quadruples). How-
ever, this is only an upper limit. Jacobs chooses
triplets until the nullspace matrix of all triplets occupies
ten times as many columns as the original
measurement matrix. We have set this threshold
to 100 times. In turn, all possible third order closure
constraints for the sequence are calculated.
In

Figure

7, the result is graphed for Jacobs'
rank three approximation, rank four approximation
and the method of closure constraints. The
result for the rank three version is clearly biased.
The performance of the rank four and closure
based methods are similar up to about percent
missing data. With more missing data, the
closure method is superior. Based on this exper-
Fig. 6. One image of the box sequence.
0.5135fraction of occlusion
RMS
Jacobs, rank three
Jacobs, rank four
Closure constraints
Fig. 7. Averaged RMS error over 100 trials. The error is
plotted against the average fraction of frames in which a
point is occluded. The tested methods are Jacobs' rank
three and four methods and closure based method.
iment, the closure constraints are preferable both
in terms of stability and complexity.
7. Conclusions
In this paper, we have presented an integrated
approach to the structure and motion problem
for the aOEne camera model. Correspondences of
points, lines and conics have been handled in a
uni-ed manner to reconstruct the scene and the
camera positions. The proposed scheme is illustrated
on both simulated and real data.

Appendix

A
Proof: (of Proposition 2) The number of linearly
independent equations (in the components
of T IJK ) can be calculated as follows. The 15 linear
constraints obtained from the minors of M in
(15) are not linearly independent, i.e., there exists
non-trivial combinations of these constraints that
vanishes. Consider the matrix4
A I x I x I
A J x J x J
obtained from M by duplicating its last column.
This matrix is obviously of rank ! 5, implying
that all 5 \Theta 5 minors vanish. There are 6 such
minors and they can be written (using Laplacian
expansions) as linear equations in the previously
obtained linear constraints (minors from the -rst
four columns) with image coordinates (elements
from the last column) as coeOEcients. This gives 6
linear dependencies on the 15 original constraints,
called second order constraints. On the other
hand it is obvious that all linear constraints on
the originally obtained 15 constraints can be written
as the vanishing of minors from a determinant
of the form4
A I x I k 1
A J x J k 2
Hence the vector [
is a linear combination
of the other columns of the matrix and since
it has to be independent of A I , A J and AK , we
deduce that we have obtained all possible second
order linear constraints.
The process does not stop here, since these second
order constraints are not linearly indepen-
dent. This can be seen by considering the matrix4
A I x I x I x I
A J x J x J x J
Again Laplacian expansions give one third order
constraint. To sum up we have
linearly independent constraints for two corresponding
points. The similar reasoning as before
gives that all possible second order constraints has
been obtained.
Using three corresponding points we obtain 10
linearly independent constraints from the second
linearly independent constraints from
the third point. However, there are linear dependencies
among these 20 constraints. To see this
consider the matrix4
A I x I - x I
A J x J -
x J
x denotes the third point. Using Laplacian
expansions of the 5 \Theta 5 minors we obtain 6 bilinear
expressions in x and -
x with the components of the
third order combination of aOEne tensors as coeOE-
cients. Each such minor give a linear dependency
between the constraints, i.e., 6 second order con-
straints. Again there are third order constraints
obtained from4
A I x I x I -
x I
A J x J x J - x J
and 2A I x I - x I -
x I
A J x J -
giving in total 2 third order constraints. To sum
up we have independent
constraints. We note again that all possible linear
constraints have been obtained according to the
same reasoning as above.
The same analysis can be made for the case
of four point matches. First we have 10 linearly
independent constraints from each point (apart
from the -rst one) and each pair of corresponding
points give 4 second order linear constraints,
giving constraints. Then one
third order constraint can be obtained from the
determinant of4
A I x I - x I -
x I
A J x J -
where - x denote the fourth point, giving
linearly independent constraints for
four points. Again all possible constraints have
been obtained, which concludes the proof.
Remark. The rank condition rank M ! 4 is
equivalent to the vanishing of all 4 \Theta 4 minors of
M . These minors are algebraic equations in the
24 elements of M . These (non-linear) equations
de-ne a variety in 24 dimensional space. The dimension
of this variety is a well-de-ned number, in
this case 21, which means that the co-dimension
is 3. This means that, in general (at all points
on the variety except for a subset of measure zero
in the Zariski topology), the variety can locally
be described as the vanishing of three polynomial
equations. This can be seen by making row and
column operations on M until it has the following
structure 2
where p, q and r are polynomial expressions in the
entries of M . The matrix above has rank ! 4 if
and only if
equations de-ne the variety locally. The points
on the variety where the rank condition can not
locally be described by three algebraic equations
are the ones where all of the 3 \Theta 3 minors of M
vanishes, which is a closed (and hence of measure
zero) subset in the Zariski topology.
Remark. Since we are interested in linear con-
straints, we obtain 10 linearly independent equations
instead of the 3 so-called algebraically independent
equations described in the previous re-
mark. However, one can not select 10 such constraints
in advance that will be linearly independent
for every point match. Therefore, in numerical
computations, it is better to use all of them.
Proof: (of Proposition 4) It is easy to see that
there are no second (or higher) order linear constraints
involving only the 4 constraints in (23).
Neither are there any higher order constraints for
the two sets of (23) involving two dioeerent points,
x and - x. Finally, for four dioeerent points, there
can be no more than 11 linearly independent con-
straints, since according to (24) the matrix containing
all constraints has a non-trivial null-space.
Notes
1. Again the choice of de-ning a contravariant tensor is
arbitrarily made. In fact, the tensor could have been
de-ned covariantly as
I
K7which is the one used in (Quan and Kanade 1997).
Transformations between these representations (and
other intermediate ones such as covariant in one index
and contravariant in the other ones) can easily be made.
2. The tensor t ijk can also be used to transfer directions
seen in two of the three images to a direction in the
third one, using the mixed form t i
jk according to
3. This has been con-rmed under various imaging condi-
tions, like e.g., closely spaced images.



--R

Close Range Photogrammetry and Machine Vision
Use your hand as a 3-d mouse
What can be seen in three dimensions with an uncalibrated stereo rig?
Geometry and Algebra of Multipe Projective Transformations

Structure and motion from points

Theory of Reconstruction from Image Motion
A unifying framework for structure and motion recovery from image sequences
Geometric invariance in Computer Vision
AOEne structure from line correspondences with uncalibrated aOEne cam- eras
A new linear method for euclidean motion/structure from three calibrated aOEne views
Algebraic Projective Geometry
AOEne Analysis of Image Sequences
3d motion recovery via aOEne epipolar geometry
Relative aOEne struc- ture: Canonical model for 3d from 2d geometry and applications
Simultaneous reconstruction of scene structure and camera locations from uncalibrated image sequences
A factorization based algorithm for multi-image projective structure and mo- tion
Shape and motion from image streams under orthography: a factorization method
Motion Segmentation and Outlier Detec- tion
Factorization methods for projective structure and motion
Linear projective reconstruction from matching tensors
Motion and structure from line correspondences: Closed-form solution
--TR
Motion and Structure from Line Correspondences; Closed-Form Solution, Uniqueness, and Optimization
Shape and motion from image streams under orthography
Geometric invariance in computer vision
Conics-based stereo, motion estimation, and pose determination
Affine analysis of image sequences
3D motion recovery via affine epipolar geometry
Relative Affine Structure
Affine Structure from Line Correspondences With Uncalibrated Affine Cameras
What can be seen in three dimensions with an uncalibrated stereo rig
A Factorization Based Algorithm for Multi-Image Projective Structure and Motion
Use Your Hand as a 3-D Mouse, or, Relative Orientation from Extended Sequences of Sparse Point and Line Correspondences Using the Affine Trifocal Tensor
Structure and Motion from Points, Lines and Conics with Affine Cameras
Linear Fitting with Missing Data
Factorization Methods for Projective Structure and Motion
A New Linear Method for Euclidean Motion/Structure from Three Calibrated Affine Views
A unifying framework for structure and motion recovery from image sequences
Simultaneous Reconstruction of Scene Structure and Camera Locations from Uncalibrated Image Sequences

--CTR
Yi Ma , Kun Huang , Ren Vidal , Jana Koeck , Shankar Sastry, Rank Conditions on the Multiple-View Matrix, International Journal of Computer Vision, v.59 n.2, p.115-137, September 2004
Leo Reyes , Eduardo Bayro-Corrochano, Simultaneous and Sequential Reconstruction of Visual Primitives with Bundle Adjustment, Journal of Mathematical Imaging and Vision, v.25 n.1, p.63-78, July      2006
Fredrik Kahl , Anders Heyden , Long Quan, Minimal Projective Reconstruction Including Missing Data, IEEE Transactions on Pattern Analysis and Machine Intelligence, v.23 n.4, p.418-424, April 2001
Jacob Goldberger, Reconstructing camera projection matrices from multiple pairwise overlapping views, Computer Vision and Image Understanding, v.97 n.3, p.283-296, March 2005
Nicolas Guilbert , Adrien Bartoli , Anders Heyden, Affine Approximation for Direct Batch Recovery of Euclidian Structure and Motion from Sparse Data, International Journal of Computer Vision, v.69 n.3, p.317-333, September 2006
Pei Chen , David Suter, An Analysis of Linear Subspace Approaches for Computer Vision and Pattern Recognition, International Journal of Computer Vision, v.68 n.1, p.83-106, June      2006
Pei Chen , David Suter, A Bilinear Approach to the Parameter Estimation of a General Heteroscedastic Linear System, with Application to Conic Fitting, Journal of Mathematical Imaging and Vision, v.28 n.3, p.191-208, July      2007
Hayman , Torfi Thrhallsson , David Murray, Tracking While Zooming Using Affine Transfer and Multifocal Tensors, International Journal of Computer Vision, v.51 n.1, p.37-62, January
