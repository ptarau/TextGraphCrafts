AbstractThis correspondence presents a new technique for calibrating a camera mounted on a controllable head/eye platform. It uses the trajectories of an arbitrary number of tracked corner features to improve the calibration parameter estimates over time, utilizing a novel variable state dimension form of recursive filter. No special visual stimuli are required and no assumptions are made about the structure of the scene, other than that it is stationary relative to the head. The algorithm runs at 4 frames per second on a single Inmos T805 transputer, and is fully integrated into a real-time active vision system. Updated calibration parameters are regularly passed to the vision modules that require them. Although the algorithm requires an initial estimate of camera focal length, results are presented from real experiments demonstrating that convergence is achieved for initial errors up to 50%. 