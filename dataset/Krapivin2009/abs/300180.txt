An application of Pontryagin's maximum principle data assimilation is used to blend possibly incomplete or nonuniformly distributed spatio-temporal observational data into geophysical models. Used extensively in engineering control theory applications, data assimilation has been introduced relatively recently into meteorological forecasting, natural-resource recovery modeling, and climate dynamics. Variational data assimilation is a promising assimilation technique in which it is assumed that the optimal state of the system is an extrema of a carefully chosen cost function. Provided that an adjoint model is available, the required model gradient can be computed by integrating the model forward and its adjoint backward. The gradient is then used to extremize the cost function with a suitable iterative or conjugate gradient solver.The problem addressed in this study is the explosive growth in both on-line computer memory and remote storage requirements of computing the gradient by the forward/adjoint technique which characterizes large-scale assimilation studies. Storage limitations impose severe limitation on the size of assimilation studies, even on the largest  computers. By using a recursive strategy, a schedule can be constructed that enables the forward/adjoint model runs to be performed in such a way that storage requirements can be traded for longer computational times.  This generally applicable strategy enables data assimilation studies on significantly larger domains than would otherwise be possible, given the particular hardware constraints, without compromising the outcome in any way. Furthermore, it is  shown that this tradeoff is indeed viable and that when the schedule is optimized, the storage and computational times grow at most logarithmically. 