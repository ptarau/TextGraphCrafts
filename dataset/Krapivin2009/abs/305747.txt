We investigate two problems concerning the complexity of evaluating a function f on k distinct inputs by  k parallel decision-tree algorithms.In the product problem, for some fixed depth bound  d, we seek to maximize the fraction of input k-tuples for which all k decision trees are correct. Assume that for a single input to f, the best depth-d decision tree is correct on a fraction p of inputs. We prove that the maximum fraction of k-tuples on which k depth-d algorithms are all correct is at most pk, which is the trivial lower bound. We show that if we replace the restriction to depth d by "expected depth d," then this result need not hold.In the  help-bits problem, before the decision-tree computations begin, up to k-1 arbitrary binary questions (help-bit queries) can be asked about the k-tuple of inputs. In the second stage, for each possible (k-1)-tuple of answers to the help-bit queries, there is a k-tuple of decision trees where the ith tree is supposed to correctly compute the value of the function on the ith input, for any input that is consistent with the help bits. The complexity here is the maximum depth of any of the trees in the algorithm.  We show that for all k sufficiently large, this complexity is equal to degs(f), which is the minimum degree of a multivariate polynomial whose sign is equal to f. 