Combining different machine learning algorithms in the same system can produce benefits above and beyond what either method could achieve alone.  This paper demonstrates that genetic algorithms can be used in conjunction with lazy learning to solve examples of a difficult class of delayed reinforcement learning problems better than either method alone. This class, the class of differential games, includes numerous important control problems that arise in robotics, planning, game playing, and other areas, and solutions for differential games suggest solution strategies for the general class of planning and control problems. We conducted a series of experiments applying three learning approaches  lazy Q-learning, k-nearest neighbor (k-NN), and a genetic algorithm  to a particular differential game called a pursuit game.  Our experiments demonstrate that k-NN had great difficulty solving the problem, while a lazy version of Q-learning performed moderately well and the genetic algorithm performed even better.  These results motivated the next step in the experiments, where we hypothesized k-NN was having difficulty because it did not have good examples  a common source of difficulty for lazy learning.  Therefore, we used the genetic algorithm as a bootstrapping method for k-NN to create a system to provide these examples.  Our experiments demonstrate that the resulting joint system learned to solve the pursuit games with a high degree of accuracy  outperforming either method alone  and with relatively small memory requirements. 