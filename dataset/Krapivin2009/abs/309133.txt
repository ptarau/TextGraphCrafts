When a data file is replicated at more than one site, it is of interest to detect corruption by comparing the multiple copies. In order to reduce the amount of messaging for large files, techniques based on page signatures and combined signatures have been explored. However, for 3 or more sites, the known methods assume that the number of corrupted page copies is at most M/2  1, where M is the number of sites. This is a pessimistic assumption which is unrealistic. In this paper, this assumption is replaced by another assumption which is shown to be reasonable. Based on this assumption, and based on a finer model of the system, three distributed algorithms are derived, which can either improve the performance or provide more tolerance to corruptions compared to previous methods. As in some previous work, the amount of signature transmission in the algorithms varies according to the number and patterns of page copy corruptions that actually occur, and two of the algorithms achieve the optimal amount of signature transmission when no failure occurs. 