AbstractWe consider the problem of assigning an input vector to one of m classes by predicting P(c|${\schmi x}$) for m. For a two-class problem, the probability of class one given ${\schmi x}$ is estimated by (y(${\schmi x}$)), where Gaussian process prior is placed on y(${\schmi x}$), and is combined with the training data to obtain predictions for new ${\schmi x}$ points. We provide a Bayesian treatment, integrating over uncertainty in y and in the parameters that control the Gaussian process prior; the necessary integration over y is carried out using Laplace's approximation. The method is generalized to multiclass problems (m > 2) using the softmax function. We demonstrate the effectiveness of the method on a number of datasets. 